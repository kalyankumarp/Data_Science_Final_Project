{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import statsmodels.api as sm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Task 1\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "\n",
    "# TASK 2\n",
    "from sklearn.preprocessing import MinMaxScaler \n",
    "\n",
    "# TASK 3a\n",
    "from sklearn import linear_model\n",
    "import statsmodels.api as sm\n",
    "from sklearn.metrics  import mean_absolute_error\n",
    "\n",
    "from sklearn import tree\n",
    "# Naive bayes\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "from sklearn.externals.six import StringIO\n",
    "from sklearn import metrics\n",
    "import pydot\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# HyperParameter Tuning\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import f1_score, make_scorer\n",
    "from scipy.stats import rv_continuous, randint\n",
    "\n",
    "# Bayesian Optimisation\n",
    "\n",
    "from hyperopt import hp, tpe, Trials, fmin\n",
    "from hpsklearn import HyperoptEstimator, knn, decision_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1  = pd.read_csv('US Demographic Data 2015.csv')\n",
    "data1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = pd.read_csv('Temp2015.csv')\n",
    "temp.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1['Percent Population with age between 16 and 44'] = temp['Percent Population with age between 16 and 44']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1['Percent Population with age between 45 and 74'] = temp['Percent Population with age between 45 and 74']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1['Percent Population with age between 75 and over'] = temp['Percent Population with age between 75 and over']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data1[['CensusId', 'State', 'County', 'TotalPop', 'Percent Population with age between 16 and 44',\n",
    "       'Percent Population with age between 45 and 74',\n",
    "       'Percent Population with age between 75 and over','Men', 'Women', 'Hispanic',\n",
    "       'White', 'Black', 'Native', 'Asian', 'Pacific', 'Citizen', 'Income',\n",
    "       'IncomeErr', 'IncomePerCap', 'IncomePerCapErr', 'Poverty',\n",
    "       'ChildPoverty', 'Professional', 'Service', 'Office', 'Construction',\n",
    "       'Production', 'Drive', 'Carpool', 'Transit', 'Walk', 'OtherTransp',\n",
    "       'WorkAtHome', 'MeanCommute', 'Unemployment']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are some missing values in the Income column\n",
    "# Replacing using median \n",
    "median = data['Income'].median()\n",
    "data['Income'].fillna(median, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are some missing values in the ChildPoverty column\n",
    "# Replacing using median \n",
    "median = data['ChildPoverty'].median()\n",
    "data['ChildPoverty'].fillna(median, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not worked\n",
    "#def f(row):\n",
    "#    if data[data['Unemployment'] >= 10]:\n",
    "#        val = 3\n",
    " #   elif data[(data['Unemployment'] >= 5) & (data['Unemployment'] < 10)]:\n",
    "  #      val = 2\n",
    "   # else:\n",
    "    #    val = 1\n",
    "    #return val\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "row_indexes=data[data['Unemployment'] >= 12].index\n",
    "data.loc[row_indexes,'Class']=\"3\"\n",
    "\n",
    "row_indexes1=data[(data['Unemployment'] >= 8) & (data['Unemployment'] < 12)].index\n",
    "data.loc[row_indexes1,'Class']=\"2\"\n",
    "\n",
    "row_indexes2=data[data['Unemployment'] < 8].index\n",
    "data.loc[row_indexes2,'Class']=\"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not worked\n",
    "\n",
    "#data['Class'] = data.apply(f,axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not worked\n",
    "\n",
    "#data.loc[data['Unemployment'] >= 10, 'Class'] = 3\n",
    "#data.loc[[data['Unemployment'] >= 5 and data['Unemployment'] < 10, 'Class'] = 2\n",
    "#data.loc[data['Unemployment'] < 5, 'Class'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not worked\n",
    "\n",
    "#data[['Class']][data['Unemployment'] >= 5.5] = 1\n",
    "#data['Class'][data['Unemployment'] > 3.5 and data['Unemployment'] < 5.5] = 2\n",
    "#data['Class'][data['Unemployment'] <= 3.5] = 3\n",
    "#for i in data['Unemployment']:\n",
    "#    if data[(data['Unemployment'] >= 10)]:\n",
    " #       data['Class'] = 1\n",
    "  #  elif data[(data['Unemployment'] >= 5) & (data['Unemployment'] < 10)]:\n",
    "   #     data['Class'] = 2\n",
    "    #else:\n",
    "     #   data['Class'] = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data[\"National Unemployment Rate for 2013\"] = 9.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "se  = pd.read_csv('State Unemployment rate 2013.csv')\n",
    "ce = pd.read_csv('County Unemployment rate 2013.csv')\n",
    "ce.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "se.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "se.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"ce['County'] = ce['County'].str.lower()\n",
    "data['County'] = data['County'].str.lower()\n",
    "data['State'] = data['State'].str.lower()\n",
    "se['State'] = se['State'].str.lower()\n",
    "ce.head()\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = pd.merge(data, se, how=\"inner\", on = 'State')\n",
    "d1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = pd.merge(d1, ce, how=\"inner\", on = ['CensusId'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d[['StateId','CensusId', 'State', 'County', 'TotalPop', 'Percent Population with age between 16 and 44',\n",
    "       'Percent Population with age between 45 and 74',\n",
    "       'Percent Population with age between 75 and over','Men', 'Women', 'Hispanic',\n",
    "       'White', 'Black', 'Native', 'Asian', 'Pacific', 'Citizen Voting Age Pop', 'Median Household Income',\n",
    "       'IncomeErr', 'IncomePerCap', 'IncomePerCapErr', 'Poverty',\n",
    "       'ChildPoverty', 'Professional', 'Service', 'Office', 'Construction',\n",
    "       'Production', 'Drive', 'Carpool', 'Transit', 'Walk', 'OtherTransp',\n",
    "       'WorkAtHome', 'Mean Commute Time',\n",
    "       'State Unemployment rate for 2013', 'County Unemployment Rate for 2013', \n",
    "   'Unemployment', 'Class']] = d[['Id2','CensusId', 'State', 'County_x', 'TotalPop', 'Percent Population with age between 16 and 44',\n",
    "       'Percent Population with age between 45 and 74',\n",
    "       'Percent Population with age between 75 and over', 'Men', 'Women', 'Hispanic',\n",
    "       'White', 'Black', 'Native', 'Asian', 'Pacific', 'Citizen', 'Income',\n",
    "       'IncomeErr', 'IncomePerCap', 'IncomePerCapErr', 'Poverty',\n",
    "       'ChildPoverty', 'Professional', 'Service', 'Office', 'Construction',\n",
    "       'Production', 'Drive', 'Carpool', 'Transit', 'Walk', 'OtherTransp',\n",
    "       'WorkAtHome', 'MeanCommute',\n",
    "       'Unemployment rate', 'County Unemployment Rate', 'Unemployment', 'Class']]\n",
    "\n",
    "\n",
    "dataN = d[['StateId','CensusId', 'State', 'County', 'TotalPop', 'Percent Population with age between 16 and 44',\n",
    "       'Percent Population with age between 45 and 74',\n",
    "       'Percent Population with age between 75 and over','Men', 'Women', 'Hispanic',\n",
    "       'White', 'Black', 'Native', 'Asian', 'Pacific', 'Citizen Voting Age Pop', 'Median Household Income',\n",
    "       'IncomeErr', 'IncomePerCap', 'IncomePerCapErr', 'Poverty',\n",
    "       'ChildPoverty', 'Professional', 'Service', 'Office', 'Construction',\n",
    "       'Production', 'Drive', 'Carpool', 'Transit', 'Walk', 'OtherTransp',\n",
    "       'WorkAtHome', 'Mean Commute Time',\n",
    "       'State Unemployment rate for 2013', 'County Unemployment Rate for 2013', \n",
    "   'Unemployment', 'Class']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataN.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataN.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataN.to_csv(\"New.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_new  = pd.read_csv('New.csv')\n",
    "data_new.drop(['Unnamed: 0'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_new.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_new.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_new.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_new.drop(['Women'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We also don't need the 'IncomeErr', '' and 'IncomePerCapErr' attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_new.drop(['IncomeErr', 'IncomePerCapErr'], axis = 1, inplace = True)\n",
    "data_new.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have to remove the attribute 'OtherTransp' to avoid linear dependence\n",
    "data_new.drop(['OtherTransp'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_un = data_new[\"TotalPop\"][data_new[\"Class\"] == 1]\n",
    "print(b_un.mean())\n",
    "\n",
    "a_un = data_new[\"TotalPop\"][data_new[\"Class\"] == 2]\n",
    "print(a_un.mean())\n",
    "\n",
    "w_un = data_new[\"TotalPop\"][data_new[\"Class\"] == 3]\n",
    "print(w_un.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_new.plot.scatter(x= \"TotalPop\", y = 'Citizen Voting Age Pop')\n",
    "r = np.corrcoef(data_new[[\"TotalPop\", \"Citizen Voting Age Pop\"]].transpose())\n",
    "r[0,1]**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_new[[\"TotalPop\", \"Citizen Voting Age Pop\"]]\n",
    "Y = data_new[\"Unemployment\"]\n",
    "X = sm.add_constant(X)\n",
    "results3 = sm.OLS(Y,X).fit()\n",
    "print(results3.summary())\n",
    "#SSE = round(results3.ssr,3)\n",
    "#SSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_new[[\"TotalPop\", 'Citizen Voting Age Pop']]\n",
    "Y = data_new[\"Unemployment\"]\n",
    "X = sm.add_constant(X)\n",
    "results3 = sm.OLS(Y,X).fit()\n",
    "print(results3.summary())\n",
    "#SSE = round(results3.ssr,3)\n",
    "#SSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The vaiables \"TotalPop\" and \"Citizen Voting Age Pop\" are not independent. \n",
    "# And we got adj R2 value 0 for the combination of \"TotalPop\" and \"Citizen Voting Age Pop\" \n",
    "# So, we have to include the interaction between these or remove one of them in the regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_new['TC'] = data_new['TotalPop']*data_new[\"Citizen Voting Age Pop\"]\n",
    "#removing \"Citizen Voting Age Pop\"\n",
    "data_new.drop(['Citizen Voting Age Pop'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_new.plot.scatter(x= \"TotalPop\", y = 'Men')\n",
    "r = np.corrcoef(data_new[[\"TotalPop\", \"Men\"]].transpose())\n",
    "r[0,1]**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_new[[\"TotalPop\"]]\n",
    "Y = data_new[\"Unemployment\"]\n",
    "X = sm.add_constant(X)\n",
    "results3 = sm.OLS(Y,X).fit()\n",
    "print(results3.summary())\n",
    "#SSE = round(results3.ssr,3)\n",
    "#SSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_new[[\"Men\"]]\n",
    "Y = data_new[\"Unemployment\"]\n",
    "X = sm.add_constant(X)\n",
    "results3 = sm.OLS(Y,X).fit()\n",
    "print(results3.summary())\n",
    "#SSE = round(results3.ssr,3)\n",
    "#SSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_new[[\"TotalPop\",'Men']]\n",
    "Y = data_new[\"Unemployment\"]\n",
    "X = sm.add_constant(X)\n",
    "results3 = sm.OLS(Y,X).fit()\n",
    "print(results3.summary())\n",
    "#SSE = round(results3.ssr,3)\n",
    "#SSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_new['TM'] = data_new['TotalPop']*data_new[\"Men\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The vaiables \"TotalPop\" and \"Men\" are not independent. \n",
    "# But the adj R2 value haven't increased significantly with the inclusion of the variable \"Men\"\n",
    "# So, we have to keep both for the regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_new['TM'] = data_new['TotalPop']*data_new[\"Men\"]\n",
    "#removing \"Men\"\n",
    "data_new.drop([\"Men\"], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = data_new.plot.scatter(x= \"TotalPop\", y= \"Percent Population with age between 16 and 44\")\n",
    "a.set(xlim=(0, 30000))\n",
    "r = np.corrcoef(data_new[[\"TotalPop\", \"Percent Population with age between 16 and 44\"]].transpose())\n",
    "r[0,1]**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = data_new.plot.scatter(x= \"TotalPop\", y= \"Percent Population with age between 45 and 74\")\n",
    "a.set(xlim=(0, 30000))\n",
    "r = np.corrcoef(data_new[[\"TotalPop\", \"Percent Population with age between 45 and 74\"]].transpose())\n",
    "r[0,1]**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = data_new.plot.scatter(x= \"TotalPop\", y= \"Percent Population with age between 75 and over\")\n",
    "a.set(xlim=(0, 30000))\n",
    "r = np.corrcoef(data_new[[\"TotalPop\", \"Percent Population with age between 75 and over\"]].transpose())\n",
    "r[0,1]**2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = data_new.plot.scatter(x= \"Percent Population with age between 16 and 44\", y= \"Percent Population with age between 45 and 74\")\n",
    "a\n",
    "r1 = np.corrcoef(data_new[[\"Percent Population with age between 16 and 44\", \"Percent Population with age between 45 and 74\"]].transpose())\n",
    "print(r1[0,1]**2)\n",
    "\n",
    "r = np.corrcoef(data_new[[\"Percent Population with age between 16 and 44\", \"Unemployment\"]].transpose())\n",
    "print(r[0,1]**2)\n",
    "\n",
    "r = np.corrcoef(data_new[[\"Percent Population with age between 45 and 74\", \"Unemployment\"]].transpose())\n",
    "print(r[0,1]**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_new[[\"Percent Population with age between 16 and 44\"]]\n",
    "Y = data_new[\"Unemployment\"]\n",
    "X = sm.add_constant(X)\n",
    "results3 = sm.OLS(Y,X).fit()\n",
    "print(results3.summary())\n",
    "#SSE = round(results3.ssr,3)\n",
    "#SSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_new[[\"Percent Population with age between 45 and 74\"]]\n",
    "Y = data_new[\"Unemployment\"]\n",
    "X = sm.add_constant(X)\n",
    "results3 = sm.OLS(Y,X).fit()\n",
    "print(results3.summary())\n",
    "#SSE = round(results3.ssr,3)\n",
    "#SSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_new[[\"Percent Population with age between 16 and 44\", \"Percent Population with age between 45 and 74\"]]\n",
    "Y = data_new[\"Unemployment\"]\n",
    "X = sm.add_constant(X)\n",
    "results3 = sm.OLS(Y,X).fit()\n",
    "print(results3.summary())\n",
    "#SSE = round(results3.ssr,3)\n",
    "#SSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The vaiables \"Percent Population with age between 16 and 44\" and \"Percent Population with age between 45 and 74\" are not independent. \n",
    "\n",
    "# But adj R2 value increased for the combination of \"Percent Population with age between 16 and 44\" and \"Percent Population with age between 45 and 74\" \n",
    "# So, we have to include both for the regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = data_new.plot.scatter(x= \"Percent Population with age between 16 and 44\", y= \"Percent Population with age between 75 and over\")\n",
    "a\n",
    "r = np.corrcoef(data_new[[\"Percent Population with age between 16 and 44\", \"Percent Population with age between 75 and over\"]].transpose())\n",
    "print(r[0,1])\n",
    "\n",
    "r = np.corrcoef(data_new[[\"Percent Population with age between 16 and 44\", \"Unemployment\"]].transpose())\n",
    "print(r[0,1])\n",
    "\n",
    "r = np.corrcoef(data_new[[\"Percent Population with age between 75 and over\", \"Unemployment\"]].transpose())\n",
    "print(r[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_new[[\"Percent Population with age between 75 and over\"]]\n",
    "Y = data_new[\"Unemployment\"]\n",
    "X = sm.add_constant(X)\n",
    "results3 = sm.OLS(Y,X).fit()\n",
    "print(results3.summary())\n",
    "#SSE = round(results3.ssr,3)\n",
    "#SSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_new[[\"Percent Population with age between 16 and 44\", \"Percent Population with age between 45 and 74\", \"Percent Population with age between 75 and over\"]]\n",
    "Y = data_new[\"Unemployment\"]\n",
    "X = sm.add_constant(X)\n",
    "results3 = sm.OLS(Y,X).fit()\n",
    "print(results3.summary())\n",
    "#SSE = round(results3.ssr,3)\n",
    "#SSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The adj R2 value increased significantly \n",
    "# for the combination of \"Percent Population with age between 16 and 44\", \"Percent Population with age between 45 and 74\" and \"Percent Population with age between 75 and over\"\n",
    "# So, we have to include all the three for the regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = data_new.plot.scatter(x= \"TotalPop\", y = 'Hispanic')\n",
    "a.set(xlim=(0, 300000))\n",
    "r = np.corrcoef(data_new[[\"TotalPop\", \"Hispanic\"]].transpose())\n",
    "r[0,1]**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_new[[\"Hispanic\"]]\n",
    "Y = data_new[\"Unemployment\"]\n",
    "X = sm.add_constant(X)\n",
    "results3 = sm.OLS(Y,X).fit()\n",
    "print(results3.summary())\n",
    "#SSE = round(results3.ssr,3)\n",
    "#SSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = data_new.plot.scatter(x= \"TotalPop\", y = 'White')\n",
    "a.set(xlim=(0, 300000))\n",
    "r = np.corrcoef(data_new[[\"TotalPop\", \"White\"]].transpose())\n",
    "r[0,1]**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = data_new.plot.scatter(x= 'White', y = \"Black\")\n",
    "a\n",
    "r = np.corrcoef(data_new[['White', \"Black\"]].transpose())\n",
    "r[0,1]**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_new[['White']]\n",
    "Y = data_new[\"Unemployment\"]\n",
    "X = sm.add_constant(X)\n",
    "results3 = sm.OLS(Y,X).fit()\n",
    "print(results3.summary())\n",
    "#SSE = round(results3.ssr,3)\n",
    "#SSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = data_new.plot.scatter(x= 'Black', y = \"Native\")\n",
    "a\n",
    "r = np.corrcoef(data_new[['Black', \"Native\"]].transpose())\n",
    "r[0,1]**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_new[['Black']]\n",
    "Y = data_new[\"Unemployment\"]\n",
    "X = sm.add_constant(X)\n",
    "results3 = sm.OLS(Y,X).fit()\n",
    "print(results3.summary())\n",
    "#SSE = round(results3.ssr,3)\n",
    "#SSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_new[['Native']]\n",
    "Y = data_new[\"Unemployment\"]\n",
    "X = sm.add_constant(X)\n",
    "results3 = sm.OLS(Y,X).fit()\n",
    "print(results3.summary())\n",
    "#SSE = round(results3.ssr,3)\n",
    "#SSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = data_new.plot.scatter(x= \"Native\", y = \"Pacific\")\n",
    "a\n",
    "r = np.corrcoef(data_new[[\"Native\", \"Pacific\"]].transpose())\n",
    "r[0,1]**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_new[['Pacific']]\n",
    "Y = data_new[\"Unemployment\"]\n",
    "X = sm.add_constant(X)\n",
    "results3 = sm.OLS(Y,X).fit()\n",
    "print(results3.summary())\n",
    "#SSE = round(results3.ssr,3)\n",
    "#SSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = data_new.plot.scatter(x= \"Pacific\", y = \"Asian\")\n",
    "a\n",
    "r = np.corrcoef(data_new[[\"Pacific\", \"Asian\"]].transpose())\n",
    "r[0,1]**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_new[[\"Asian\"]]\n",
    "Y = data_new[\"Unemployment\"]\n",
    "X = sm.add_constant(X)\n",
    "results3 = sm.OLS(Y,X).fit()\n",
    "print(results3.summary())\n",
    "#SSE = round(results3.ssr,3)\n",
    "#SSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = data_new.plot.scatter(x= \"TotalPop\", y= \"Median Household Income\")\n",
    "a.set(xlim=(0, 30000))\n",
    "\n",
    "r = np.corrcoef(data_new[[\"TotalPop\", \"Median Household Income\"]].transpose())\n",
    "r[0,1]**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_new.plot.scatter(x= \"Median Household Income\", y = 'IncomePerCap')\n",
    "r = np.corrcoef(data_new[[\"Median Household Income\", 'IncomePerCap']].transpose())\n",
    "print(r[0,1]**2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_new.plot.scatter(x= \"Median Household Income\", y = 'Poverty')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_new.plot.scatter(x= 'IncomePerCap', y = 'Poverty')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_new[[\"Median Household Income\"]]\n",
    "Y = data_new[\"Unemployment\"]\n",
    "X = sm.add_constant(X)\n",
    "results3 = sm.OLS(Y,X).fit()\n",
    "print(results3.summary())\n",
    "#SSE = round(results3.ssr,3)\n",
    "#SSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_new[['IncomePerCap']]\n",
    "Y = data_new[\"Unemployment\"]\n",
    "X = sm.add_constant(X)\n",
    "results3 = sm.OLS(Y,X).fit()\n",
    "print(results3.summary())\n",
    "#SSE = round(results3.ssr,3)\n",
    "#SSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_new[['Poverty']]\n",
    "Y = data_new[\"Unemployment\"]\n",
    "X = sm.add_constant(X)\n",
    "results3 = sm.OLS(Y,X).fit()\n",
    "print(results3.summary())\n",
    "#SSE = round(results3.ssr,3)\n",
    "#SSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_new[['Poverty', 'IncomePerCap']]\n",
    "Y = data_new[\"Unemployment\"]\n",
    "X = sm.add_constant(X)\n",
    "results3 = sm.OLS(Y,X).fit()\n",
    "print(results3.summary())\n",
    "#SSE = round(results3.ssr,3)\n",
    "#SSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_new[['Poverty', \"Median Household Income\"]]\n",
    "Y = data_new[\"Unemployment\"]\n",
    "X = sm.add_constant(X)\n",
    "results3 = sm.OLS(Y,X).fit()\n",
    "print(results3.summary())\n",
    "#SSE = round(results3.ssr,3)\n",
    "#SSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_new[['Poverty', \"Median Household Income\", 'IncomePerCap']]\n",
    "Y = data_new[\"Unemployment\"]\n",
    "X = sm.add_constant(X)\n",
    "results3 = sm.OLS(Y,X).fit()\n",
    "print(results3.summary())\n",
    "#SSE = round(results3.ssr,3)\n",
    "#SSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The vaiables 'IncomePerCap' and 'Poverty' are not independent. \n",
    "# But the adj R2 value increased significantly \n",
    "# with the combination of \"Median Household Income\" and 'Poverty'\n",
    "# So, we have to keep both for the regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing \"IncomePerCap\"\n",
    "data_new.drop([\"IncomePerCap\"], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_new.plot.scatter(x= \"Median Household Income\", y = \"ChildPoverty\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_new[['ChildPoverty']]\n",
    "Y = data_new[\"Unemployment\"]\n",
    "X = sm.add_constant(X)\n",
    "results3 = sm.OLS(Y,X).fit()\n",
    "print(results3.summary())\n",
    "#SSE = round(results3.ssr,3)\n",
    "#SSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_new[['Poverty']]\n",
    "Y = data_new[\"Unemployment\"]\n",
    "X = sm.add_constant(X)\n",
    "results3 = sm.OLS(Y,X).fit()\n",
    "print(results3.summary())\n",
    "#SSE = round(results3.ssr,3)\n",
    "#SSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_new[['Poverty', \"ChildPoverty\"]]\n",
    "Y = data_new[\"Unemployment\"]\n",
    "X = sm.add_constant(X)\n",
    "results3 = sm.OLS(Y,X).fit()\n",
    "print(results3.summary())\n",
    "#SSE = round(results3.ssr,3)\n",
    "#SSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The vaiables \"Poverty\" and \"ChildPoverty\" are not independent. \n",
    "# But the adj R2 value haven't increased significantly with the inclusion of 'ChildPoverty'\n",
    "# So, we have to keep both for the regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_new['MCP'] = data_new[\"Median Household Income\"]*data_new[\"ChildPoverty\"]\n",
    "#removing \"ChildPoverty\"\n",
    "data_new.drop([\"ChildPoverty\"], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = data_new.plot.scatter(x= \"TotalPop\", y = 'Professional')\n",
    "a.set(xlim=(0, 30000))\n",
    "r = np.corrcoef(data_new[[\"TotalPop\", 'Professional']].transpose())\n",
    "print(r[0,1]**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_new.plot.scatter(x= \"Median Household Income\", y = 'Professional')\n",
    "r = np.corrcoef(data_new[[\"Median Household Income\", 'Professional']].transpose())\n",
    "print(r[0,1]**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_new[[\"Median Household Income\"]]\n",
    "Y = data_new[\"Unemployment\"]\n",
    "X = sm.add_constant(X)\n",
    "results3 = sm.OLS(Y,X).fit()\n",
    "print(results3.summary())\n",
    "#SSE = round(results3.ssr,3)\n",
    "#SSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_new[['Professional']]\n",
    "Y = data_new[\"Unemployment\"]\n",
    "X = sm.add_constant(X)\n",
    "results3 = sm.OLS(Y,X).fit()\n",
    "print(results3.summary())\n",
    "#SSE = round(results3.ssr,3)\n",
    "#SSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_new[[\"Median Household Income\",'Professional']]\n",
    "Y = data_new[\"Unemployment\"]\n",
    "X = sm.add_constant(X)\n",
    "results3 = sm.OLS(Y,X).fit()\n",
    "print(results3.summary())\n",
    "#SSE = round(results3.ssr,3)\n",
    "#SSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The vaiables \"Median Household Income\" and 'Professional' are not independent. \n",
    "# But the R2 value is not increased significantly for the combination of \"Median Household Income\" and 'Professional' \n",
    "# So, we have to include only \"Median Household Income\" for the the regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing 'Professional'\n",
    "data_new.drop(['Professional'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_new.plot.scatter(x= \"Median Household Income\", y = 'Service')\n",
    "r = np.corrcoef(data_new[[\"Median Household Income\", 'Service']].transpose())\n",
    "print(r[0,1]**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_new[['Service']]\n",
    "Y = data_new[\"Unemployment\"]\n",
    "X = sm.add_constant(X)\n",
    "results3 = sm.OLS(Y,X).fit()\n",
    "print(results3.summary())\n",
    "#SSE = round(results3.ssr,3)\n",
    "#SSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_new.plot.scatter(x= \"Median Household Income\", y = 'Office')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_new[['Office']]\n",
    "Y = data_new[\"Unemployment\"]\n",
    "X = sm.add_constant(X)\n",
    "results3 = sm.OLS(Y,X).fit()\n",
    "print(results3.summary())\n",
    "#SSE = round(results3.ssr,3)\n",
    "#SSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_new.plot.scatter(x= \"Median Household Income\", y = 'Construction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_new[['Construction']]\n",
    "Y = data_new[\"Unemployment\"]\n",
    "X = sm.add_constant(X)\n",
    "results3 = sm.OLS(Y,X).fit()\n",
    "print(results3.summary())\n",
    "#SSE = round(results3.ssr,3)\n",
    "#SSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_new.plot.scatter(x= \"Median Household Income\", y = 'Production')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_new[['Production']]\n",
    "Y = data_new[\"Unemployment\"]\n",
    "X = sm.add_constant(X)\n",
    "results3 = sm.OLS(Y,X).fit()\n",
    "print(results3.summary())\n",
    "#SSE = round(results3.ssr,3)\n",
    "#SSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_new.plot.scatter(x= \"Median Household Income\", y = 'Drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_new[['Drive']]\n",
    "Y = data_new[\"Unemployment\"]\n",
    "X = sm.add_constant(X)\n",
    "results3 = sm.OLS(Y,X).fit()\n",
    "print(results3.summary())\n",
    "#SSE = round(results3.ssr,3)\n",
    "#SSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_new.plot.scatter(x= \"Median Household Income\", y = 'Carpool')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_new[['Carpool']]\n",
    "Y = data_new[\"Unemployment\"]\n",
    "X = sm.add_constant(X)\n",
    "results3 = sm.OLS(Y,X).fit()\n",
    "print(results3.summary())\n",
    "#SSE = round(results3.ssr,3)\n",
    "#SSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_new.plot.scatter(x= \"Median Household Income\", y = 'Transit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_new[['Transit']]\n",
    "Y = data_new[\"Unemployment\"]\n",
    "X = sm.add_constant(X)\n",
    "results3 = sm.OLS(Y,X).fit()\n",
    "print(results3.summary())\n",
    "#SSE = round(results3.ssr,3)\n",
    "#SSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_new.plot.scatter(x= \"Median Household Income\", y = 'Walk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_new[['Walk']]\n",
    "Y = data_new[\"Unemployment\"]\n",
    "X = sm.add_constant(X)\n",
    "results3 = sm.OLS(Y,X).fit()\n",
    "print(results3.summary())\n",
    "#SSE = round(results3.ssr,3)\n",
    "#SSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_new.plot.scatter(x= \"Median Household Income\", y = 'WorkAtHome')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_new[['WorkAtHome']]\n",
    "Y = data_new[\"Unemployment\"]\n",
    "X = sm.add_constant(X)\n",
    "results3 = sm.OLS(Y,X).fit()\n",
    "print(results3.summary())\n",
    "#SSE = round(results3.ssr,3)\n",
    "#SSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_new.plot.scatter(x= \"Drive\", y = 'Mean Commute Time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_new[['Mean Commute Time']]\n",
    "Y = data_new[\"Unemployment\"]\n",
    "X = sm.add_constant(X)\n",
    "results3 = sm.OLS(Y,X).fit()\n",
    "print(results3.summary())\n",
    "#SSE = round(results3.ssr,3)\n",
    "#SSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_new.plot.scatter(x= \"Walk\", y = 'Mean Commute Time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = data_new.plot.scatter(x= 'TotalPop', y = 'State Unemployment rate for 2013')\n",
    "a.set(xlim=(0, 30000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_new[['State Unemployment rate for 2013']]\n",
    "Y = data_new[\"Unemployment\"]\n",
    "X = sm.add_constant(X)\n",
    "results3 = sm.OLS(Y,X).fit()\n",
    "print(results3.summary())\n",
    "#SSE = round(results3.ssr,3)\n",
    "#SSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = data_new.plot.scatter(x= 'TotalPop', y = 'County Unemployment Rate for 2013')\n",
    "a.set(xlim=(0, 30000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_new[['County Unemployment Rate for 2013']]\n",
    "Y = data_new[\"Unemployment\"]\n",
    "X = sm.add_constant(X)\n",
    "results3 = sm.OLS(Y,X).fit()\n",
    "print(results3.summary())\n",
    "#SSE = round(results3.ssr,3)\n",
    "#SSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_new.to_csv('Regression.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_new.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THe attributes 'County Unemployment Rate for 2013', 'State Unemployment rate for 2013', 'Poverty', \n",
    "# 'White', \"Median Household Income\", 'Black', and 'Service' are important variables for regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Original New dataset\n",
    "data_new  = pd.read_csv('New.csv')\n",
    "data_new.drop(['Unnamed: 0'], axis = 1, inplace = True)\n",
    "data_new.drop(['IncomeErr', 'IncomePerCapErr'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_new.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data3 = data_new.drop(['StateId','CensusId', 'State', 'County'], axis=1)\n",
    "#print(data3.groupby(\"Class\").describe())\n",
    "\n",
    "print(data_new.groupby(\"Class\").describe()[\"TotalPop\"])\n",
    "t = sns.boxplot(x = data_new[\"Class\"], y = data_new['TotalPop'], data = data_new)\n",
    "#plt.ylim(0, 6000000)\n",
    "print(t.set(ylim=(0, 300000)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_new.groupby(\"Class\").describe()[\"Percent Population with age between 16 and 44\"])\n",
    "t = sns.boxplot(x = data_new[\"Class\"], y = data_new['Percent Population with age between 16 and 44'], data = data_new)\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_new.groupby(\"Class\").describe()[\"Percent Population with age between 45 and 74\"])\n",
    "t = sns.boxplot(x = data_new[\"Class\"], y = data_new['Percent Population with age between 45 and 74'], data = data_new)\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_new.groupby(\"Class\").describe()[\"Percent Population with age between 75 and over\"])\n",
    "t = sns.boxplot(x = data_new[\"Class\"], y = data_new['Percent Population with age between 75 and over'], data = data_new)\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_new.groupby(\"Class\").describe()[\"Men\"])\n",
    "t = sns.boxplot(x = data_new[\"Class\"], y = data_new['Men'], data = data_new)\n",
    "print(t.set(ylim=(0, 100000)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_new.groupby(\"Class\").describe()[\"Women\"])\n",
    "t = sns.boxplot(x = data_new[\"Class\"], y = data_new['Women'], data = data_new)\n",
    "print(t.set(ylim=(0, 100000)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_new.groupby(\"Class\").describe()[\"Hispanic\"])\n",
    "t = sns.boxplot(x = data_new[\"Class\"], y = data_new['Hispanic'], data = data_new)\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_new.groupby(\"Class\").describe()[\"White\"])\n",
    "t = sns.boxplot(x = data_new[\"Class\"], y = data_new['White'], data = data_new)\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_new.groupby(\"Class\").describe()[\"Black\"])\n",
    "t = sns.boxplot(x = data_new[\"Class\"], y = data_new['Black'], data = data_new)\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_new.groupby(\"Class\").describe()[\"Native\"])\n",
    "t = sns.boxplot(x = data_new[\"Class\"], y = data_new['Native'], data = data_new)\n",
    "#print(t)\n",
    "print(t.set(ylim=(0, 5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_new.groupby(\"Class\").describe()[\"Asian\"])\n",
    "t = sns.boxplot(x = data_new[\"Class\"], y = data_new['Asian'], data = data_new)\n",
    "#print(t)\n",
    "print(t.set(ylim=(0, 5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_new.groupby(\"Class\").describe()[\"Pacific\"])\n",
    "t = sns.boxplot(x = data_new[\"Class\"], y = data_new['Pacific'], data = data_new)\n",
    "#print(t)\n",
    "print(t.set(ylim=(0, 5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_new.groupby(\"Class\").describe()[\"Citizen Voting Age Pop\"])\n",
    "t = sns.boxplot(x = data_new[\"Class\"], y = data_new['Citizen Voting Age Pop'], data = data_new)\n",
    "#print(t)\n",
    "print(t.set(ylim=(0, 400000)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_new.groupby(\"Class\").describe()[\"Median Household Income\"])\n",
    "t = sns.boxplot(x = data_new[\"Class\"], y = data_new[\"Median Household Income\"], data = data_new)\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_new.groupby(\"Class\").describe()[\"IncomePerCap\"])\n",
    "t = sns.boxplot(x = data_new[\"Class\"], y = data_new[\"IncomePerCap\"], data = data_new)\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_new.groupby(\"Class\").describe()['Poverty'])\n",
    "t = sns.boxplot(x = data_new[\"Class\"], y = data_new['Poverty'], data = data_new)\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_new.groupby(\"Class\").describe()['ChildPoverty'])\n",
    "t = sns.boxplot(x = data_new[\"Class\"], y = data_new['ChildPoverty'], data = data_new)\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_new.groupby(\"Class\").describe()['Professional'])\n",
    "t = sns.boxplot(x = data_new[\"Class\"], y = data_new['Professional'], data = data_new)\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_new.groupby(\"Class\").describe()['Service'])\n",
    "t = sns.boxplot(x = data_new[\"Class\"], y = data_new['Service'], data = data_new)\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_new.groupby(\"Class\").describe()['Office'])\n",
    "t = sns.boxplot(x = data_new[\"Class\"], y = data_new['Office'], data = data_new)\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_new.groupby(\"Class\").describe()['Construction'])\n",
    "t = sns.boxplot(x = data_new[\"Class\"], y = data_new['Construction'], data = data_new)\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_new.groupby(\"Class\").describe()['Production'])\n",
    "t = sns.boxplot(x = data_new[\"Class\"], y = data_new['Production'], data = data_new)\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_new.groupby(\"Class\").describe()['Drive'])\n",
    "t = sns.boxplot(x = data_new[\"Class\"], y = data_new['Drive'], data = data_new)\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_new.groupby(\"Class\").describe()['Carpool'])\n",
    "t = sns.boxplot(x = data_new[\"Class\"], y = data_new['Carpool'], data = data_new)\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_new.groupby(\"Class\").describe()['Transit'])\n",
    "t = sns.boxplot(x = data_new[\"Class\"], y = data_new['Transit'], data = data_new)\n",
    "print(t.set(ylim=(0, 5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_new.groupby(\"Class\").describe()['Walk'])\n",
    "t = sns.boxplot(x = data_new[\"Class\"], y = data_new['Walk'], data = data_new)\n",
    "print(t.set(ylim=(0, 10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_new.groupby(\"Class\").describe()['WorkAtHome'])\n",
    "t = sns.boxplot(x = data_new[\"Class\"], y = data_new['WorkAtHome'], data = data_new)\n",
    "print(t.set(ylim=(0, 15)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_new.groupby(\"Class\").describe()['Mean Commute Time'])\n",
    "t = sns.boxplot(x = data_new[\"Class\"], y = data_new['Mean Commute Time'], data = data_new)\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_new.groupby(\"Class\").describe()['State Unemployment rate for 2013'])\n",
    "t = sns.boxplot(x = data_new[\"Class\"], y = data_new['State Unemployment rate for 2013'], data = data_new)\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_new.groupby(\"Class\").describe()['County Unemployment Rate for 2013'])\n",
    "t = sns.boxplot(x = data_new[\"Class\"], y = data_new['County Unemployment Rate for 2013'], data = data_new)\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_new.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_new.to_csv(\"Classification.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The variables 'TotalPop', 'Men;, White', 'Black','Citizen Voting Age Pop', 'Median Household Income', \n",
    "#               'IncomePerCap', 'Poverty', 'ChildPoverty', 'County Unemployment Rate for 2013' \n",
    "#                are the important attributes to determine the class of a county"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_new['Class'][data_new['Class'] == 1] = \"Lowest\"\n",
    "data_new['Class'][data_new['Class'] == 2] = \"Moderate\"\n",
    "data_new['Class'][data_new['Class'] == 3] = \"Highest\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regression Model\n",
    "\n",
    "dataR = pd.read_csv(\"Regression.csv\")\n",
    "dataR.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataR.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataR.drop(\"Unnamed: 0\", axis = 1 , inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataR.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TASK 1\n",
    "X_train, X_val= train_test_split(dataR, test_size = 0.2, random_state = 1)\n",
    "x_train = X_train.iloc[:,4:28]\n",
    "x_val =   X_val.iloc[:,4:28]                                             \n",
    "y_train = X_train.iloc[:,28:29]\n",
    "y_val = X_val.iloc[:,28:29]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TASK 1\n",
    "\"\"\"X_train, X_test= train_test_split(dataR, test_size = 0.2, random_state = 1)\n",
    "X_train, X_val= train_test_split(X_train, test_size = 0.2, random_state = 1)\n",
    "x_train = X_train.iloc[:,4:28]\n",
    "x_val =   X_val.iloc[:,4:28]                                             \n",
    "y_train = X_train.iloc[:,28:29]\n",
    "y_val = X_val.iloc[:,28:29]\n",
    "x_test = X_test.iloc[:,4:28]\n",
    "y_test = X_test.iloc[:,28:29]\n",
    "\n",
    "x_val.info()\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_train.info()\n",
    "#y_train.info()\n",
    "x_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "x_train[['TotalPop', 'Percent Population with age between 16 and 44',\n",
    "       'Percent Population with age between 45 and 74',\n",
    "       'Percent Population with age between 75 and over', 'Hispanic', 'White',\n",
    "       'Black', 'Native', 'Asian', 'Pacific', 'Median Household Income',\n",
    "       'Poverty', 'Service', 'Office', 'Construction', 'Production', 'Drive',\n",
    "       'Carpool', 'Transit', 'Walk', 'WorkAtHome', 'Mean Commute Time',\n",
    "       'State Unemployment rate for 2013',\n",
    "       'County Unemployment Rate for 2013']] = scaler.fit_transform(x_train[['TotalPop', 'Percent Population with age between 16 and 44',\n",
    "       'Percent Population with age between 45 and 74',\n",
    "       'Percent Population with age between 75 and over', 'Hispanic', 'White',\n",
    "       'Black', 'Native', 'Asian', 'Pacific', 'Median Household Income',\n",
    "       'Poverty', 'Service', 'Office', 'Construction', 'Production', 'Drive',\n",
    "       'Carpool', 'Transit', 'Walk', 'WorkAtHome', 'Mean Commute Time',\n",
    "       'State Unemployment rate for 2013',\n",
    "       'County Unemployment Rate for 2013']])\n",
    "\n",
    "x_val[['TotalPop', 'Percent Population with age between 16 and 44',\n",
    "       'Percent Population with age between 45 and 74',\n",
    "       'Percent Population with age between 75 and over', 'Hispanic', 'White',\n",
    "       'Black', 'Native', 'Asian', 'Pacific', 'Median Household Income',\n",
    "       'Poverty', 'Service', 'Office', 'Construction', 'Production', 'Drive',\n",
    "       'Carpool', 'Transit', 'Walk', 'WorkAtHome', 'Mean Commute Time',\n",
    "       'State Unemployment rate for 2013',\n",
    "       'County Unemployment Rate for 2013']] = scaler.fit_transform(x_val[['TotalPop', 'Percent Population with age between 16 and 44',\n",
    "       'Percent Population with age between 45 and 74',\n",
    "       'Percent Population with age between 75 and over', 'Hispanic', 'White',\n",
    "       'Black', 'Native', 'Asian', 'Pacific', 'Median Household Income',\n",
    "       'Poverty', 'Service', 'Office', 'Construction', 'Production', 'Drive',\n",
    "       'Carpool', 'Transit', 'Walk', 'WorkAtHome', 'Mean Commute Time',\n",
    "       'State Unemployment rate for 2013',\n",
    "       'County Unemployment Rate for 2013']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Build model with 1 predictor (using statsmodels)\n",
    "X = x_train[\"Poverty\"] \n",
    "Y = y_train[\"Unemployment\"]\n",
    "X = sm.add_constant(X)\n",
    "results = sm.OLS(Y,X).fit()\n",
    "print(results.summary())\n",
    "#SSE = round(results.ssr,3)\n",
    "#SSE\n",
    "\n",
    "# Checking the model with y_val\n",
    "X = sm.add_constant(x_val[[\"Poverty\"]])\n",
    "y_pred = results.predict(X)\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import explained_variance_score\n",
    "MSE = mean_squared_error(y_val[\"Unemployment\"], y_pred)\n",
    "MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Build model with 2 predictors (using statsmodels)\n",
    "X = x_train[[\"Poverty\", 'White']] \n",
    "Y = y_train[\"Unemployment\"]\n",
    "X = sm.add_constant(X)\n",
    "results = sm.OLS(Y,X).fit()\n",
    "print(results.summary())\n",
    "#SSE = round(results.ssr,3)\n",
    "#SSE\n",
    "\n",
    "# Checking the model with y_val\n",
    "X = sm.add_constant(x_val[[\"Poverty\", 'White']])\n",
    "y_pred = results.predict(X)\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import explained_variance_score\n",
    "MSE = mean_squared_error(y_val[\"Unemployment\"], y_pred)\n",
    "MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Build model with 3 predictors (using statsmodels)\n",
    "X = x_train[[\"Poverty\", 'White', \"Median Household Income\"]] \n",
    "Y = y_train[\"Unemployment\"]\n",
    "X = sm.add_constant(X)\n",
    "results = sm.OLS(Y,X).fit()\n",
    "print(results.summary())\n",
    "#SSE = round(results.ssr,3)\n",
    "#SSE\n",
    "\n",
    "# Checking the model with y_val\n",
    "X = sm.add_constant(x_val[[\"Poverty\", 'White', \"Median Household Income\"]])\n",
    "y_pred = results.predict(X)\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import explained_variance_score\n",
    "MSE = mean_squared_error(y_val[\"Unemployment\"], y_pred)\n",
    "MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Build model with 3 predictors (using statsmodels)\n",
    "X = x_train[[\"Poverty\", 'White', \"Black\"]] \n",
    "Y = y_train[\"Unemployment\"]\n",
    "X = sm.add_constant(X)\n",
    "results = sm.OLS(Y,X).fit()\n",
    "print(results.summary())\n",
    "#SSE = round(results.ssr,3)\n",
    "#SSE\n",
    "\n",
    "# Checking the model with y_val\n",
    "X = sm.add_constant(x_val[[\"Poverty\", 'White', \"Black\"]])\n",
    "y_pred = results.predict(X)\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import explained_variance_score\n",
    "MSE = mean_squared_error(y_val[\"Unemployment\"], y_pred)\n",
    "MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Build model with 3 predictors (using statsmodels)\n",
    "X = x_train[[\"Poverty\", 'White', \"Black\",\"Service\"]] \n",
    "Y = y_train[\"Unemployment\"]\n",
    "X = sm.add_constant(X)\n",
    "results = sm.OLS(Y,X).fit()\n",
    "print(results.summary())\n",
    "#SSE = round(results.ssr,3)\n",
    "#SSE\n",
    "\n",
    "# Checking the model with y_val\n",
    "X = sm.add_constant(x_val[[\"Poverty\", 'White', \"Black\", \"Service\"]])\n",
    "y_pred = results.predict(X)\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import explained_variance_score\n",
    "MSE = mean_squared_error(y_val[\"Unemployment\"], y_pred)\n",
    "MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Build model with 4 predictors (using statsmodels)\n",
    "X = x_train[[\"Poverty\", 'White', \"Black\",\"Service\", \"WorkAtHome\"]] \n",
    "Y = y_train[\"Unemployment\"]\n",
    "X = sm.add_constant(X)\n",
    "results = sm.OLS(Y,X).fit()\n",
    "print(results.summary())\n",
    "#SSE = round(results.ssr,3)\n",
    "#SSE\n",
    "\n",
    "# Checking the model with y_val\n",
    "X = sm.add_constant(x_val[[\"Poverty\", 'White', \"Black\", \"Service\", \"WorkAtHome\"]])\n",
    "y_pred = results.predict(X)\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import explained_variance_score\n",
    "MSE = mean_squared_error(y_val[\"Unemployment\"], y_pred)\n",
    "MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Build model with 5 predictors (using statsmodels)\n",
    "X = x_train[[\"Poverty\", 'White', \"Black\",\"Service\", \"WorkAtHome\", \"Hispanic\"]] \n",
    "Y = y_train[\"Unemployment\"]\n",
    "X = sm.add_constant(X)\n",
    "results = sm.OLS(Y,X).fit()\n",
    "print(results.summary())\n",
    "#SSE = round(results.ssr,3)\n",
    "#SSE\n",
    "\n",
    "# Checking the model with y_val\n",
    "X = sm.add_constant(x_val[[\"Poverty\", 'White', \"Black\", \"Service\", \"WorkAtHome\", \"Hispanic\"]])\n",
    "y_pred = results.predict(X)\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import explained_variance_score\n",
    "MSE = mean_squared_error(y_val[\"Unemployment\"], y_pred)\n",
    "MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Build model with 6 predictors (using statsmodels)\n",
    "X = x_train[[\"Poverty\", 'White', \"Black\",\"Service\", \"WorkAtHome\", \"Hispanic\", 'Mean Commute Time']] \n",
    "Y = y_train[\"Unemployment\"]\n",
    "X = sm.add_constant(X)\n",
    "results = sm.OLS(Y,X).fit()\n",
    "print(results.summary())\n",
    "#SSE = round(results.ssr,3)\n",
    "#SSE\n",
    "\n",
    "# Checking the model with y_val\n",
    "X = sm.add_constant(x_val[[\"Poverty\", 'White', \"Black\", \"Service\", \"WorkAtHome\", \"Hispanic\", 'Mean Commute Time']])\n",
    "y_pred = results.predict(X)\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import explained_variance_score\n",
    "MSE = mean_squared_error(y_val[\"Unemployment\"], y_pred)\n",
    "MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Build model with 7 predictors (using statsmodels)\n",
    "X = x_train[[\"Poverty\", 'White', \"Black\",\"Service\", \"WorkAtHome\", \"Hispanic\", 'Mean Commute Time', \n",
    "             \"Percent Population with age between 75 and over\"]] \n",
    "Y = y_train[\"Unemployment\"]\n",
    "X = sm.add_constant(X)\n",
    "results = sm.OLS(Y,X).fit()\n",
    "print(results.summary())\n",
    "#SSE = round(results.ssr,3)\n",
    "#SSE\n",
    "\n",
    "# Checking the model with y_val\n",
    "X = sm.add_constant(x_val[[\"Poverty\", 'White', \"Black\", \"Service\", \"WorkAtHome\", \"Hispanic\", 'Mean Commute Time', \n",
    "                           \"Percent Population with age between 75 and over\"]])\n",
    "y_pred = results.predict(X)\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import explained_variance_score\n",
    "MSE = mean_squared_error(y_val[\"Unemployment\"], y_pred)\n",
    "MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Build model with 7 predictors (using statsmodels)\n",
    "X = x_train[[\"Poverty\", 'White', \"Black\",\"Service\", \"WorkAtHome\", \"Hispanic\", 'Mean Commute Time', \n",
    "             \"Percent Population with age between 16 and 44\"]] \n",
    "Y = y_train[\"Unemployment\"]\n",
    "X = sm.add_constant(X)\n",
    "results = sm.OLS(Y,X).fit()\n",
    "print(results.summary())\n",
    "#SSE = round(results.ssr,3)\n",
    "#SSE\n",
    "\n",
    "# Checking the model with y_val\n",
    "X = sm.add_constant(x_val[[\"Poverty\", 'White', \"Black\", \"Service\", \"WorkAtHome\", \"Hispanic\", 'Mean Commute Time', \n",
    "                           \"Percent Population with age between 16 and 44\"]])\n",
    "y_pred = results.predict(X)\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import explained_variance_score\n",
    "MSE = mean_squared_error(y_val[\"Unemployment\"], y_pred)\n",
    "MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Build model with 8 predictors (using statsmodels)\n",
    "X = x_train[[\"Poverty\", 'White', \"Black\",\"Service\", \"WorkAtHome\", \"Hispanic\", 'Mean Commute Time', \n",
    "             \"Percent Population with age between 16 and 44\", \"Percent Population with age between 45 and 74\"]] \n",
    "Y = y_train[\"Unemployment\"]\n",
    "X = sm.add_constant(X)\n",
    "results = sm.OLS(Y,X).fit()\n",
    "print(results.summary())\n",
    "#SSE = round(results.ssr,3)\n",
    "#SSE\n",
    "\n",
    "# Checking the model with y_val\n",
    "X = sm.add_constant(x_val[[\"Poverty\", 'White', \"Black\", \"Service\", \"WorkAtHome\", \"Hispanic\", 'Mean Commute Time', \n",
    "                           \"Percent Population with age between 16 and 44\", \"Percent Population with age between 45 and 74\"]])\n",
    "y_pred = results.predict(X)\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import explained_variance_score\n",
    "MSE = mean_squared_error(y_val[\"Unemployment\"], y_pred)\n",
    "MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Build model with 8 predictors (using statsmodels)\n",
    "X = x_train[[\"Poverty\", 'White', \"Black\",\"Service\", \"WorkAtHome\", \"Hispanic\", 'Mean Commute Time', \n",
    "             \"Percent Population with age between 16 and 44\", \"TotalPop\"]] \n",
    "Y = y_train[\"Unemployment\"]\n",
    "X = sm.add_constant(X)\n",
    "results = sm.OLS(Y,X).fit()\n",
    "print(results.summary())\n",
    "#SSE = round(results.ssr,3)\n",
    "#SSE\n",
    "\n",
    "# Checking the model with y_val\n",
    "X = sm.add_constant(x_val[[\"Poverty\", 'White', \"Black\", \"Service\", \"WorkAtHome\", \"Hispanic\", 'Mean Commute Time', \n",
    "                           \"Percent Population with age between 16 and 44\", \"TotalPop\"]])\n",
    "y_pred = results.predict(X)\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import explained_variance_score\n",
    "MSE = mean_squared_error(y_val[\"Unemployment\"], y_pred)\n",
    "MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Build model with 8 predictors (using statsmodels)\n",
    "X = x_train[[\"Poverty\", 'White', \"Black\",\"Service\", \"WorkAtHome\", \"Hispanic\", 'Mean Commute Time', \n",
    "             \"Percent Population with age between 16 and 44\", 'Native']] \n",
    "Y = y_train[\"Unemployment\"]\n",
    "X = sm.add_constant(X)\n",
    "results = sm.OLS(Y,X).fit()\n",
    "print(results.summary())\n",
    "#SSE = round(results.ssr,3)\n",
    "#SSE\n",
    "\n",
    "# Checking the model with y_val\n",
    "X = sm.add_constant(x_val[[\"Poverty\", 'White', \"Black\", \"Service\", \"WorkAtHome\", \"Hispanic\", 'Mean Commute Time', \n",
    "                           \"Percent Population with age between 16 and 44\", 'Native']])\n",
    "y_pred = results.predict(X)\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import explained_variance_score\n",
    "MSE = mean_squared_error(y_val[\"Unemployment\"], y_pred)\n",
    "MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Build model with 8 predictors (using statsmodels)\n",
    "X = x_train[[\"Poverty\", 'White', \"Black\",\"Service\", \"WorkAtHome\", \"Hispanic\", 'Mean Commute Time', \n",
    "             \"Percent Population with age between 16 and 44\", 'Asian']] \n",
    "Y = y_train[\"Unemployment\"]\n",
    "X = sm.add_constant(X)\n",
    "results = sm.OLS(Y,X).fit()\n",
    "print(results.summary())\n",
    "#SSE = round(results.ssr,3)\n",
    "#SSE\n",
    "\n",
    "# Checking the model with y_val\n",
    "X = sm.add_constant(x_val[[\"Poverty\", 'White', \"Black\", \"Service\", \"WorkAtHome\", \"Hispanic\", 'Mean Commute Time', \n",
    "                           \"Percent Population with age between 16 and 44\", 'Asian']])\n",
    "y_pred = results.predict(X)\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import explained_variance_score\n",
    "MSE = mean_squared_error(y_val[\"Unemployment\"], y_pred)\n",
    "MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Build model with 9 predictors (using statsmodels)\n",
    "X = x_train[[\"Poverty\", 'White', \"Black\",\"Service\", \"WorkAtHome\", \"Hispanic\", 'Mean Commute Time', \n",
    "             \"Percent Population with age between 16 and 44\", 'Asian', 'Pacific']] \n",
    "Y = y_train[\"Unemployment\"]\n",
    "X = sm.add_constant(X)\n",
    "results = sm.OLS(Y,X).fit()\n",
    "print(results.summary())\n",
    "#SSE = round(results.ssr,3)\n",
    "#SSE\n",
    "\n",
    "# Checking the model with y_val\n",
    "X = sm.add_constant(x_val[[\"Poverty\", 'White', \"Black\", \"Service\", \"WorkAtHome\", \"Hispanic\", 'Mean Commute Time', \n",
    "                           \"Percent Population with age between 16 and 44\", 'Asian', 'Pacific']])\n",
    "y_pred = results.predict(X)\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import explained_variance_score\n",
    "MSE = mean_squared_error(y_val[\"Unemployment\"], y_pred)\n",
    "MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Build model with 9 predictors (using statsmodels)\n",
    "X = x_train[[\"Poverty\", 'White', \"Black\",\"Service\", \"WorkAtHome\", \"Hispanic\", 'Mean Commute Time', \n",
    "             \"Percent Population with age between 16 and 44\", 'Asian', 'Office']] \n",
    "Y = y_train[\"Unemployment\"]\n",
    "X = sm.add_constant(X)\n",
    "results = sm.OLS(Y,X).fit()\n",
    "print(results.summary())\n",
    "#SSE = round(results.ssr,3)\n",
    "#SSE\n",
    "\n",
    "# Checking the model with y_val\n",
    "X = sm.add_constant(x_val[[\"Poverty\", 'White', \"Black\", \"Service\", \"WorkAtHome\", \"Hispanic\", 'Mean Commute Time', \n",
    "                           \"Percent Population with age between 16 and 44\", 'Asian','Office']])\n",
    "y_pred = results.predict(X)\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import explained_variance_score\n",
    "MSE = mean_squared_error(y_val[\"Unemployment\"], y_pred)\n",
    "MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Build model with 10 predictors (using statsmodels)\n",
    "X = x_train[[\"Poverty\", 'White', \"Black\",\"Service\", \"WorkAtHome\", \"Hispanic\", 'Mean Commute Time', \n",
    "             \"Percent Population with age between 16 and 44\", 'Asian', 'Office', 'Construction']] \n",
    "Y = y_train[\"Unemployment\"]\n",
    "X = sm.add_constant(X)\n",
    "results = sm.OLS(Y,X).fit()\n",
    "print(results.summary())\n",
    "#SSE = round(results.ssr,3)\n",
    "#SSE\n",
    "\n",
    "# Checking the model with y_val\n",
    "X = sm.add_constant(x_val[[\"Poverty\", 'White', \"Black\", \"Service\", \"WorkAtHome\", \"Hispanic\", 'Mean Commute Time', \n",
    "                           \"Percent Population with age between 16 and 44\", 'Asian','Office', 'Construction']])\n",
    "y_pred = results.predict(X)\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import explained_variance_score\n",
    "MSE = mean_squared_error(y_val[\"Unemployment\"], y_pred)\n",
    "MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Build model with 11 predictors (using statsmodels)\n",
    "X = x_train[[\"Poverty\", 'White', \"Black\",\"Service\", \"WorkAtHome\", \"Hispanic\", 'Mean Commute Time', \n",
    "             \"Percent Population with age between 16 and 44\", 'Asian', 'Office', 'Construction', 'Production']] \n",
    "Y = y_train[\"Unemployment\"]\n",
    "X = sm.add_constant(X)\n",
    "results = sm.OLS(Y,X).fit()\n",
    "print(results.summary())\n",
    "#SSE = round(results.ssr,3)\n",
    "#SSE\n",
    "\n",
    "# Checking the model with y_val\n",
    "X = sm.add_constant(x_val[[\"Poverty\", 'White', \"Black\", \"Service\", \"WorkAtHome\", \"Hispanic\", 'Mean Commute Time', \n",
    "                           \"Percent Population with age between 16 and 44\", 'Asian','Office', 'Construction','Production']])\n",
    "y_pred = results.predict(X)\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import explained_variance_score\n",
    "MSE = mean_squared_error(y_val[\"Unemployment\"], y_pred)\n",
    "MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Build model with 11 predictors (using statsmodels)\n",
    "X = x_train[[\"Poverty\", 'White', \"Black\",\"Service\", \"WorkAtHome\", \"Hispanic\", 'Mean Commute Time', \n",
    "             \"Percent Population with age between 16 and 44\", 'Asian', 'Office', 'Construction', 'Drive']] \n",
    "Y = y_train[\"Unemployment\"]\n",
    "X = sm.add_constant(X)\n",
    "results = sm.OLS(Y,X).fit()\n",
    "print(results.summary())\n",
    "#SSE = round(results.ssr,3)\n",
    "#SSE\n",
    "\n",
    "# Checking the model with y_val\n",
    "X = sm.add_constant(x_val[[\"Poverty\", 'White', \"Black\", \"Service\", \"WorkAtHome\", \"Hispanic\", 'Mean Commute Time', \n",
    "                           \"Percent Population with age between 16 and 44\", 'Asian','Office', 'Construction','Drive']])\n",
    "y_pred = results.predict(X)\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import explained_variance_score\n",
    "MSE = mean_squared_error(y_val[\"Unemployment\"], y_pred)\n",
    "MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Build model with 12 predictors (using statsmodels)\n",
    "X = x_train[[\"Poverty\", 'White', \"Black\",\"Service\", \"WorkAtHome\", \"Hispanic\", 'Mean Commute Time', \n",
    "             \"Percent Population with age between 16 and 44\", 'Asian', 'Office', 'Construction', 'Drive', 'Carpool']] \n",
    "Y = y_train[\"Unemployment\"]\n",
    "X = sm.add_constant(X)\n",
    "results = sm.OLS(Y,X).fit()\n",
    "print(results.summary())\n",
    "#SSE = round(results.ssr,3)\n",
    "#SSE\n",
    "\n",
    "# Checking the model with y_val\n",
    "X = sm.add_constant(x_val[[\"Poverty\", 'White', \"Black\", \"Service\", \"WorkAtHome\", \"Hispanic\", 'Mean Commute Time', \n",
    "                           \"Percent Population with age between 16 and 44\", 'Asian','Office', 'Construction','Drive', 'Carpool']])\n",
    "y_pred = results.predict(X)\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import explained_variance_score\n",
    "MSE = mean_squared_error(y_val[\"Unemployment\"], y_pred)\n",
    "MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Build model with 12 predictors (using statsmodels)\n",
    "X = x_train[[\"Poverty\", 'White', \"Black\",\"Service\", \"WorkAtHome\", \"Hispanic\", 'Mean Commute Time', \n",
    "             \"Percent Population with age between 16 and 44\", 'Asian', 'Office', 'Construction', 'Drive', 'Transit']] \n",
    "Y = y_train[\"Unemployment\"]\n",
    "X = sm.add_constant(X)\n",
    "results = sm.OLS(Y,X).fit()\n",
    "print(results.summary())\n",
    "#SSE = round(results.ssr,3)\n",
    "#SSE\n",
    "\n",
    "# Checking the model with y_val\n",
    "X = sm.add_constant(x_val[[\"Poverty\", 'White', \"Black\", \"Service\", \"WorkAtHome\", \"Hispanic\", 'Mean Commute Time', \n",
    "                           \"Percent Population with age between 16 and 44\", 'Asian','Office', 'Construction','Drive', 'Transit']])\n",
    "y_pred = results.predict(X)\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import explained_variance_score\n",
    "MSE = mean_squared_error(y_val[\"Unemployment\"], y_pred)\n",
    "MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Build model with 13 predictors (using statsmodels)\n",
    "X = x_train[[\"Poverty\", 'White', \"Black\",\"Service\", \"WorkAtHome\", \"Hispanic\", 'Mean Commute Time', \n",
    "             \"Percent Population with age between 16 and 44\", 'Asian', 'Office', 'Construction', 'Drive', 'Transit', \n",
    "             'Walk']] \n",
    "Y = y_train[\"Unemployment\"]\n",
    "X = sm.add_constant(X)\n",
    "results = sm.OLS(Y,X).fit()\n",
    "print(results.summary())\n",
    "#SSE = round(results.ssr,3)\n",
    "#SSE\n",
    "\n",
    "# Checking the model with y_val\n",
    "X = sm.add_constant(x_val[[\"Poverty\", 'White', \"Black\", \"Service\", \"WorkAtHome\", \"Hispanic\", 'Mean Commute Time', \n",
    "                           \"Percent Population with age between 16 and 44\", 'Asian','Office', 'Construction','Drive', 'Transit', \n",
    "                           'Walk']])\n",
    "y_pred = results.predict(X)\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import explained_variance_score\n",
    "MSE = mean_squared_error(y_val[\"Unemployment\"], y_pred)\n",
    "MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Build model with 13 predictors (using statsmodels)\n",
    "X = x_train[[\"Poverty\", 'White', \"Black\",\"Service\", \"WorkAtHome\", \"Hispanic\", 'Mean Commute Time', \n",
    "             \"Percent Population with age between 16 and 44\", 'Asian', 'Office', 'Construction', 'Drive', 'Transit',\n",
    "            \"State Unemployment rate for 2013\"]] \n",
    "Y = y_train[\"Unemployment\"]\n",
    "X = sm.add_constant(X)\n",
    "results = sm.OLS(Y,X).fit()\n",
    "print(results.summary())\n",
    "#SSE = round(results.ssr,3)\n",
    "#SSE\n",
    "\n",
    "# Checking the model with y_val\n",
    "X = sm.add_constant(x_val[[\"Poverty\", 'White', \"Black\", \"Service\", \"WorkAtHome\", \"Hispanic\", 'Mean Commute Time', \n",
    "                           \"Percent Population with age between 16 and 44\", 'Asian','Office', 'Construction','Drive', 'Transit',\n",
    "                          \"State Unemployment rate for 2013\"]])\n",
    "y_pred = results.predict(X)\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import explained_variance_score\n",
    "MSE = mean_squared_error(y_val[\"Unemployment\"], y_pred)\n",
    "MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Build model with 14 predictors (using statsmodels)\n",
    "X = x_train[[\"Poverty\", 'White', \"Black\",\"Service\", \"WorkAtHome\", \"Hispanic\", 'Mean Commute Time', \n",
    "             \"Percent Population with age between 16 and 44\", 'Asian', 'Office', 'Construction', 'Drive', 'Transit',\n",
    "            \"State Unemployment rate for 2013\", \"County Unemployment Rate for 2013\"]] \n",
    "Y = y_train[\"Unemployment\"]\n",
    "X = sm.add_constant(X)\n",
    "results = sm.OLS(Y,X).fit()\n",
    "print(results.summary())\n",
    "#SSE = round(results.ssr,3)\n",
    "#SSE\n",
    "\n",
    "# Checking the model with y_val\n",
    "X = sm.add_constant(x_val[[\"Poverty\", 'White', \"Black\", \"Service\", \"WorkAtHome\", \"Hispanic\", 'Mean Commute Time', \n",
    "                           \"Percent Population with age between 16 and 44\", 'Asian','Office', 'Construction','Drive', 'Transit',\n",
    "                          \"State Unemployment rate for 2013\", \"County Unemployment Rate for 2013\"]])\n",
    "y_pred = results.predict(X)\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import explained_variance_score\n",
    "MSE = mean_squared_error(y_val[\"Unemployment\"], y_pred)\n",
    "MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The regression model with the predictors \"Poverty\", 'White', \"Black\", \"Service\", \"WorkAtHome\", \"Hispanic\", 'Mean Commute Time', \n",
    "#                           \"Percent Population with age between 16 and 44\", 'Asian','Office', 'Construction','Drive', 'Transit',\n",
    "#                          \"State Unemployment rate for 2013\", \"County Unemployment Rate for 2013\"\n",
    "# is the best model with adj R2 value of 0.839, R2 value of 0.840 and Root mean square error of 3.04"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Reg = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting 2017 unemploymnet rates\n",
    "\n",
    "data2017 = pd.read_csv(\"US Demographic Data 2017.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp2017 = pd.read_csv(\"Temp2017.csv\")\n",
    "temp2017.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2017['Percent Population with age between 16 and 44'] = temp2017['Percent Population with age between 16 and 44']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2017['Percent Population with age between 45 and 74'] = temp2017['Percent Population with age between 45 and 74']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2017['Percent Population with age between 75 and over'] = temp2017['Percent Population with age between 75 and over']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2017.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2017.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "se1  = pd.read_csv('State Unemployment rate 2015.csv')\n",
    "ce1 = pd.read_csv('County Unemployment rate 2015.csv')\n",
    "ce1.info()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d2 = pd.merge(data2017, se1, how=\"inner\", on = 'State')\n",
    "d2.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd = pd.merge(d2, ce1, how=\"inner\", on = ['CountyId'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dd[['StateId','CountyId', 'State', 'County', 'TotalPop', 'Percent Population with age between 16 and 44',\n",
    "       'Percent Population with age between 45 and 74',\n",
    "       'Percent Population with age between 75 and over','Men', 'Women', 'Hispanic',\n",
    "       'White', 'Black', 'Native', 'Asian', 'Pacific', 'Citizen Voting Age Pop', 'Median Household Income',\n",
    "       'IncomeErr', 'IncomePerCap', 'IncomePerCapErr', 'Poverty',\n",
    "       'ChildPoverty', 'Professional', 'Service', 'Office', 'Construction',\n",
    "       'Production', 'Drive', 'Carpool', 'Transit', 'Walk', 'OtherTransp',\n",
    "       'WorkAtHome', 'Mean Commute Time',\n",
    "       'State Unemployment rate for 2015', 'County Unemployment Rate for 2015', \n",
    "   'Unemployment']] = dd[['StateId','CountyId', 'State', 'County_x', 'TotalPop', 'Percent Population with age between 16 and 44',\n",
    "       'Percent Population with age between 45 and 74',\n",
    "       'Percent Population with age between 75 and over', 'Men', 'Women', 'Hispanic',\n",
    "       'White', 'Black', 'Native', 'Asian', 'Pacific', 'VotingAgeCitizen', 'Income',\n",
    "       'IncomeErr', 'IncomePerCap', 'IncomePerCapErr', 'Poverty',\n",
    "       'ChildPoverty', 'Professional', 'Service', 'Office', 'Construction',\n",
    "       'Production', 'Drive', 'Carpool', 'Transit', 'Walk', 'OtherTransp',\n",
    "       'WorkAtHome', 'MeanCommute',\n",
    "       'State Unemployment rate', 'County Unemployment rate 2015', 'Unemployment']]\n",
    "\n",
    "\n",
    "dataN2017 = dd[['StateId','CountyId', 'State', 'County', 'TotalPop', 'Percent Population with age between 16 and 44',\n",
    "       'Percent Population with age between 45 and 74',\n",
    "       'Percent Population with age between 75 and over','Men', 'Women', 'Hispanic',\n",
    "       'White', 'Black', 'Native', 'Asian', 'Pacific', 'Citizen Voting Age Pop', 'Median Household Income',\n",
    "       'IncomeErr', 'IncomePerCap', 'IncomePerCapErr', 'Poverty',\n",
    "       'ChildPoverty', 'Professional', 'Service', 'Office', 'Construction',\n",
    "       'Production', 'Drive', 'Carpool', 'Transit', 'Walk', 'OtherTransp',\n",
    "       'WorkAtHome', 'Mean Commute Time',\n",
    "       'State Unemployment rate for 2015', 'County Unemployment Rate for 2015', \n",
    "   'Unemployment']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataN2017.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "dataN2017[['TotalPop', 'Percent Population with age between 16 and 44',\n",
    "       'Percent Population with age between 45 and 74',\n",
    "       'Percent Population with age between 75 and over', 'Hispanic', 'White',\n",
    "       'Black', 'Native', 'Asian', 'Pacific', 'Median Household Income',\n",
    "       'Poverty', 'Service', 'Office', 'Construction', 'Production', 'Drive',\n",
    "       'Carpool', 'Transit', 'Walk', 'WorkAtHome', 'Mean Commute Time',\n",
    "       'State Unemployment rate for 2015',\n",
    "       'County Unemployment Rate for 2015']] = scaler.fit_transform(dataN2017[['TotalPop', 'Percent Population with age between 16 and 44',\n",
    "       'Percent Population with age between 45 and 74',\n",
    "       'Percent Population with age between 75 and over', 'Hispanic', 'White',\n",
    "       'Black', 'Native', 'Asian', 'Pacific', 'Median Household Income',\n",
    "       'Poverty', 'Service', 'Office', 'Construction', 'Production', 'Drive',\n",
    "       'Carpool', 'Transit', 'Walk', 'WorkAtHome', 'Mean Commute Time',\n",
    "       'State Unemployment rate for 2015',\n",
    "       'County Unemployment Rate for 2015']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sm.add_constant(dataN2017[[\"Poverty\", 'White', \"Black\", \"Service\", \"WorkAtHome\", \"Hispanic\", 'Mean Commute Time', \n",
    "                           \"Percent Population with age between 16 and 44\", 'Asian','Office', 'Construction','Drive', 'Transit',\n",
    "                          \"State Unemployment rate for 2015\", \"County Unemployment Rate for 2015\"]])\n",
    "y = Reg.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MSE = mean_squared_error(dataN2017[\"Unemployment\"], y)\n",
    "MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAE = mean_absolute_error(dataN2017[\"Unemployment\"], y)\n",
    "MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pred = y.to_frame\n",
    "#pred.iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.values\n",
    "\n",
    "pred  = pd.DataFrame({'Predicted Unemployement Rate': y.values})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred[\"Actual Uemployment rate\"] = dataN2017[\"Unemployment\"]\n",
    "pred[\"Predicted Unemployement Rate\"] = round(pred[\"Predicted Unemployement Rate\"], 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Predicted = pred[[\"Actual Uemployment rate\", 'Predicted Unemployement Rate']] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Predicted.to_csv(\"Predicted Unemployment Rates 2017.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataC = pd.read_csv(\"Classification.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataC.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataC.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataC.drop(\"Unnamed: 0\", axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataC.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataC['Class'][DataC['Class'] == 1] = \"Lowest\"\n",
    "DataC['Class'][DataC['Class'] == 2] = \"Moderate\"\n",
    "DataC['Class'][DataC['Class'] == 3] = \"Highest\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val= train_test_split(DataC, test_size = 0.2, random_state = 1)\n",
    "x_train = X_train.iloc[:,4:35]\n",
    "x_val =   X_val.iloc[:,4:35]                                             \n",
    "y_train = X_train.iloc[:,36:]\n",
    "y_val = X_val.iloc[:,36:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_train.info()\n",
    "#y_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "x_train[['TotalPop',\n",
    "       'Percent Population with age between 16 and 44',\n",
    "       'Percent Population with age between 45 and 74',\n",
    "       'Percent Population with age between 75 and over', 'Men', 'Women',\n",
    "       'Hispanic', 'White', 'Black', 'Native', 'Asian', 'Pacific',\n",
    "       'Citizen Voting Age Pop', 'Median Household Income', 'IncomePerCap',\n",
    "       'Poverty', 'ChildPoverty', 'Professional', 'Service', 'Office',\n",
    "       'Construction', 'Production', 'Drive', 'Carpool', 'Transit', 'Walk',\n",
    "       'OtherTransp', 'WorkAtHome', 'Mean Commute Time',\n",
    "       'State Unemployment rate for 2013', 'County Unemployment Rate for 2013']] = scaler.fit_transform(x_train[['TotalPop',\n",
    "       'Percent Population with age between 16 and 44',\n",
    "       'Percent Population with age between 45 and 74',\n",
    "       'Percent Population with age between 75 and over', 'Men', 'Women',\n",
    "       'Hispanic', 'White', 'Black', 'Native', 'Asian', 'Pacific',\n",
    "       'Citizen Voting Age Pop', 'Median Household Income', 'IncomePerCap',\n",
    "       'Poverty', 'ChildPoverty', 'Professional', 'Service', 'Office',\n",
    "       'Construction', 'Production', 'Drive', 'Carpool', 'Transit', 'Walk',\n",
    "       'OtherTransp', 'WorkAtHome', 'Mean Commute Time',\n",
    "       'State Unemployment rate for 2013', 'County Unemployment Rate for 2013']])\n",
    "\n",
    "x_val[['TotalPop',\n",
    "       'Percent Population with age between 16 and 44',\n",
    "       'Percent Population with age between 45 and 74',\n",
    "       'Percent Population with age between 75 and over', 'Men', 'Women',\n",
    "       'Hispanic', 'White', 'Black', 'Native', 'Asian', 'Pacific',\n",
    "       'Citizen Voting Age Pop', 'Median Household Income', 'IncomePerCap',\n",
    "       'Poverty', 'ChildPoverty', 'Professional', 'Service', 'Office',\n",
    "       'Construction', 'Production', 'Drive', 'Carpool', 'Transit', 'Walk',\n",
    "       'OtherTransp', 'WorkAtHome', 'Mean Commute Time',\n",
    "       'State Unemployment rate for 2013', 'County Unemployment Rate for 2013']] = scaler.fit_transform(x_val[['TotalPop',\n",
    "       'Percent Population with age between 16 and 44',\n",
    "       'Percent Population with age between 45 and 74',\n",
    "       'Percent Population with age between 75 and over', 'Men', 'Women',\n",
    "       'Hispanic', 'White', 'Black', 'Native', 'Asian', 'Pacific',\n",
    "       'Citizen Voting Age Pop', 'Median Household Income', 'IncomePerCap',\n",
    "       'Poverty', 'ChildPoverty', 'Professional', 'Service', 'Office',\n",
    "       'Construction', 'Production', 'Drive', 'Carpool', 'Transit', 'Walk',\n",
    "       'OtherTransp', 'WorkAtHome', 'Mean Commute Time',\n",
    "       'State Unemployment rate for 2013', 'County Unemployment Rate for 2013']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_val.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Build decision tree with all parameters\n",
    "model = tree.DecisionTreeClassifier(criterion = \"entropy\", random_state = 0)\n",
    "x = x_train\n",
    "y = y_train\n",
    "model.fit(x,y)\n",
    "\n",
    "# Show decision tree\n",
    "#model.tree_.__getstate__()['nodes']\n",
    "\n",
    "# Predict class labels using decision tree\n",
    "x_test = x_val\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "# Compute confusion matrix\n",
    "y_test = y_val\n",
    "conf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(conf_matrix)\n",
    "\n",
    "# Plot confusion matrix\n",
    "sns.heatmap(conf_matrix, annot = True, fmt = \".3f\", square = True, cmap = plt.cm.Blues)\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.title('Confusion matrix')\n",
    "plt.tight_layout()\n",
    "\n",
    "\n",
    "# Compute evaluation metrics\n",
    "print(metrics.accuracy_score(y_test, y_pred)) # accuracy\n",
    "print(1 - metrics.accuracy_score(y_test, y_pred)) # error\n",
    "print(metrics.precision_score(y_test, y_pred, average = None)) # precision\n",
    "print(metrics.recall_score(y_test, y_pred, average = None)) # recall\n",
    "print(metrics.f1_score(y_test, y_pred, average = None)) # F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Build decision tree with one parameter\n",
    "model = tree.DecisionTreeClassifier(criterion = \"entropy\", random_state = 0)\n",
    "x = x_train[[\"TotalPop\"]]\n",
    "y = y_train\n",
    "model.fit(x,y)\n",
    "\n",
    "# Show decision tree\n",
    "#model.tree_.__getstate__()['nodes']\n",
    "\n",
    "# Predict class labels using decision tree\n",
    "x_test = x_val[[\"TotalPop\"]]\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "# Compute confusion matrix\n",
    "y_test = y_val\n",
    "conf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(conf_matrix)\n",
    "\n",
    "# Plot confusion matrix\n",
    "sns.heatmap(conf_matrix, annot = True, fmt = \".3f\", square = True, cmap = plt.cm.Blues)\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.title('Confusion matrix')\n",
    "plt.tight_layout()\n",
    "\n",
    "\n",
    "# Compute evaluation metrics\n",
    "print(metrics.accuracy_score(y_test, y_pred)) # accuracy\n",
    "print(1 - metrics.accuracy_score(y_test, y_pred)) # error\n",
    "print(metrics.precision_score(y_test, y_pred, average = None)) # precision\n",
    "print(metrics.recall_score(y_test, y_pred, average = None)) # recall\n",
    "print(metrics.f1_score(y_test, y_pred, average = None)) # F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Build decision tree with 2 parameters\n",
    "model = tree.DecisionTreeClassifier(criterion = \"entropy\", random_state = 0)\n",
    "x = x_train[[\"TotalPop\", \"Men\"]]\n",
    "y = y_train\n",
    "model.fit(x,y)\n",
    "\n",
    "# Show decision tree\n",
    "#model.tree_.__getstate__()['nodes']\n",
    "\n",
    "# Predict class labels using decision tree\n",
    "x_test = x_val[[\"TotalPop\", \"Men\"]]\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "# Compute confusion matrix\n",
    "y_test = y_val\n",
    "conf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(conf_matrix)\n",
    "\n",
    "# Plot confusion matrix\n",
    "sns.heatmap(conf_matrix, annot = True, fmt = \".3f\", square = True, cmap = plt.cm.Blues)\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.title('Confusion matrix')\n",
    "plt.tight_layout()\n",
    "\n",
    "\n",
    "# Compute evaluation metrics\n",
    "print(metrics.accuracy_score(y_test, y_pred)) # accuracy\n",
    "print(1 - metrics.accuracy_score(y_test, y_pred)) # error\n",
    "print(metrics.precision_score(y_test, y_pred, average = None)) # precision\n",
    "print(metrics.recall_score(y_test, y_pred, average = None)) # recall\n",
    "print(metrics.f1_score(y_test, y_pred, average = None)) # F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Build decision tree with 2 parameter\n",
    "model = tree.DecisionTreeClassifier(criterion = \"entropy\", random_state = 0)\n",
    "x = x_train[[\"TotalPop\", \"White\"]]\n",
    "y = y_train\n",
    "model.fit(x,y)\n",
    "\n",
    "# Show decision tree\n",
    "#model.tree_.__getstate__()['nodes']\n",
    "\n",
    "# Predict class labels using decision tree\n",
    "x_test = x_val[[\"TotalPop\", \"White\"]]\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "# Compute confusion matrix\n",
    "y_test = y_val\n",
    "conf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(conf_matrix)\n",
    "\n",
    "# Plot confusion matrix\n",
    "sns.heatmap(conf_matrix, annot = True, fmt = \".3f\", square = True, cmap = plt.cm.Blues)\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.title('Confusion matrix')\n",
    "plt.tight_layout()\n",
    "\n",
    "\n",
    "# Compute evaluation metrics\n",
    "print(metrics.accuracy_score(y_test, y_pred)) # accuracy\n",
    "print(1 - metrics.accuracy_score(y_test, y_pred)) # error\n",
    "print(metrics.precision_score(y_test, y_pred, average = None)) # precision\n",
    "print(metrics.recall_score(y_test, y_pred, average = None)) # recall\n",
    "print(metrics.f1_score(y_test, y_pred, average = None)) # F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Build decision tree with 3 parameters\n",
    "model = tree.DecisionTreeClassifier(criterion = \"entropy\", random_state = 0)\n",
    "x = x_train[[\"TotalPop\", \"White\", \"Black\"]]\n",
    "y = y_train\n",
    "model.fit(x,y)\n",
    "\n",
    "# Show decision tree\n",
    "#model.tree_.__getstate__()['nodes']\n",
    "\n",
    "# Predict class labels using decision tree\n",
    "x_test = x_val[[\"TotalPop\", \"White\", \"Black\"]]\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "# Compute confusion matrix\n",
    "y_test = y_val\n",
    "conf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(conf_matrix)\n",
    "\n",
    "# Plot confusion matrix\n",
    "sns.heatmap(conf_matrix, annot = True, fmt = \".3f\", square = True, cmap = plt.cm.Blues)\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.title('Confusion matrix')\n",
    "plt.tight_layout()\n",
    "\n",
    "\n",
    "# Compute evaluation metrics\n",
    "print(metrics.accuracy_score(y_test, y_pred)) # accuracy\n",
    "print(1 - metrics.accuracy_score(y_test, y_pred)) # error\n",
    "print(metrics.precision_score(y_test, y_pred, average = None)) # precision\n",
    "print(metrics.recall_score(y_test, y_pred, average = None)) # recall\n",
    "print(metrics.f1_score(y_test, y_pred, average = None)) # F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Build decision tree with 4 parameters\n",
    "model = tree.DecisionTreeClassifier(criterion = \"entropy\", random_state = 0)\n",
    "x = x_train[[\"TotalPop\", \"White\", \"Black\",\"ChildPoverty\"]]\n",
    "y = y_train\n",
    "model.fit(x,y)\n",
    "\n",
    "# Show decision tree\n",
    "#model.tree_.__getstate__()['nodes']\n",
    "\n",
    "# Predict class labels using decision tree\n",
    "x_test = x_val[[\"TotalPop\", \"White\", \"Black\", \"ChildPoverty\"]]\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "# Compute confusion matrix\n",
    "y_test = y_val\n",
    "conf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(conf_matrix)\n",
    "\n",
    "# Plot confusion matrix\n",
    "sns.heatmap(conf_matrix, annot = True, fmt = \".3f\", square = True, cmap = plt.cm.Blues)\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.title('Confusion matrix')\n",
    "plt.tight_layout()\n",
    "\n",
    "\n",
    "# Compute evaluation metrics\n",
    "print(metrics.accuracy_score(y_test, y_pred)) # accuracy\n",
    "print(1 - metrics.accuracy_score(y_test, y_pred)) # error\n",
    "print(metrics.precision_score(y_test, y_pred, average = None)) # precision\n",
    "print(metrics.recall_score(y_test, y_pred, average = None)) # recall\n",
    "print(metrics.f1_score(y_test, y_pred, average = None)) # F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Build decision tree with 5 parameters\n",
    "model = tree.DecisionTreeClassifier(criterion = \"entropy\", random_state = 0)\n",
    "x = x_train[[\"TotalPop\", \"White\", \"Black\",\"ChildPoverty\", \"Poverty\"]]\n",
    "y = y_train\n",
    "model.fit(x,y)\n",
    "\n",
    "# Show decision tree\n",
    "#model.tree_.__getstate__()['nodes']\n",
    "\n",
    "# Predict class labels using decision tree\n",
    "x_test = x_val[[\"TotalPop\", \"White\", \"Black\", \"ChildPoverty\", \"Poverty\"]]\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "# Compute confusion matrix\n",
    "y_test = y_val\n",
    "conf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(conf_matrix)\n",
    "\n",
    "# Plot confusion matrix\n",
    "sns.heatmap(conf_matrix, annot = True, fmt = \".3f\", square = True, cmap = plt.cm.Blues)\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.title('Confusion matrix')\n",
    "plt.tight_layout()\n",
    "\n",
    "\n",
    "# Compute evaluation metrics\n",
    "print(metrics.accuracy_score(y_test, y_pred)) # accuracy\n",
    "print(1 - metrics.accuracy_score(y_test, y_pred)) # error\n",
    "print(metrics.precision_score(y_test, y_pred, average = None)) # precision\n",
    "print(metrics.recall_score(y_test, y_pred, average = None)) # recall\n",
    "print(metrics.f1_score(y_test, y_pred, average = None)) # F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Build decision tree with 6 parameters\n",
    "model = tree.DecisionTreeClassifier(criterion = \"entropy\", random_state = 0)\n",
    "x = x_train[[\"TotalPop\", \"White\", \"Black\", \"ChildPoverty\", \"Poverty\", \"IncomePerCap\"]]\n",
    "y = y_train\n",
    "model.fit(x,y)\n",
    "\n",
    "# Show decision tree\n",
    "#model.tree_.__getstate__()['nodes']\n",
    "\n",
    "# Predict class labels using decision tree\n",
    "x_test = x_val[[\"TotalPop\", \"White\", \"Black\", \"ChildPoverty\", \"Poverty\", \"IncomePerCap\"]]\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "# Compute confusion matrix\n",
    "y_test = y_val\n",
    "conf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(conf_matrix)\n",
    "\n",
    "# Plot confusion matrix\n",
    "sns.heatmap(conf_matrix, annot = True, fmt = \".3f\", square = True, cmap = plt.cm.Blues)\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.title('Confusion matrix')\n",
    "plt.tight_layout()\n",
    "\n",
    "\n",
    "# Compute evaluation metrics\n",
    "print(metrics.accuracy_score(y_test, y_pred)) # accuracy\n",
    "print(1 - metrics.accuracy_score(y_test, y_pred)) # error\n",
    "print(metrics.precision_score(y_test, y_pred, average = None)) # precision\n",
    "print(metrics.recall_score(y_test, y_pred, average = None)) # recall\n",
    "print(metrics.f1_score(y_test, y_pred, average = None)) # F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Build decision tree with 6 parameter\n",
    "model = tree.DecisionTreeClassifier(criterion = \"entropy\", random_state = 0)\n",
    "x = x_train[[\"TotalPop\", \"White\", \"Black\", \"ChildPoverty\", \"Poverty\", \"Median Household Income\"]] \n",
    "y = y_train\n",
    "model.fit(x,y)\n",
    "\n",
    "# Show decision tree\n",
    "#model.tree_.__getstate__()['nodes']\n",
    "\n",
    "# Predict class labels using decision tree\n",
    "x_test = x_val[[\"TotalPop\", \"White\", \"Black\", \"ChildPoverty\", \"Poverty\", \"Median Household Income\"]] \n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "# Compute confusion matrix\n",
    "y_test = y_val\n",
    "conf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(conf_matrix)\n",
    "\n",
    "# Plot confusion matrix\n",
    "sns.heatmap(conf_matrix, annot = True, fmt = \".3f\", square = True, cmap = plt.cm.Blues)\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.title('Confusion matrix')\n",
    "plt.tight_layout()\n",
    "\n",
    "\n",
    "# Compute evaluation metrics\n",
    "print(metrics.accuracy_score(y_test, y_pred)) # accuracy\n",
    "print(1 - metrics.accuracy_score(y_test, y_pred)) # error\n",
    "print(metrics.precision_score(y_test, y_pred, average = None)) # precision\n",
    "print(metrics.recall_score(y_test, y_pred, average = None)) # recall\n",
    "print(metrics.f1_score(y_test, y_pred, average = None)) # F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Build decision tree with 7 parameters\n",
    "model = tree.DecisionTreeClassifier(criterion = \"entropy\", random_state = 0)\n",
    "x = x_train[[\"TotalPop\", \"White\", \"Black\", \"ChildPoverty\", \"Poverty\", \"Median Household Income\", \"Citizen Voting Age Pop\"]]\n",
    "y = y_train\n",
    "model.fit(x,y)\n",
    "\n",
    "# Show decision tree\n",
    "#model.tree_.__getstate__()['nodes']\n",
    "\n",
    "# Predict class labels using decision tree\n",
    "x_test = x_val[[\"TotalPop\", \"White\", \"Black\", \"ChildPoverty\", \"Poverty\", \"Median Household Income\", \"Citizen Voting Age Pop\"]]\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "# Compute confusion matrix\n",
    "y_test = y_val\n",
    "conf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(conf_matrix)\n",
    "\n",
    "# Plot confusion matrix\n",
    "sns.heatmap(conf_matrix, annot = True, fmt = \".3f\", square = True, cmap = plt.cm.Blues)\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.title('Confusion matrix')\n",
    "plt.tight_layout()\n",
    "\n",
    "\n",
    "# Compute evaluation metrics\n",
    "print(metrics.accuracy_score(y_test, y_pred)) # accuracy\n",
    "print(1 - metrics.accuracy_score(y_test, y_pred)) # error\n",
    "print(metrics.precision_score(y_test, y_pred, average = None)) # precision\n",
    "print(metrics.recall_score(y_test, y_pred, average = None)) # recall\n",
    "print(metrics.f1_score(y_test, y_pred, average = None)) # F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Build decision tree with 8 parameter\n",
    "model = tree.DecisionTreeClassifier(criterion = \"entropy\", random_state = 0)\n",
    "x = x_train[[\"TotalPop\", \"White\", \"Black\", \"ChildPoverty\", \"Poverty\", \"Median Household Income\", \"Citizen Voting Age Pop\", \n",
    "             \"County Unemployment Rate for 2013\"]]\n",
    "y = y_train\n",
    "model.fit(x,y)\n",
    "\n",
    "# Show decision tree\n",
    "#model.tree_.__getstate__()['nodes']\n",
    "\n",
    "# Predict class labels using decision tree\n",
    "x_test = x_val[[\"TotalPop\", \"White\", \"Black\", \"ChildPoverty\", \"Poverty\", \"Median Household Income\", \"Citizen Voting Age Pop\", \n",
    "             \"County Unemployment Rate for 2013\"]]\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "# Compute confusion matrix\n",
    "y_test = y_val\n",
    "conf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(conf_matrix)\n",
    "\n",
    "# Plot confusion matrix\n",
    "sns.heatmap(conf_matrix, annot = True, fmt = \".3f\", square = True, cmap = plt.cm.Blues)\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.title('Confusion matrix')\n",
    "plt.tight_layout()\n",
    "\n",
    "\n",
    "# Compute evaluation metrics\n",
    "print(metrics.accuracy_score(y_test, y_pred)) # accuracy\n",
    "print(1 - metrics.accuracy_score(y_test, y_pred)) # error\n",
    "print(metrics.precision_score(y_test, y_pred, average = None)) # precision\n",
    "print(metrics.recall_score(y_test, y_pred, average = None)) # recall\n",
    "print(metrics.f1_score(y_test, y_pred, average = None)) # F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Build decision tree with 9 parameter\n",
    "model = tree.DecisionTreeClassifier(criterion = \"entropy\", random_state = 0)\n",
    "x = x_train[[\"TotalPop\", \"White\", \"Black\", \"ChildPoverty\", \"Poverty\", \"Median Household Income\", \"Citizen Voting Age Pop\", \n",
    "             \"County Unemployment Rate for 2013\", 'Percent Population with age between 16 and 44']]\n",
    "y = y_train\n",
    "model.fit(x,y)\n",
    "\n",
    "# Show decision tree\n",
    "#model.tree_.__getstate__()['nodes']\n",
    "\n",
    "# Predict class labels using decision tree\n",
    "x_test = x_val[[\"TotalPop\", \"White\", \"Black\", \"ChildPoverty\", \"Poverty\", \"Median Household Income\", \"Citizen Voting Age Pop\", \n",
    "             \"County Unemployment Rate for 2013\", 'Percent Population with age between 16 and 44']]\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "# Compute confusion matrix\n",
    "y_test = y_val\n",
    "conf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(conf_matrix)\n",
    "\n",
    "# Plot confusion matrix\n",
    "sns.heatmap(conf_matrix, annot = True, fmt = \".3f\", square = True, cmap = plt.cm.Blues)\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.title('Confusion matrix')\n",
    "plt.tight_layout()\n",
    "\n",
    "\n",
    "# Compute evaluation metrics\n",
    "print(metrics.accuracy_score(y_test, y_pred)) # accuracy\n",
    "print(1 - metrics.accuracy_score(y_test, y_pred)) # error\n",
    "print(metrics.precision_score(y_test, y_pred, average = None)) # precision\n",
    "print(metrics.recall_score(y_test, y_pred, average = None)) # recall\n",
    "print(metrics.f1_score(y_test, y_pred, average = None)) # F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Build decision tree with 9 parameter\n",
    "model = tree.DecisionTreeClassifier(criterion = \"entropy\", random_state = 0)\n",
    "x = x_train[[\"TotalPop\", \"White\", \"Black\", \"ChildPoverty\", \"Poverty\", \"Median Household Income\", \"Citizen Voting Age Pop\", \n",
    "             \"County Unemployment Rate for 2013\", 'Percent Population with age between 45 and 74']]\n",
    "y = y_train\n",
    "model.fit(x,y)\n",
    "\n",
    "# Show decision tree\n",
    "#model.tree_.__getstate__()['nodes']\n",
    "\n",
    "# Predict class labels using decision tree\n",
    "x_test = x_val[[\"TotalPop\", \"White\", \"Black\", \"ChildPoverty\", \"Poverty\", \"Median Household Income\", \"Citizen Voting Age Pop\", \n",
    "             \"County Unemployment Rate for 2013\", 'Percent Population with age between 45 and 74']]\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "# Compute confusion matrix\n",
    "y_test = y_val\n",
    "conf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(conf_matrix)\n",
    "\n",
    "# Plot confusion matrix\n",
    "sns.heatmap(conf_matrix, annot = True, fmt = \".3f\", square = True, cmap = plt.cm.Blues)\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.title('Confusion matrix')\n",
    "plt.tight_layout()\n",
    "\n",
    "\n",
    "# Compute evaluation metrics\n",
    "print(metrics.accuracy_score(y_test, y_pred)) # accuracy\n",
    "print(1 - metrics.accuracy_score(y_test, y_pred)) # error\n",
    "print(metrics.precision_score(y_test, y_pred, average = None)) # precision\n",
    "print(metrics.recall_score(y_test, y_pred, average = None)) # recall\n",
    "print(metrics.f1_score(y_test, y_pred, average = None)) # F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Build decision tree with 9 parameter\n",
    "model = tree.DecisionTreeClassifier(criterion = \"entropy\", random_state = 0)\n",
    "x = x_train[[\"TotalPop\", \"White\", \"Black\", \"ChildPoverty\", \"Poverty\", \"Median Household Income\", \"Citizen Voting Age Pop\", \n",
    "             \"County Unemployment Rate for 2013\", 'Percent Population with age between 75 and over']]\n",
    "y = y_train\n",
    "model.fit(x,y)\n",
    "\n",
    "# Show decision tree\n",
    "#model.tree_.__getstate__()['nodes']\n",
    "\n",
    "# Predict class labels using decision tree\n",
    "x_test = x_val[[\"TotalPop\", \"White\", \"Black\", \"ChildPoverty\", \"Poverty\", \"Median Household Income\", \"Citizen Voting Age Pop\", \n",
    "             \"County Unemployment Rate for 2013\", 'Percent Population with age between 75 and over']]\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "# Compute confusion matrix\n",
    "y_test = y_val\n",
    "conf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(conf_matrix)\n",
    "\n",
    "# Plot confusion matrix\n",
    "sns.heatmap(conf_matrix, annot = True, fmt = \".3f\", square = True, cmap = plt.cm.Blues)\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.title('Confusion matrix')\n",
    "plt.tight_layout()\n",
    "\n",
    "\n",
    "# Compute evaluation metrics\n",
    "print(metrics.accuracy_score(y_test, y_pred)) # accuracy\n",
    "print(1 - metrics.accuracy_score(y_test, y_pred)) # error\n",
    "print(metrics.precision_score(y_test, y_pred, average = None)) # precision\n",
    "print(metrics.recall_score(y_test, y_pred, average = None)) # recall\n",
    "print(metrics.f1_score(y_test, y_pred, average = None)) # F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Build decision tree with 9 parameter\n",
    "model = tree.DecisionTreeClassifier(criterion = \"entropy\", random_state = 0)\n",
    "x = x_train[[\"TotalPop\", \"White\", \"Black\", \"ChildPoverty\", \"Poverty\", \"Median Household Income\", \"Citizen Voting Age Pop\", \n",
    "             \"County Unemployment Rate for 2013\", 'Hispanic']]\n",
    "y = y_train\n",
    "model.fit(x,y)\n",
    "\n",
    "# Show decision tree\n",
    "#model.tree_.__getstate__()['nodes']\n",
    "\n",
    "# Predict class labels using decision tree\n",
    "x_test = x_val[[\"TotalPop\", \"White\", \"Black\", \"ChildPoverty\", \"Poverty\", \"Median Household Income\", \"Citizen Voting Age Pop\", \n",
    "             \"County Unemployment Rate for 2013\", 'Hispanic']]\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "# Compute confusion matrix\n",
    "y_test = y_val\n",
    "conf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(conf_matrix)\n",
    "\n",
    "# Plot confusion matrix\n",
    "sns.heatmap(conf_matrix, annot = True, fmt = \".3f\", square = True, cmap = plt.cm.Blues)\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.title('Confusion matrix')\n",
    "plt.tight_layout()\n",
    "\n",
    "\n",
    "# Compute evaluation metrics\n",
    "print(metrics.accuracy_score(y_test, y_pred)) # accuracy\n",
    "print(1 - metrics.accuracy_score(y_test, y_pred)) # error\n",
    "print(metrics.precision_score(y_test, y_pred, average = None)) # precision\n",
    "print(metrics.recall_score(y_test, y_pred, average = None)) # recall\n",
    "print(metrics.f1_score(y_test, y_pred, average = None)) # F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Build decision tree with 10 parameters\n",
    "model = tree.DecisionTreeClassifier(criterion = \"entropy\", random_state = 0)\n",
    "x = x_train[[\"TotalPop\", \"White\", \"Black\", \"ChildPoverty\", \"Poverty\", \"Median Household Income\", \"Citizen Voting Age Pop\", \n",
    "             \"County Unemployment Rate for 2013\", 'Hispanic', 'Native']]\n",
    "y = y_train\n",
    "model.fit(x,y)\n",
    "\n",
    "# Show decision tree\n",
    "#model.tree_.__getstate__()['nodes']\n",
    "\n",
    "# Predict class labels using decision tree\n",
    "x_test = x_val[[\"TotalPop\", \"White\", \"Black\", \"ChildPoverty\", \"Poverty\", \"Median Household Income\", \"Citizen Voting Age Pop\", \n",
    "             \"County Unemployment Rate for 2013\", 'Hispanic', 'Native']]\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "# Compute confusion matrix\n",
    "y_test = y_val\n",
    "conf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(conf_matrix)\n",
    "\n",
    "# Plot confusion matrix\n",
    "sns.heatmap(conf_matrix, annot = True, fmt = \".3f\", square = True, cmap = plt.cm.Blues)\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.title('Confusion matrix')\n",
    "plt.tight_layout()\n",
    "\n",
    "\n",
    "# Compute evaluation metrics\n",
    "print(metrics.accuracy_score(y_test, y_pred)) # accuracy\n",
    "print(1 - metrics.accuracy_score(y_test, y_pred)) # error\n",
    "print(metrics.precision_score(y_test, y_pred, average = None)) # precision\n",
    "print(metrics.recall_score(y_test, y_pred, average = None)) # recall\n",
    "print(metrics.f1_score(y_test, y_pred, average = None)) # F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Build decision tree with 11 parameters\n",
    "model = tree.DecisionTreeClassifier(criterion = \"entropy\", random_state = 0)\n",
    "x = x_train[[\"TotalPop\", \"White\", \"Black\", \"ChildPoverty\", \"Poverty\", \"Median Household Income\", \"Citizen Voting Age Pop\", \n",
    "             \"County Unemployment Rate for 2013\", 'Hispanic', 'Native', 'Asian']]\n",
    "y = y_train\n",
    "model.fit(x,y)\n",
    "\n",
    "# Show decision tree\n",
    "#model.tree_.__getstate__()['nodes']\n",
    "\n",
    "# Predict class labels using decision tree\n",
    "x_test = x_val[[\"TotalPop\", \"White\", \"Black\", \"ChildPoverty\", \"Poverty\", \"Median Household Income\", \"Citizen Voting Age Pop\", \n",
    "             \"County Unemployment Rate for 2013\", 'Hispanic', 'Native', 'Asian']]\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "# Compute confusion matrix\n",
    "y_test = y_val\n",
    "conf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(conf_matrix)\n",
    "\n",
    "# Plot confusion matrix\n",
    "sns.heatmap(conf_matrix, annot = True, fmt = \".3f\", square = True, cmap = plt.cm.Blues)\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.title('Confusion matrix')\n",
    "plt.tight_layout()\n",
    "\n",
    "\n",
    "# Compute evaluation metrics\n",
    "print(metrics.accuracy_score(y_test, y_pred)) # accuracy\n",
    "print(1 - metrics.accuracy_score(y_test, y_pred)) # error\n",
    "print(metrics.precision_score(y_test, y_pred, average = None)) # precision\n",
    "print(metrics.recall_score(y_test, y_pred, average = None)) # recall\n",
    "print(metrics.f1_score(y_test, y_pred, average = None)) # F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Build decision tree with 11 parameter\n",
    "model = tree.DecisionTreeClassifier(criterion = \"entropy\", random_state = 0)\n",
    "x = x_train[[\"TotalPop\", \"White\", \"Black\", \"ChildPoverty\", \"Poverty\", \"Median Household Income\", \"Citizen Voting Age Pop\", \n",
    "             \"County Unemployment Rate for 2013\", 'Hispanic', 'Native', 'Pacific']]\n",
    "y = y_train\n",
    "model.fit(x,y)\n",
    "\n",
    "# Show decision tree\n",
    "#model.tree_.__getstate__()['nodes']\n",
    "\n",
    "# Predict class labels using decision tree\n",
    "x_test = x_val[[\"TotalPop\", \"White\", \"Black\", \"ChildPoverty\", \"Poverty\", \"Median Household Income\", \"Citizen Voting Age Pop\", \n",
    "             \"County Unemployment Rate for 2013\", 'Hispanic', 'Native', 'Pacific']]\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "# Compute confusion matrix\n",
    "y_test = y_val\n",
    "conf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(conf_matrix)\n",
    "\n",
    "# Plot confusion matrix\n",
    "sns.heatmap(conf_matrix, annot = True, fmt = \".3f\", square = True, cmap = plt.cm.Blues)\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.title('Confusion matrix')\n",
    "plt.tight_layout()\n",
    "\n",
    "\n",
    "# Compute evaluation metrics\n",
    "print(metrics.accuracy_score(y_test, y_pred)) # accuracy\n",
    "print(1 - metrics.accuracy_score(y_test, y_pred)) # error\n",
    "print(metrics.precision_score(y_test, y_pred, average = None)) # precision\n",
    "print(metrics.recall_score(y_test, y_pred, average = None)) # recall\n",
    "print(metrics.f1_score(y_test, y_pred, average = None)) # F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Build decision tree with 11 parameter\n",
    "model = tree.DecisionTreeClassifier(criterion = \"entropy\", random_state = 0)\n",
    "x = x_train[[\"TotalPop\", \"White\", \"Black\", \"ChildPoverty\", \"Poverty\", \"Median Household Income\", \"Citizen Voting Age Pop\", \n",
    "             \"County Unemployment Rate for 2013\", 'Hispanic', 'Native', 'Service']]\n",
    "y = y_train\n",
    "model.fit(x,y)\n",
    "\n",
    "# Show decision tree\n",
    "#model.tree_.__getstate__()['nodes']\n",
    "\n",
    "# Predict class labels using decision tree\n",
    "x_test = x_val[[\"TotalPop\", \"White\", \"Black\", \"ChildPoverty\", \"Poverty\", \"Median Household Income\", \"Citizen Voting Age Pop\", \n",
    "             \"County Unemployment Rate for 2013\", 'Hispanic', 'Native', 'Service']]\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "# Compute confusion matrix\n",
    "y_test = y_val\n",
    "conf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(conf_matrix)\n",
    "\n",
    "# Plot confusion matrix\n",
    "sns.heatmap(conf_matrix, annot = True, fmt = \".3f\", square = True, cmap = plt.cm.Blues)\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.title('Confusion matrix')\n",
    "plt.tight_layout()\n",
    "\n",
    "\n",
    "# Compute evaluation metrics\n",
    "print(metrics.accuracy_score(y_test, y_pred)) # accuracy\n",
    "print(1 - metrics.accuracy_score(y_test, y_pred)) # error\n",
    "print(metrics.precision_score(y_test, y_pred, average = None)) # precision\n",
    "print(metrics.recall_score(y_test, y_pred, average = None)) # recall\n",
    "print(metrics.f1_score(y_test, y_pred, average = None)) # F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Build decision tree with 11 parameter\n",
    "model = tree.DecisionTreeClassifier(criterion = \"entropy\", random_state = 0)\n",
    "x = x_train[[\"TotalPop\", \"White\", \"Black\", \"ChildPoverty\", \"Poverty\", \"Median Household Income\", \"Citizen Voting Age Pop\", \n",
    "             \"County Unemployment Rate for 2013\", 'Hispanic', 'Native', 'Office']]\n",
    "y = y_train\n",
    "model.fit(x,y)\n",
    "\n",
    "# Show decision tree\n",
    "#model.tree_.__getstate__()['nodes']\n",
    "\n",
    "# Predict class labels using decision tree\n",
    "x_test = x_val[[\"TotalPop\", \"White\", \"Black\", \"ChildPoverty\", \"Poverty\", \"Median Household Income\", \"Citizen Voting Age Pop\", \n",
    "             \"County Unemployment Rate for 2013\", 'Hispanic', 'Native', 'Office']]\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "# Compute confusion matrix\n",
    "y_test = y_val\n",
    "conf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(conf_matrix)\n",
    "\n",
    "# Plot confusion matrix\n",
    "sns.heatmap(conf_matrix, annot = True, fmt = \".3f\", square = True, cmap = plt.cm.Blues)\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.title('Confusion matrix')\n",
    "plt.tight_layout()\n",
    "\n",
    "\n",
    "# Compute evaluation metrics\n",
    "print(metrics.accuracy_score(y_test, y_pred)) # accuracy\n",
    "print(1 - metrics.accuracy_score(y_test, y_pred)) # error\n",
    "print(metrics.precision_score(y_test, y_pred, average = None)) # precision\n",
    "print(metrics.recall_score(y_test, y_pred, average = None)) # recall\n",
    "print(metrics.f1_score(y_test, y_pred, average = None)) # F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Build decision tree with 11 parameter\n",
    "model = tree.DecisionTreeClassifier(criterion = \"entropy\", random_state = 0)\n",
    "x = x_train[[\"TotalPop\", \"White\", \"Black\", \"ChildPoverty\", \"Poverty\", \"Median Household Income\", \"Citizen Voting Age Pop\", \n",
    "             \"County Unemployment Rate for 2013\", 'Hispanic', 'Native', 'Construction']]\n",
    "y = y_train\n",
    "model.fit(x,y)\n",
    "\n",
    "# Show decision tree\n",
    "#model.tree_.__getstate__()['nodes']\n",
    "\n",
    "# Predict class labels using decision tree\n",
    "x_test = x_val[[\"TotalPop\", \"White\", \"Black\", \"ChildPoverty\", \"Poverty\", \"Median Household Income\", \"Citizen Voting Age Pop\", \n",
    "             \"County Unemployment Rate for 2013\", 'Hispanic', 'Native', 'Construction']]\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "# Compute confusion matrix\n",
    "y_test = y_val\n",
    "conf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(conf_matrix)\n",
    "\n",
    "# Plot confusion matrix\n",
    "sns.heatmap(conf_matrix, annot = True, fmt = \".3f\", square = True, cmap = plt.cm.Blues)\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.title('Confusion matrix')\n",
    "plt.tight_layout()\n",
    "\n",
    "\n",
    "# Compute evaluation metrics\n",
    "print(metrics.accuracy_score(y_test, y_pred)) # accuracy\n",
    "print(1 - metrics.accuracy_score(y_test, y_pred)) # error\n",
    "print(metrics.precision_score(y_test, y_pred, average = None)) # precision\n",
    "print(metrics.recall_score(y_test, y_pred, average = None)) # recall\n",
    "print(metrics.f1_score(y_test, y_pred, average = None)) # F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Build decision tree with 11 parameter\n",
    "model = tree.DecisionTreeClassifier(criterion = \"entropy\", random_state = 0)\n",
    "x = x_train[[\"TotalPop\", \"White\", \"Black\", \"ChildPoverty\", \"Poverty\", \"Median Household Income\", \"Citizen Voting Age Pop\", \n",
    "             \"County Unemployment Rate for 2013\", 'Hispanic', 'Native', 'Production']]\n",
    "y = y_train\n",
    "model.fit(x,y)\n",
    "\n",
    "# Show decision tree\n",
    "#model.tree_.__getstate__()['nodes']\n",
    "\n",
    "# Predict class labels using decision tree\n",
    "x_test = x_val[[\"TotalPop\", \"White\", \"Black\", \"ChildPoverty\", \"Poverty\", \"Median Household Income\", \"Citizen Voting Age Pop\", \n",
    "             \"County Unemployment Rate for 2013\", 'Hispanic', 'Native', 'Production']]\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "# Compute confusion matrix\n",
    "y_test = y_val\n",
    "conf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(conf_matrix)\n",
    "\n",
    "# Plot confusion matrix\n",
    "sns.heatmap(conf_matrix, annot = True, fmt = \".3f\", square = True, cmap = plt.cm.Blues)\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.title('Confusion matrix')\n",
    "plt.tight_layout()\n",
    "\n",
    "\n",
    "# Compute evaluation metrics\n",
    "print(metrics.accuracy_score(y_test, y_pred)) # accuracy\n",
    "print(1 - metrics.accuracy_score(y_test, y_pred)) # error\n",
    "print(metrics.precision_score(y_test, y_pred, average = None)) # precision\n",
    "print(metrics.recall_score(y_test, y_pred, average = None)) # recall\n",
    "print(metrics.f1_score(y_test, y_pred, average = None)) # F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Build decision tree with 11 parameter\n",
    "model = tree.DecisionTreeClassifier(criterion = \"entropy\", random_state = 0)\n",
    "x = x_train[[\"TotalPop\", \"White\", \"Black\", \"ChildPoverty\", \"Poverty\", \"Median Household Income\", \"Citizen Voting Age Pop\", \n",
    "             \"County Unemployment Rate for 2013\", 'Hispanic', 'Native', 'Drive']]\n",
    "y = y_train\n",
    "model.fit(x,y)\n",
    "\n",
    "# Show decision tree\n",
    "#model.tree_.__getstate__()['nodes']\n",
    "\n",
    "# Predict class labels using decision tree\n",
    "x_test = x_val[[\"TotalPop\", \"White\", \"Black\", \"ChildPoverty\", \"Poverty\", \"Median Household Income\", \"Citizen Voting Age Pop\", \n",
    "             \"County Unemployment Rate for 2013\", 'Hispanic', 'Native', 'Drive']]\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "# Compute confusion matrix\n",
    "y_test = y_val\n",
    "conf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(conf_matrix)\n",
    "\n",
    "# Plot confusion matrix\n",
    "sns.heatmap(conf_matrix, annot = True, fmt = \".3f\", square = True, cmap = plt.cm.Blues)\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.title('Confusion matrix')\n",
    "plt.tight_layout()\n",
    "\n",
    "\n",
    "# Compute evaluation metrics\n",
    "print(metrics.accuracy_score(y_test, y_pred)) # accuracy\n",
    "print(1 - metrics.accuracy_score(y_test, y_pred)) # error\n",
    "print(metrics.precision_score(y_test, y_pred, average = None)) # precision\n",
    "print(metrics.recall_score(y_test, y_pred, average = None)) # recall\n",
    "print(metrics.f1_score(y_test, y_pred, average = None)) # F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Build decision tree with 11 parameter\n",
    "model = tree.DecisionTreeClassifier(criterion = \"entropy\", random_state = 0)\n",
    "x = x_train[[\"TotalPop\", \"White\", \"Black\", \"ChildPoverty\", \"Poverty\", \"Median Household Income\", \"Citizen Voting Age Pop\", \n",
    "             \"County Unemployment Rate for 2013\", 'Hispanic', 'Native', 'Carpool']]\n",
    "y = y_train\n",
    "model.fit(x,y)\n",
    "\n",
    "# Show decision tree\n",
    "#model.tree_.__getstate__()['nodes']\n",
    "\n",
    "# Predict class labels using decision tree\n",
    "x_test = x_val[[\"TotalPop\", \"White\", \"Black\", \"ChildPoverty\", \"Poverty\", \"Median Household Income\", \"Citizen Voting Age Pop\", \n",
    "             \"County Unemployment Rate for 2013\", 'Hispanic', 'Native', 'Carpool']]\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "# Compute confusion matrix\n",
    "y_test = y_val\n",
    "conf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(conf_matrix)\n",
    "\n",
    "# Plot confusion matrix\n",
    "sns.heatmap(conf_matrix, annot = True, fmt = \".3f\", square = True, cmap = plt.cm.Blues)\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.title('Confusion matrix')\n",
    "plt.tight_layout()\n",
    "\n",
    "\n",
    "# Compute evaluation metrics\n",
    "print(metrics.accuracy_score(y_test, y_pred)) # accuracy\n",
    "print(1 - metrics.accuracy_score(y_test, y_pred)) # error\n",
    "print(metrics.precision_score(y_test, y_pred, average = None)) # precision\n",
    "print(metrics.recall_score(y_test, y_pred, average = None)) # recall\n",
    "print(metrics.f1_score(y_test, y_pred, average = None)) # F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Build decision tree with 11 parameter\n",
    "model = tree.DecisionTreeClassifier(criterion = \"entropy\", random_state = 0)\n",
    "x = x_train[[\"TotalPop\", \"White\", \"Black\", \"ChildPoverty\", \"Poverty\", \"Median Household Income\", \"Citizen Voting Age Pop\", \n",
    "             \"County Unemployment Rate for 2013\", 'Hispanic', 'Native', \"Transit\"]] \n",
    "y = y_train\n",
    "model.fit(x,y)\n",
    "\n",
    "# Show decision tree\n",
    "#model.tree_.__getstate__()['nodes']\n",
    "\n",
    "# Predict class labels using decision tree\n",
    "x_test = x_val[[\"TotalPop\", \"White\", \"Black\", \"ChildPoverty\", \"Poverty\", \"Median Household Income\", \"Citizen Voting Age Pop\", \n",
    "             \"County Unemployment Rate for 2013\", 'Hispanic', 'Native', \"Transit\"]] \n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "# Compute confusion matrix\n",
    "y_test = y_val\n",
    "conf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(conf_matrix)\n",
    "\n",
    "# Plot confusion matrix\n",
    "sns.heatmap(conf_matrix, annot = True, fmt = \".3f\", square = True, cmap = plt.cm.Blues)\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.title('Confusion matrix')\n",
    "plt.tight_layout()\n",
    "\n",
    "\n",
    "# Compute evaluation metrics\n",
    "print(metrics.accuracy_score(y_test, y_pred)) # accuracy\n",
    "print(1 - metrics.accuracy_score(y_test, y_pred)) # error\n",
    "print(metrics.precision_score(y_test, y_pred, average = None)) # precision\n",
    "print(metrics.recall_score(y_test, y_pred, average = None)) # recall\n",
    "print(metrics.f1_score(y_test, y_pred, average = None)) # F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Build decision tree with 11 parameter\n",
    "model = tree.DecisionTreeClassifier(criterion = \"entropy\", random_state = 0)\n",
    "x = x_train[[\"TotalPop\", \"White\", \"Black\", \"ChildPoverty\", \"Poverty\", \"Median Household Income\", \"Citizen Voting Age Pop\", \n",
    "             \"County Unemployment Rate for 2013\", 'Hispanic', 'Native', \"Walk\"]] \n",
    "y = y_train\n",
    "model.fit(x,y)\n",
    "\n",
    "# Show decision tree\n",
    "#model.tree_.__getstate__()['nodes']\n",
    "\n",
    "# Predict class labels using decision tree\n",
    "x_test = x_val[[\"TotalPop\", \"White\", \"Black\", \"ChildPoverty\", \"Poverty\", \"Median Household Income\", \"Citizen Voting Age Pop\", \n",
    "             \"County Unemployment Rate for 2013\", 'Hispanic', 'Native', \"Walk\"]] \n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "# Compute confusion matrix\n",
    "y_test = y_val\n",
    "conf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(conf_matrix)\n",
    "\n",
    "# Plot confusion matrix\n",
    "sns.heatmap(conf_matrix, annot = True, fmt = \".3f\", square = True, cmap = plt.cm.Blues)\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.title('Confusion matrix')\n",
    "plt.tight_layout()\n",
    "\n",
    "\n",
    "# Compute evaluation metrics\n",
    "print(metrics.accuracy_score(y_test, y_pred)) # accuracy\n",
    "print(1 - metrics.accuracy_score(y_test, y_pred)) # error\n",
    "print(metrics.precision_score(y_test, y_pred, average = None)) # precision\n",
    "print(metrics.recall_score(y_test, y_pred, average = None)) # recall\n",
    "print(metrics.f1_score(y_test, y_pred, average = None)) # F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build decision tree with 12 parameter\n",
    "model = tree.DecisionTreeClassifier(criterion = \"entropy\", random_state = 0)\n",
    "x = x_train[[\"TotalPop\", \"White\", \"Black\", \"ChildPoverty\", \"Poverty\", \"Median Household Income\", \"Citizen Voting Age Pop\", \n",
    "             \"County Unemployment Rate for 2013\", 'Hispanic', 'Native', \"Walk\", \"WorkAtHome\"]]\n",
    "y = y_train\n",
    "model.fit(x,y)\n",
    "\n",
    "# Show decision tree\n",
    "#model.tree_.__getstate__()['nodes']\n",
    "\n",
    "# Predict class labels using decision tree\n",
    "x_test = x_val[[\"TotalPop\", \"White\", \"Black\", \"ChildPoverty\", \"Poverty\", \"Median Household Income\", \"Citizen Voting Age Pop\", \n",
    "             \"County Unemployment Rate for 2013\", 'Hispanic', 'Native', \"Walk\", \"WorkAtHome\"]]\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "# Compute confusion matrix\n",
    "y_test = y_val\n",
    "conf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(conf_matrix)\n",
    "\n",
    "# Plot confusion matrix\n",
    "sns.heatmap(conf_matrix, annot = True, fmt = \".3f\", square = True, cmap = plt.cm.Blues)\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.title('Confusion matrix')\n",
    "plt.tight_layout()\n",
    "\n",
    "\n",
    "# Compute evaluation metrics\n",
    "print(metrics.accuracy_score(y_test, y_pred)) # accuracy\n",
    "print(1 - metrics.accuracy_score(y_test, y_pred)) # error\n",
    "print(metrics.precision_score(y_test, y_pred, average = None)) # precision\n",
    "print(metrics.recall_score(y_test, y_pred, average = None)) # recall\n",
    "print(metrics.f1_score(y_test, y_pred, average = None)) # F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build decision tree with 12 parameter\n",
    "model = tree.DecisionTreeClassifier(criterion = \"entropy\", random_state = 0)\n",
    "x = x_train[[\"TotalPop\", \"White\", \"Black\", \"ChildPoverty\", \"Poverty\", \"Median Household Income\", \"Citizen Voting Age Pop\", \n",
    "             \"County Unemployment Rate for 2013\", 'Hispanic', 'Native', \"Walk\", 'Mean Commute Time']]\n",
    "y = y_train\n",
    "model.fit(x,y)\n",
    "\n",
    "# Show decision tree\n",
    "#model.tree_.__getstate__()['nodes']\n",
    "\n",
    "# Predict class labels using decision tree\n",
    "x_test = x_val[[\"TotalPop\", \"White\", \"Black\", \"ChildPoverty\", \"Poverty\", \"Median Household Income\", \"Citizen Voting Age Pop\", \n",
    "             \"County Unemployment Rate for 2013\", 'Hispanic', 'Native', \"Walk\", 'Mean Commute Time']]\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "# Compute confusion matrix\n",
    "y_test = y_val\n",
    "conf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(conf_matrix)\n",
    "\n",
    "# Plot confusion matrix\n",
    "sns.heatmap(conf_matrix, annot = True, fmt = \".3f\", square = True, cmap = plt.cm.Blues)\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.title('Confusion matrix')\n",
    "plt.tight_layout()\n",
    "\n",
    "\n",
    "# Compute evaluation metrics\n",
    "print(metrics.accuracy_score(y_test, y_pred)) # accuracy\n",
    "print(1 - metrics.accuracy_score(y_test, y_pred)) # error\n",
    "print(metrics.precision_score(y_test, y_pred, average = None)) # precision\n",
    "print(metrics.recall_score(y_test, y_pred, average = None)) # recall\n",
    "print(metrics.f1_score(y_test, y_pred, average = None)) # F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build decision tree with 12 parameter\n",
    "model = tree.DecisionTreeClassifier(criterion = \"entropy\", random_state = 0)\n",
    "x = x_train[[\"TotalPop\", \"White\", \"Black\", \"ChildPoverty\", \"Poverty\", \"Median Household Income\", \"Citizen Voting Age Pop\", \n",
    "             \"County Unemployment Rate for 2013\", 'Hispanic', 'Native', \"Walk\", \"State Unemployment rate for 2013\"]]\n",
    "y = y_train\n",
    "model.fit(x,y)\n",
    "\n",
    "# Show decision tree\n",
    "#model.tree_.__getstate__()['nodes']\n",
    "\n",
    "# Predict class labels using decision tree\n",
    "x_test = x_val[[\"TotalPop\", \"White\", \"Black\", \"ChildPoverty\", \"Poverty\", \"Median Household Income\", \"Citizen Voting Age Pop\", \n",
    "             \"County Unemployment Rate for 2013\", 'Hispanic', 'Native', \"Walk\",\"State Unemployment rate for 2013\"]]\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "# Compute confusion matrix\n",
    "y_test = y_val\n",
    "conf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(conf_matrix)\n",
    "\n",
    "# Plot confusion matrix\n",
    "sns.heatmap(conf_matrix, annot = True, fmt = \".3f\", square = True, cmap = plt.cm.Blues)\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.title('Confusion matrix')\n",
    "plt.tight_layout()\n",
    "\n",
    "\n",
    "# Compute evaluation metrics\n",
    "print(metrics.accuracy_score(y_test, y_pred)) # accuracy\n",
    "print(1 - metrics.accuracy_score(y_test, y_pred)) # error\n",
    "print(metrics.precision_score(y_test, y_pred, average = None)) # precision\n",
    "print(metrics.recall_score(y_test, y_pred, average = None)) # recall\n",
    "print(metrics.f1_score(y_test, y_pred, average = None)) # F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build decision tree with 12 parameter\n",
    "model = tree.DecisionTreeClassifier(criterion = \"entropy\", random_state = 0)\n",
    "x = x_train[[\"County Unemployment Rate for 2013\"]]\n",
    "y = y_train\n",
    "model.fit(x,y)\n",
    "\n",
    "# Show decision tree\n",
    "#model.tree_.__getstate__()['nodes']\n",
    "\n",
    "# Predict class labels using decision tree\n",
    "x_test = x_val[[\"County Unemployment Rate for 2013\"]]\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "# Compute confusion matrix\n",
    "y_test = y_val\n",
    "conf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(conf_matrix)\n",
    "\n",
    "# Plot confusion matrix\n",
    "sns.heatmap(conf_matrix, annot = True, fmt = \".3f\", square = True, cmap = plt.cm.Blues)\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.title('Confusion matrix')\n",
    "plt.tight_layout()\n",
    "\n",
    "\n",
    "# Compute evaluation metrics\n",
    "print(metrics.accuracy_score(y_test, y_pred)) # accuracy\n",
    "print(1 - metrics.accuracy_score(y_test, y_pred)) # error\n",
    "print(metrics.precision_score(y_test, y_pred, average = None)) # precision\n",
    "print(metrics.recall_score(y_test, y_pred, average = None)) # recall\n",
    "print(metrics.f1_score(y_test, y_pred, average = None)) # F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision tree with 1 parameter gave the best F1 Scores\n",
    "# \"County Unemployment Rate for 2013\", \n",
    "# [0.72093023 0.85846154 0.70815451]] is the best decision tree classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6 parameters = .78, .49, .50\n",
    "#\"TotalPop\",\"ChildPoverty\", \"IncomePerCap\",\"Poverty\",\"Median Household Income\",\"Black\"\n",
    "\n",
    "# \"County Unemployment Rate for 2013\"\n",
    "# 0.86728395 0.74166667 0.7625"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive Bayes\n",
    "model = GaussianNB()\n",
    "x = x_train[[\"TotalPop\"]]\n",
    "y = y_train\n",
    "model.fit(x,y)\n",
    "\n",
    "# Predict class labels using Naive Bayes classifier\n",
    "x_test = x_val[[\"TotalPop\"]]\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "# Compute confusion matrix\n",
    "y_test = y_val\n",
    "conf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(conf_matrix)\n",
    "\n",
    "# Plot confusion matrix\n",
    "sns.heatmap(conf_matrix, annot = True, fmt = \".3f\", square = True, cmap = plt.cm.Blues)\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.title('Confusion matrix')\n",
    "plt.tight_layout()\n",
    "\n",
    "# TASK 4\n",
    "# Compute evaluation metrics\n",
    "print(metrics.accuracy_score(y_test, y_pred)) # accuracy\n",
    "print(1 - metrics.accuracy_score(y_test, y_pred)) # error\n",
    "print(metrics.precision_score(y_test, y_pred, average = None)) # precision\n",
    "print(metrics.recall_score(y_test, y_pred, average = None)) # recall\n",
    "print(metrics.f1_score(y_test, y_pred, average = None)) # F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GaussianNB()\n",
    "x = x_train\n",
    "y = y_train\n",
    "model.fit(x,y)\n",
    "\n",
    "# Predict class labels using Naive Bayes classifier\n",
    "x_test = x_val\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "# Compute confusion matrix\n",
    "y_test = y_val\n",
    "conf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(conf_matrix)\n",
    "\n",
    "# Plot confusion matrix\n",
    "sns.heatmap(conf_matrix, annot = True, fmt = \".3f\", square = True, cmap = plt.cm.Blues)\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.title('Confusion matrix')\n",
    "plt.tight_layout()\n",
    "\n",
    "# TASK 4\n",
    "# Compute evaluation metrics\n",
    "print(metrics.accuracy_score(y_test, y_pred)) # accuracy\n",
    "print(1 - metrics.accuracy_score(y_test, y_pred)) # error\n",
    "print(metrics.precision_score(y_test, y_pred, average = None)) # precision\n",
    "print(metrics.recall_score(y_test, y_pred, average = None)) # recall\n",
    "print(metrics.f1_score(y_test, y_pred, average = None)) # F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive Bayes with 2 parameters\n",
    "model = GaussianNB()\n",
    "x = x_train[[\"TotalPop\",\"Men\"]]\n",
    "y = y_train\n",
    "model.fit(x,y)\n",
    "\n",
    "# Predict class labels using Naive Bayes classifier\n",
    "x_test = x_val[[\"TotalPop\",\"Men\"]]\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "# Compute confusion matrix\n",
    "y_test = y_val\n",
    "conf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(conf_matrix)\n",
    "\n",
    "# Plot confusion matrix\n",
    "sns.heatmap(conf_matrix, annot = True, fmt = \".3f\", square = True, cmap = plt.cm.Blues)\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.title('Confusion matrix')\n",
    "plt.tight_layout()\n",
    "\n",
    "# TASK 4\n",
    "# Compute evaluation metrics\n",
    "print(metrics.accuracy_score(y_test, y_pred)) # accuracy\n",
    "print(1 - metrics.accuracy_score(y_test, y_pred)) # error\n",
    "print(metrics.precision_score(y_test, y_pred, average = None)) # precision\n",
    "print(metrics.recall_score(y_test, y_pred, average = None)) # recall\n",
    "print(metrics.f1_score(y_test, y_pred, average = None)) # F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive Bayes with 2 parameters\n",
    "model = GaussianNB()\n",
    "x = x_train[[\"TotalPop\",\"White\"]]\n",
    "y = y_train\n",
    "model.fit(x,y)\n",
    "\n",
    "# Predict class labels using Naive Bayes classifier\n",
    "x_test = x_val[[\"TotalPop\",\"White\"]]\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "# Compute confusion matrix\n",
    "y_test = y_val\n",
    "conf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(conf_matrix)\n",
    "\n",
    "# Plot confusion matrix\n",
    "sns.heatmap(conf_matrix, annot = True, fmt = \".3f\", square = True, cmap = plt.cm.Blues)\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.title('Confusion matrix')\n",
    "plt.tight_layout()\n",
    "\n",
    "# TASK 4\n",
    "# Compute evaluation metrics\n",
    "print(metrics.accuracy_score(y_test, y_pred)) # accuracy\n",
    "print(1 - metrics.accuracy_score(y_test, y_pred)) # error\n",
    "print(metrics.precision_score(y_test, y_pred, average = None)) # precision\n",
    "print(metrics.recall_score(y_test, y_pred, average = None)) # recall\n",
    "print(metrics.f1_score(y_test, y_pred, average = None)) # F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive Bayes with 3 parameters\n",
    "model = GaussianNB()\n",
    "x = x_train[[\"TotalPop\", \"White\", \"Black\"]]\n",
    "y = y_train\n",
    "model.fit(x,y)\n",
    "\n",
    "# Predict class labels using Naive Bayes classifier\n",
    "x_test = x_val[[\"TotalPop\",\"White\", \"Black\"]]\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "# Compute confusion matrix\n",
    "y_test = y_val\n",
    "conf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(conf_matrix)\n",
    "\n",
    "# Plot confusion matrix\n",
    "sns.heatmap(conf_matrix, annot = True, fmt = \".3f\", square = True, cmap = plt.cm.Blues)\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.title('Confusion matrix')\n",
    "plt.tight_layout()\n",
    "\n",
    "# TASK 4\n",
    "# Compute evaluation metrics\n",
    "print(metrics.accuracy_score(y_test, y_pred)) # accuracy\n",
    "print(1 - metrics.accuracy_score(y_test, y_pred)) # error\n",
    "print(metrics.precision_score(y_test, y_pred, average = None)) # precision\n",
    "print(metrics.recall_score(y_test, y_pred, average = None)) # recall\n",
    "print(metrics.f1_score(y_test, y_pred, average = None)) # F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive Bayes with 4 parameters\n",
    "model = GaussianNB()\n",
    "x = x_train[[\"TotalPop\", \"White\", \"Black\",\"Citizen Voting Age Pop\"]]\n",
    "y = y_train\n",
    "model.fit(x,y)\n",
    "\n",
    "# Predict class labels using Naive Bayes classifier\n",
    "x_test = x_val[[\"TotalPop\", \"White\", \"Black\",\"Citizen Voting Age Pop\"]]\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "# Compute confusion matrix\n",
    "y_test = y_val\n",
    "conf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(conf_matrix)\n",
    "\n",
    "# Plot confusion matrix\n",
    "sns.heatmap(conf_matrix, annot = True, fmt = \".3f\", square = True, cmap = plt.cm.Blues)\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.title('Confusion matrix')\n",
    "plt.tight_layout()\n",
    "\n",
    "# TASK 4\n",
    "# Compute evaluation metrics\n",
    "print(metrics.accuracy_score(y_test, y_pred)) # accuracy\n",
    "print(1 - metrics.accuracy_score(y_test, y_pred)) # error\n",
    "print(metrics.precision_score(y_test, y_pred, average = None)) # precision\n",
    "print(metrics.recall_score(y_test, y_pred, average = None)) # recall\n",
    "print(metrics.f1_score(y_test, y_pred, average = None)) # F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive Bayes with 4 parameters\n",
    "model = GaussianNB()\n",
    "x = x_train[[\"TotalPop\", \"White\", \"Black\",\"Median Household Income\"]]\n",
    "y = y_train\n",
    "model.fit(x,y)\n",
    "\n",
    "# Predict class labels using Naive Bayes classifier\n",
    "x_test = x_val[[\"TotalPop\", \"White\", \"Black\",\"Median Household Income\"]]\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "# Compute confusion matrix\n",
    "y_test = y_val\n",
    "conf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(conf_matrix)\n",
    "\n",
    "# Plot confusion matrix\n",
    "sns.heatmap(conf_matrix, annot = True, fmt = \".3f\", square = True, cmap = plt.cm.Blues)\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.title('Confusion matrix')\n",
    "plt.tight_layout()\n",
    "\n",
    "# TASK 4\n",
    "# Compute evaluation metrics\n",
    "print(metrics.accuracy_score(y_test, y_pred)) # accuracy\n",
    "print(1 - metrics.accuracy_score(y_test, y_pred)) # error\n",
    "print(metrics.precision_score(y_test, y_pred, average = None)) # precision\n",
    "print(metrics.recall_score(y_test, y_pred, average = None)) # recall\n",
    "print(metrics.f1_score(y_test, y_pred, average = None)) # F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive Bayes with 5 parameters\n",
    "model = GaussianNB()\n",
    "x = x_train[[\"TotalPop\", \"White\", \"Black\",\"Median Household Income\",\"IncomePerCap\"]]\n",
    "y = y_train\n",
    "model.fit(x,y)\n",
    "\n",
    "# Predict class labels using Naive Bayes classifier\n",
    "x_test = x_val[[\"TotalPop\", \"White\", \"Black\",\"Median Household Income\",\"IncomePerCap\"]]\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "# Compute confusion matrix\n",
    "y_test = y_val\n",
    "conf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(conf_matrix)\n",
    "\n",
    "# Plot confusion matrix\n",
    "sns.heatmap(conf_matrix, annot = True, fmt = \".3f\", square = True, cmap = plt.cm.Blues)\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.title('Confusion matrix')\n",
    "plt.tight_layout()\n",
    "\n",
    "# TASK 4\n",
    "# Compute evaluation metrics\n",
    "print(metrics.accuracy_score(y_test, y_pred)) # accuracy\n",
    "print(1 - metrics.accuracy_score(y_test, y_pred)) # error\n",
    "print(metrics.precision_score(y_test, y_pred, average = None)) # precision\n",
    "print(metrics.recall_score(y_test, y_pred, average = None)) # recall\n",
    "print(metrics.f1_score(y_test, y_pred, average = None)) # F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive Bayes with 6 parameters\n",
    "model = GaussianNB()\n",
    "x = x_train[[\"TotalPop\", \"White\", \"Black\",\"Median Household Income\",\"IncomePerCap\",\"Poverty\"]]\n",
    "y = y_train\n",
    "model.fit(x,y)\n",
    "\n",
    "# Predict class labels using Naive Bayes classifier\n",
    "x_test = x_val[[\"TotalPop\", \"White\", \"Black\",\"Median Household Income\",\"IncomePerCap\",\"Poverty\"]]\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "# Compute confusion matrix\n",
    "y_test = y_val\n",
    "conf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(conf_matrix)\n",
    "\n",
    "# Plot confusion matrix\n",
    "sns.heatmap(conf_matrix, annot = True, fmt = \".3f\", square = True, cmap = plt.cm.Blues)\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.title('Confusion matrix')\n",
    "plt.tight_layout()\n",
    "\n",
    "# TASK 4\n",
    "# Compute evaluation metrics\n",
    "print(metrics.accuracy_score(y_test, y_pred)) # accuracy\n",
    "print(1 - metrics.accuracy_score(y_test, y_pred)) # error\n",
    "print(metrics.precision_score(y_test, y_pred, average = None)) # precision\n",
    "print(metrics.recall_score(y_test, y_pred, average = None)) # recall\n",
    "print(metrics.f1_score(y_test, y_pred, average = None)) # F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive Bayes with 7 parameters\n",
    "model = GaussianNB()\n",
    "x = x_train[[\"TotalPop\", \"White\", \"Black\",\"Median Household Income\",\"IncomePerCap\",\"Poverty\",\"ChildPoverty\"]]\n",
    "y = y_train\n",
    "model.fit(x,y)\n",
    "\n",
    "# Predict class labels using Naive Bayes classifier\n",
    "x_test = x_val[[\"TotalPop\", \"White\", \"Black\",\"Median Household Income\",\"IncomePerCap\",\"Poverty\",\"ChildPoverty\"]]\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "# Compute confusion matrix\n",
    "y_test = y_val\n",
    "conf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(conf_matrix)\n",
    "\n",
    "# Plot confusion matrix\n",
    "sns.heatmap(conf_matrix, annot = True, fmt = \".3f\", square = True, cmap = plt.cm.Blues)\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.title('Confusion matrix')\n",
    "plt.tight_layout()\n",
    "\n",
    "# TASK 4\n",
    "# Compute evaluation metrics\n",
    "print(metrics.accuracy_score(y_test, y_pred)) # accuracy\n",
    "print(1 - metrics.accuracy_score(y_test, y_pred)) # error\n",
    "print(metrics.precision_score(y_test, y_pred, average = None)) # precision\n",
    "print(metrics.recall_score(y_test, y_pred, average = None)) # recall\n",
    "print(metrics.f1_score(y_test, y_pred, average = None)) # F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive Bayes with 8 parameters\n",
    "model = GaussianNB()\n",
    "x = x_train[[\"TotalPop\", \"White\", \"Black\",\"Median Household Income\",\"IncomePerCap\",\"Poverty\",\"ChildPoverty\", \"Men\"]]\n",
    "y = y_train\n",
    "model.fit(x,y)\n",
    "\n",
    "# Predict class labels using Naive Bayes classifier\n",
    "x_test = x_val[[\"TotalPop\", \"White\", \"Black\",\"Median Household Income\",\"IncomePerCap\",\"Poverty\",\"ChildPoverty\", \"Men\"]]\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "# Compute confusion matrix\n",
    "y_test = y_val\n",
    "conf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(conf_matrix)\n",
    "\n",
    "# Plot confusion matrix\n",
    "sns.heatmap(conf_matrix, annot = True, fmt = \".3f\", square = True, cmap = plt.cm.Blues)\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.title('Confusion matrix')\n",
    "plt.tight_layout()\n",
    "\n",
    "# TASK 4\n",
    "# Compute evaluation metrics\n",
    "print(metrics.accuracy_score(y_test, y_pred)) # accuracy\n",
    "print(1 - metrics.accuracy_score(y_test, y_pred)) # error\n",
    "print(metrics.precision_score(y_test, y_pred, average = None)) # precision\n",
    "print(metrics.recall_score(y_test, y_pred, average = None)) # recall\n",
    "print(metrics.f1_score(y_test, y_pred, average = None)) # F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive Bayes 2013\n",
    "model = GaussianNB()\n",
    "x = x_train[[\"TotalPop\", \"White\", \"Black\",\"Median Household Income\",\"IncomePerCap\",\"Poverty\",\"ChildPoverty\", \n",
    "             \"County Unemployment Rate for 2013\"]]\n",
    "y = y_train\n",
    "model.fit(x,y)\n",
    "\n",
    "# Predict class labels using Naive Bayes classifier\n",
    "x_test = x_val[[\"TotalPop\", \"White\", \"Black\",\"Median Household Income\",\"IncomePerCap\",\"Poverty\",\"ChildPoverty\", \"County Unemployment Rate for 2013\"]]\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "# Compute confusion matrix\n",
    "y_test = y_val\n",
    "conf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(conf_matrix)\n",
    "\n",
    "# Plot confusion matrix\n",
    "sns.heatmap(conf_matrix, annot = True, fmt = \".3f\", square = True, cmap = plt.cm.Blues)\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.title('Confusion matrix')\n",
    "plt.tight_layout()\n",
    "\n",
    "# TASK 4\n",
    "# Compute evaluation metrics\n",
    "print(metrics.accuracy_score(y_test, y_pred)) # accuracy\n",
    "print(1 - metrics.accuracy_score(y_test, y_pred)) # error\n",
    "print(metrics.precision_score(y_test, y_pred, average = None)) # precision\n",
    "print(metrics.recall_score(y_test, y_pred, average = None)) # recall\n",
    "print(metrics.f1_score(y_test, y_pred, average = None)) # F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive Bayes with 9 parameters\n",
    "model = GaussianNB()\n",
    "x = x_train[[\"TotalPop\", \"White\", \"Black\",\"Median Household Income\",\"IncomePerCap\",\"Poverty\",\"ChildPoverty\", \n",
    "             \"County Unemployment Rate for 2013\", 'Percent Population with age between 16 and 44']]\n",
    "y = y_train\n",
    "model.fit(x,y)\n",
    "\n",
    "# Predict class labels using Naive Bayes classifier\n",
    "x_test = x_val[[\"TotalPop\", \"White\", \"Black\",\"Median Household Income\",\"IncomePerCap\",\"Poverty\",\"ChildPoverty\", \n",
    "                \"County Unemployment Rate for 2013\", 'Percent Population with age between 16 and 44']]\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "# Compute confusion matrix\n",
    "y_test = y_val\n",
    "conf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(conf_matrix)\n",
    "\n",
    "# Plot confusion matrix\n",
    "sns.heatmap(conf_matrix, annot = True, fmt = \".3f\", square = True, cmap = plt.cm.Blues)\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.title('Confusion matrix')\n",
    "plt.tight_layout()\n",
    "\n",
    "# TASK 4\n",
    "# Compute evaluation metrics\n",
    "print(metrics.accuracy_score(y_test, y_pred)) # accuracy\n",
    "print(1 - metrics.accuracy_score(y_test, y_pred)) # error\n",
    "print(metrics.precision_score(y_test, y_pred, average = None)) # precision\n",
    "print(metrics.recall_score(y_test, y_pred, average = None)) # recall\n",
    "print(metrics.f1_score(y_test, y_pred, average = None)) # F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive Bayes with 9 parameters\n",
    "model = GaussianNB()\n",
    "x = x_train[[\"TotalPop\", \"White\", \"Black\",\"Median Household Income\",\"IncomePerCap\",\"Poverty\",\"ChildPoverty\", \n",
    "             \"County Unemployment Rate for 2013\", 'Percent Population with age between 45 and 74']]\n",
    "y = y_train\n",
    "model.fit(x,y)\n",
    "\n",
    "# Predict class labels using Naive Bayes classifier\n",
    "x_test = x_val[[\"TotalPop\", \"White\", \"Black\",\"Median Household Income\",\"IncomePerCap\",\"Poverty\",\"ChildPoverty\", \n",
    "                \"County Unemployment Rate for 2013\", 'Percent Population with age between 45 and 74']]\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "# Compute confusion matrix\n",
    "y_test = y_val\n",
    "conf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(conf_matrix)\n",
    "\n",
    "# Plot confusion matrix\n",
    "sns.heatmap(conf_matrix, annot = True, fmt = \".3f\", square = True, cmap = plt.cm.Blues)\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.title('Confusion matrix')\n",
    "plt.tight_layout()\n",
    "\n",
    "# TASK 4\n",
    "# Compute evaluation metrics\n",
    "print(metrics.accuracy_score(y_test, y_pred)) # accuracy\n",
    "print(1 - metrics.accuracy_score(y_test, y_pred)) # error\n",
    "print(metrics.precision_score(y_test, y_pred, average = None)) # precision\n",
    "print(metrics.recall_score(y_test, y_pred, average = None)) # recall\n",
    "print(metrics.f1_score(y_test, y_pred, average = None)) # F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive Bayes with 9 parameters\n",
    "model = GaussianNB()\n",
    "x = x_train[[\"TotalPop\", \"White\", \"Black\",\"Median Household Income\",\"IncomePerCap\",\"Poverty\",\"ChildPoverty\", \n",
    "             \"County Unemployment Rate for 2013\", 'Percent Population with age between 75 and over']]\n",
    "y = y_train\n",
    "model.fit(x,y)\n",
    "\n",
    "# Predict class labels using Naive Bayes classifier\n",
    "x_test = x_val[[\"TotalPop\", \"White\", \"Black\",\"Median Household Income\",\"IncomePerCap\",\"Poverty\",\"ChildPoverty\", \n",
    "                \"County Unemployment Rate for 2013\", 'Percent Population with age between 75 and over']]\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "# Compute confusion matrix\n",
    "y_test = y_val\n",
    "conf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(conf_matrix)\n",
    "\n",
    "# Plot confusion matrix\n",
    "sns.heatmap(conf_matrix, annot = True, fmt = \".3f\", square = True, cmap = plt.cm.Blues)\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.title('Confusion matrix')\n",
    "plt.tight_layout()\n",
    "\n",
    "# TASK 4\n",
    "# Compute evaluation metrics\n",
    "print(metrics.accuracy_score(y_test, y_pred)) # accuracy\n",
    "print(1 - metrics.accuracy_score(y_test, y_pred)) # error\n",
    "print(metrics.precision_score(y_test, y_pred, average = None)) # precision\n",
    "print(metrics.recall_score(y_test, y_pred, average = None)) # recall\n",
    "print(metrics.f1_score(y_test, y_pred, average = None)) # F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive Bayes with 10 parameters\n",
    "model = GaussianNB()\n",
    "x = x_train[[\"TotalPop\", \"White\", \"Black\",\"Median Household Income\",\"IncomePerCap\",\"Poverty\",\"ChildPoverty\", \n",
    "             \"County Unemployment Rate for 2013\", 'Percent Population with age between 75 and over', 'Hispanic']]\n",
    "y = y_train\n",
    "model.fit(x,y)\n",
    "\n",
    "# Predict class labels using Naive Bayes classifier\n",
    "x_test = x_val[[\"TotalPop\", \"White\", \"Black\",\"Median Household Income\",\"IncomePerCap\",\"Poverty\",\"ChildPoverty\", \n",
    "                \"County Unemployment Rate for 2013\", 'Percent Population with age between 75 and over', 'Hispanic']]\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "# Compute confusion matrix\n",
    "y_test = y_val\n",
    "conf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(conf_matrix)\n",
    "\n",
    "# Plot confusion matrix\n",
    "sns.heatmap(conf_matrix, annot = True, fmt = \".3f\", square = True, cmap = plt.cm.Blues)\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.title('Confusion matrix')\n",
    "plt.tight_layout()\n",
    "\n",
    "# TASK 4\n",
    "# Compute evaluation metrics\n",
    "print(metrics.accuracy_score(y_test, y_pred)) # accuracy\n",
    "print(1 - metrics.accuracy_score(y_test, y_pred)) # error\n",
    "print(metrics.precision_score(y_test, y_pred, average = None)) # precision\n",
    "print(metrics.recall_score(y_test, y_pred, average = None)) # recall\n",
    "print(metrics.f1_score(y_test, y_pred, average = None)) # F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive Bayes with 10 parameters\n",
    "model = GaussianNB()\n",
    "x = x_train[[\"TotalPop\", \"White\", \"Black\",\"Median Household Income\",\"IncomePerCap\",\"Poverty\",\"ChildPoverty\", \n",
    "             \"County Unemployment Rate for 2013\", 'Percent Population with age between 75 and over', 'Native']]\n",
    "y = y_train\n",
    "model.fit(x,y)\n",
    "\n",
    "# Predict class labels using Naive Bayes classifier\n",
    "x_test = x_val[[\"TotalPop\", \"White\", \"Black\",\"Median Household Income\",\"IncomePerCap\",\"Poverty\",\"ChildPoverty\", \n",
    "                \"County Unemployment Rate for 2013\", 'Percent Population with age between 75 and over', 'Native']]\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "# Compute confusion matrix\n",
    "y_test = y_val\n",
    "conf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(conf_matrix)\n",
    "\n",
    "# Plot confusion matrix\n",
    "sns.heatmap(conf_matrix, annot = True, fmt = \".3f\", square = True, cmap = plt.cm.Blues)\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.title('Confusion matrix')\n",
    "plt.tight_layout()\n",
    "\n",
    "# TASK 4\n",
    "# Compute evaluation metrics\n",
    "print(metrics.accuracy_score(y_test, y_pred)) # accuracy\n",
    "print(1 - metrics.accuracy_score(y_test, y_pred)) # error\n",
    "print(metrics.precision_score(y_test, y_pred, average = None)) # precision\n",
    "print(metrics.recall_score(y_test, y_pred, average = None)) # recall\n",
    "print(metrics.f1_score(y_test, y_pred, average = None)) # F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive Bayes with 10 parameters\n",
    "model = GaussianNB()\n",
    "x = x_train[[\"TotalPop\", \"White\", \"Black\",\"Median Household Income\",\"IncomePerCap\",\"Poverty\",\"ChildPoverty\", \n",
    "             \"County Unemployment Rate for 2013\", 'Percent Population with age between 75 and over', 'Asian']]\n",
    "y = y_train\n",
    "model.fit(x,y)\n",
    "\n",
    "# Predict class labels using Naive Bayes classifier\n",
    "x_test = x_val[[\"TotalPop\", \"White\", \"Black\",\"Median Household Income\",\"IncomePerCap\",\"Poverty\",\"ChildPoverty\", \n",
    "                \"County Unemployment Rate for 2013\", 'Percent Population with age between 75 and over', 'Asian']]\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "# Compute confusion matrix\n",
    "y_test = y_val\n",
    "conf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(conf_matrix)\n",
    "\n",
    "# Plot confusion matrix\n",
    "sns.heatmap(conf_matrix, annot = True, fmt = \".3f\", square = True, cmap = plt.cm.Blues)\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.title('Confusion matrix')\n",
    "plt.tight_layout()\n",
    "\n",
    "# TASK 4\n",
    "# Compute evaluation metrics\n",
    "print(metrics.accuracy_score(y_test, y_pred)) # accuracy\n",
    "print(1 - metrics.accuracy_score(y_test, y_pred)) # error\n",
    "print(metrics.precision_score(y_test, y_pred, average = None)) # precision\n",
    "print(metrics.recall_score(y_test, y_pred, average = None)) # recall\n",
    "print(metrics.f1_score(y_test, y_pred, average = None)) # F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive Bayes with 10 parameters\n",
    "model = GaussianNB()\n",
    "x = x_train[[\"TotalPop\", \"White\", \"Black\",\"Median Household Income\",\"IncomePerCap\",\"Poverty\",\"ChildPoverty\", \n",
    "             \"County Unemployment Rate for 2013\", 'Percent Population with age between 75 and over', 'Pacific']]\n",
    "y = y_train\n",
    "model.fit(x,y)\n",
    "\n",
    "# Predict class labels using Naive Bayes classifier\n",
    "x_test = x_val[[\"TotalPop\", \"White\", \"Black\",\"Median Household Income\",\"IncomePerCap\",\"Poverty\",\"ChildPoverty\", \n",
    "                \"County Unemployment Rate for 2013\", 'Percent Population with age between 75 and over', 'Pacific']]\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "# Compute confusion matrix\n",
    "y_test = y_val\n",
    "conf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(conf_matrix)\n",
    "\n",
    "# Plot confusion matrix\n",
    "sns.heatmap(conf_matrix, annot = True, fmt = \".3f\", square = True, cmap = plt.cm.Blues)\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.title('Confusion matrix')\n",
    "plt.tight_layout()\n",
    "\n",
    "# TASK 4\n",
    "# Compute evaluation metrics\n",
    "print(metrics.accuracy_score(y_test, y_pred)) # accuracy\n",
    "print(1 - metrics.accuracy_score(y_test, y_pred)) # error\n",
    "print(metrics.precision_score(y_test, y_pred, average = None)) # precision\n",
    "print(metrics.recall_score(y_test, y_pred, average = None)) # recall\n",
    "print(metrics.f1_score(y_test, y_pred, average = None)) # F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive Bayes with 10 parameters\n",
    "model = GaussianNB()\n",
    "x = x_train[[\"TotalPop\", \"White\", \"Black\",\"Median Household Income\",\"IncomePerCap\",\"Poverty\",\"ChildPoverty\", \n",
    "             \"County Unemployment Rate for 2013\", 'Percent Population with age between 75 and over', 'Professional']]\n",
    "y = y_train\n",
    "model.fit(x,y)\n",
    "\n",
    "# Predict class labels using Naive Bayes classifier\n",
    "x_test = x_val[[\"TotalPop\", \"White\", \"Black\",\"Median Household Income\",\"IncomePerCap\",\"Poverty\",\"ChildPoverty\", \n",
    "                \"County Unemployment Rate for 2013\", 'Percent Population with age between 75 and over', 'Professional']]\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "# Compute confusion matrix\n",
    "y_test = y_val\n",
    "conf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(conf_matrix)\n",
    "\n",
    "# Plot confusion matrix\n",
    "sns.heatmap(conf_matrix, annot = True, fmt = \".3f\", square = True, cmap = plt.cm.Blues)\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.title('Confusion matrix')\n",
    "plt.tight_layout()\n",
    "\n",
    "# TASK 4\n",
    "# Compute evaluation metrics\n",
    "print(metrics.accuracy_score(y_test, y_pred)) # accuracy\n",
    "print(1 - metrics.accuracy_score(y_test, y_pred)) # error\n",
    "print(metrics.precision_score(y_test, y_pred, average = None)) # precision\n",
    "print(metrics.recall_score(y_test, y_pred, average = None)) # recall\n",
    "print(metrics.f1_score(y_test, y_pred, average = None)) # F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive Bayes with 10 parameters\n",
    "model = GaussianNB()\n",
    "x = x_train[[\"TotalPop\", \"White\", \"Black\",\"Median Household Income\",\"IncomePerCap\",\"Poverty\",\"ChildPoverty\", \n",
    "             \"County Unemployment Rate for 2013\", 'Percent Population with age between 75 and over', 'Service']]\n",
    "y = y_train\n",
    "model.fit(x,y)\n",
    "\n",
    "# Predict class labels using Naive Bayes classifier\n",
    "x_test = x_val[[\"TotalPop\", \"White\", \"Black\",\"Median Household Income\",\"IncomePerCap\",\"Poverty\",\"ChildPoverty\", \n",
    "                \"County Unemployment Rate for 2013\", 'Percent Population with age between 75 and over', 'Service']]\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "# Compute confusion matrix\n",
    "y_test = y_val\n",
    "conf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(conf_matrix)\n",
    "\n",
    "# Plot confusion matrix\n",
    "sns.heatmap(conf_matrix, annot = True, fmt = \".3f\", square = True, cmap = plt.cm.Blues)\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.title('Confusion matrix')\n",
    "plt.tight_layout()\n",
    "\n",
    "# TASK 4\n",
    "# Compute evaluation metrics\n",
    "print(metrics.accuracy_score(y_test, y_pred)) # accuracy\n",
    "print(1 - metrics.accuracy_score(y_test, y_pred)) # error\n",
    "print(metrics.precision_score(y_test, y_pred, average = None)) # precision\n",
    "print(metrics.recall_score(y_test, y_pred, average = None)) # recall\n",
    "print(metrics.f1_score(y_test, y_pred, average = None)) # F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive Bayes with 10 parameters\n",
    "model = GaussianNB()\n",
    "x = x_train[[\"TotalPop\", \"White\", \"Black\",\"Median Household Income\",\"IncomePerCap\",\"Poverty\",\"ChildPoverty\", \n",
    "             \"County Unemployment Rate for 2013\", 'Percent Population with age between 75 and over', 'Office']]\n",
    "y = y_train\n",
    "model.fit(x,y)\n",
    "\n",
    "# Predict class labels using Naive Bayes classifier\n",
    "x_test = x_val[[\"TotalPop\", \"White\", \"Black\",\"Median Household Income\",\"IncomePerCap\",\"Poverty\",\"ChildPoverty\", \n",
    "                \"County Unemployment Rate for 2013\", 'Percent Population with age between 75 and over', 'Office']]\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "# Compute confusion matrix\n",
    "y_test = y_val\n",
    "conf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(conf_matrix)\n",
    "\n",
    "# Plot confusion matrix\n",
    "sns.heatmap(conf_matrix, annot = True, fmt = \".3f\", square = True, cmap = plt.cm.Blues)\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.title('Confusion matrix')\n",
    "plt.tight_layout()\n",
    "\n",
    "# TASK 4\n",
    "# Compute evaluation metrics\n",
    "print(metrics.accuracy_score(y_test, y_pred)) # accuracy\n",
    "print(1 - metrics.accuracy_score(y_test, y_pred)) # error\n",
    "print(metrics.precision_score(y_test, y_pred, average = None)) # precision\n",
    "print(metrics.recall_score(y_test, y_pred, average = None)) # recall\n",
    "print(metrics.f1_score(y_test, y_pred, average = None)) # F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive Bayes with 10 parameters\n",
    "model = GaussianNB()\n",
    "x = x_train[[\"TotalPop\", \"White\", \"Black\",\"Median Household Income\",\"IncomePerCap\",\"Poverty\",\"ChildPoverty\", \n",
    "             \"County Unemployment Rate for 2013\", 'Percent Population with age between 75 and over', 'Construction']]\n",
    "y = y_train\n",
    "model.fit(x,y)\n",
    "\n",
    "# Predict class labels using Naive Bayes classifier\n",
    "x_test = x_val[[\"TotalPop\", \"White\", \"Black\",\"Median Household Income\",\"IncomePerCap\",\"Poverty\",\"ChildPoverty\", \n",
    "                \"County Unemployment Rate for 2013\", 'Percent Population with age between 75 and over', 'Construction']]\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "# Compute confusion matrix\n",
    "y_test = y_val\n",
    "conf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(conf_matrix)\n",
    "\n",
    "# Plot confusion matrix\n",
    "sns.heatmap(conf_matrix, annot = True, fmt = \".3f\", square = True, cmap = plt.cm.Blues)\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.title('Confusion matrix')\n",
    "plt.tight_layout()\n",
    "\n",
    "# TASK 4\n",
    "# Compute evaluation metrics\n",
    "print(metrics.accuracy_score(y_test, y_pred)) # accuracy\n",
    "print(1 - metrics.accuracy_score(y_test, y_pred)) # error\n",
    "print(metrics.precision_score(y_test, y_pred, average = None)) # precision\n",
    "print(metrics.recall_score(y_test, y_pred, average = None)) # recall\n",
    "print(metrics.f1_score(y_test, y_pred, average = None)) # F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive Bayes with 10 parameters\n",
    "model = GaussianNB()\n",
    "x = x_train[[\"TotalPop\", \"White\", \"Black\",\"Median Household Income\",\"IncomePerCap\",\"Poverty\",\"ChildPoverty\", \n",
    "             \"County Unemployment Rate for 2013\", 'Percent Population with age between 75 and over', 'Production']]\n",
    "y = y_train\n",
    "model.fit(x,y)\n",
    "\n",
    "# Predict class labels using Naive Bayes classifier\n",
    "x_test = x_val[[\"TotalPop\", \"White\", \"Black\",\"Median Household Income\",\"IncomePerCap\",\"Poverty\",\"ChildPoverty\", \n",
    "                \"County Unemployment Rate for 2013\", 'Percent Population with age between 75 and over', 'Production']]\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "# Compute confusion matrix\n",
    "y_test = y_val\n",
    "conf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(conf_matrix)\n",
    "\n",
    "# Plot confusion matrix\n",
    "sns.heatmap(conf_matrix, annot = True, fmt = \".3f\", square = True, cmap = plt.cm.Blues)\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.title('Confusion matrix')\n",
    "plt.tight_layout()\n",
    "\n",
    "# TASK 4\n",
    "# Compute evaluation metrics\n",
    "print(metrics.accuracy_score(y_test, y_pred)) # accuracy\n",
    "print(1 - metrics.accuracy_score(y_test, y_pred)) # error\n",
    "print(metrics.precision_score(y_test, y_pred, average = None)) # precision\n",
    "print(metrics.recall_score(y_test, y_pred, average = None)) # recall\n",
    "print(metrics.f1_score(y_test, y_pred, average = None)) # F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive Bayes with 11 parameters\n",
    "model = GaussianNB()\n",
    "x = x_train[[\"TotalPop\", \"White\", \"Black\",\"Median Household Income\",\"IncomePerCap\",\"Poverty\",\"ChildPoverty\", \n",
    "             \"County Unemployment Rate for 2013\", 'Percent Population with age between 75 and over', 'Production','Drive']]\n",
    "y = y_train\n",
    "model.fit(x,y)\n",
    "\n",
    "# Predict class labels using Naive Bayes classifier\n",
    "x_test = x_val[[\"TotalPop\", \"White\", \"Black\",\"Median Household Income\",\"IncomePerCap\",\"Poverty\",\"ChildPoverty\", \n",
    "                \"County Unemployment Rate for 2013\", 'Percent Population with age between 75 and over', 'Production','Drive']]\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "# Compute confusion matrix\n",
    "y_test = y_val\n",
    "conf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(conf_matrix)\n",
    "\n",
    "# Plot confusion matrix\n",
    "sns.heatmap(conf_matrix, annot = True, fmt = \".3f\", square = True, cmap = plt.cm.Blues)\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.title('Confusion matrix')\n",
    "plt.tight_layout()\n",
    "\n",
    "# TASK 4\n",
    "# Compute evaluation metrics\n",
    "print(metrics.accuracy_score(y_test, y_pred)) # accuracy\n",
    "print(1 - metrics.accuracy_score(y_test, y_pred)) # error\n",
    "print(metrics.precision_score(y_test, y_pred, average = None)) # precision\n",
    "print(metrics.recall_score(y_test, y_pred, average = None)) # recall\n",
    "print(metrics.f1_score(y_test, y_pred, average = None)) # F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive Bayes with 11 parameters\n",
    "model = GaussianNB()\n",
    "x = x_train[[\"TotalPop\", \"White\", \"Black\",\"Median Household Income\",\"IncomePerCap\",\"Poverty\",\"ChildPoverty\", \n",
    "             \"County Unemployment Rate for 2013\", 'Percent Population with age between 75 and over', 'Production','Carpool']]\n",
    "y = y_train\n",
    "model.fit(x,y)\n",
    "\n",
    "# Predict class labels using Naive Bayes classifier\n",
    "x_test = x_val[[\"TotalPop\", \"White\", \"Black\",\"Median Household Income\",\"IncomePerCap\",\"Poverty\",\"ChildPoverty\", \n",
    "                \"County Unemployment Rate for 2013\", 'Percent Population with age between 75 and over', 'Production','Carpool']]\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "# Compute confusion matrix\n",
    "y_test = y_val\n",
    "conf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(conf_matrix)\n",
    "\n",
    "# Plot confusion matrix\n",
    "sns.heatmap(conf_matrix, annot = True, fmt = \".3f\", square = True, cmap = plt.cm.Blues)\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.title('Confusion matrix')\n",
    "plt.tight_layout()\n",
    "\n",
    "# TASK 4\n",
    "# Compute evaluation metrics\n",
    "print(metrics.accuracy_score(y_test, y_pred)) # accuracy\n",
    "print(1 - metrics.accuracy_score(y_test, y_pred)) # error\n",
    "print(metrics.precision_score(y_test, y_pred, average = None)) # precision\n",
    "print(metrics.recall_score(y_test, y_pred, average = None)) # recall\n",
    "print(metrics.f1_score(y_test, y_pred, average = None)) # F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive Bayes with 11 parameters\n",
    "model = GaussianNB()\n",
    "x = x_train[[\"TotalPop\", \"White\", \"Black\",\"Median Household Income\",\"IncomePerCap\",\"Poverty\",\"ChildPoverty\", \n",
    "             \"County Unemployment Rate for 2013\", 'Percent Population with age between 75 and over', 'Production','Transit']]\n",
    "y = y_train\n",
    "model.fit(x,y)\n",
    "\n",
    "# Predict class labels using Naive Bayes classifier\n",
    "x_test = x_val[[\"TotalPop\", \"White\", \"Black\",\"Median Household Income\",\"IncomePerCap\",\"Poverty\",\"ChildPoverty\", \n",
    "                \"County Unemployment Rate for 2013\", 'Percent Population with age between 75 and over', 'Production','Transit']]\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "# Compute confusion matrix\n",
    "y_test = y_val\n",
    "conf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(conf_matrix)\n",
    "\n",
    "# Plot confusion matrix\n",
    "sns.heatmap(conf_matrix, annot = True, fmt = \".3f\", square = True, cmap = plt.cm.Blues)\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.title('Confusion matrix')\n",
    "plt.tight_layout()\n",
    "\n",
    "# TASK 4\n",
    "# Compute evaluation metrics\n",
    "print(metrics.accuracy_score(y_test, y_pred)) # accuracy\n",
    "print(1 - metrics.accuracy_score(y_test, y_pred)) # error\n",
    "print(metrics.precision_score(y_test, y_pred, average = None)) # precision\n",
    "print(metrics.recall_score(y_test, y_pred, average = None)) # recall\n",
    "print(metrics.f1_score(y_test, y_pred, average = None)) # F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive Bayes with 11 parameters\n",
    "model = GaussianNB()\n",
    "x = x_train[[\"TotalPop\", \"White\", \"Black\",\"Median Household Income\",\"IncomePerCap\",\"Poverty\",\"ChildPoverty\", \n",
    "             \"County Unemployment Rate for 2013\", 'Percent Population with age between 75 and over', 'Production','Walk']]\n",
    "y = y_train\n",
    "model.fit(x,y)\n",
    "\n",
    "# Predict class labels using Naive Bayes classifier\n",
    "x_test = x_val[[\"TotalPop\", \"White\", \"Black\",\"Median Household Income\",\"IncomePerCap\",\"Poverty\",\"ChildPoverty\", \n",
    "                \"County Unemployment Rate for 2013\", 'Percent Population with age between 75 and over', 'Production','Walk']]\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "# Compute confusion matrix\n",
    "y_test = y_val\n",
    "conf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(conf_matrix)\n",
    "\n",
    "# Plot confusion matrix\n",
    "sns.heatmap(conf_matrix, annot = True, fmt = \".3f\", square = True, cmap = plt.cm.Blues)\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.title('Confusion matrix')\n",
    "plt.tight_layout()\n",
    "\n",
    "# TASK 4\n",
    "# Compute evaluation metrics\n",
    "print(metrics.accuracy_score(y_test, y_pred)) # accuracy\n",
    "print(1 - metrics.accuracy_score(y_test, y_pred)) # error\n",
    "print(metrics.precision_score(y_test, y_pred, average = None)) # precision\n",
    "print(metrics.recall_score(y_test, y_pred, average = None)) # recall\n",
    "print(metrics.f1_score(y_test, y_pred, average = None)) # F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive Bayes with 11 parameters\n",
    "model = GaussianNB()\n",
    "x = x_train[[\"TotalPop\", \"White\", \"Black\",\"Median Household Income\",\"IncomePerCap\",\"Poverty\",\"ChildPoverty\", \n",
    "             \"County Unemployment Rate for 2013\", 'Percent Population with age between 75 and over', 'Production','WorkAtHome']]\n",
    "y = y_train\n",
    "model.fit(x,y)\n",
    "\n",
    "# Predict class labels using Naive Bayes classifier\n",
    "x_test = x_val[[\"TotalPop\", \"White\", \"Black\",\"Median Household Income\",\"IncomePerCap\",\"Poverty\",\"ChildPoverty\", \n",
    "                \"County Unemployment Rate for 2013\", 'Percent Population with age between 75 and over', 'Production','WorkAtHome']]\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "# Compute confusion matrix\n",
    "y_test = y_val\n",
    "conf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(conf_matrix)\n",
    "\n",
    "# Plot confusion matrix\n",
    "sns.heatmap(conf_matrix, annot = True, fmt = \".3f\", square = True, cmap = plt.cm.Blues)\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.title('Confusion matrix')\n",
    "plt.tight_layout()\n",
    "\n",
    "# TASK 4\n",
    "# Compute evaluation metrics\n",
    "print(metrics.accuracy_score(y_test, y_pred)) # accuracy\n",
    "print(1 - metrics.accuracy_score(y_test, y_pred)) # error\n",
    "print(metrics.precision_score(y_test, y_pred, average = None)) # precision\n",
    "print(metrics.recall_score(y_test, y_pred, average = None)) # recall\n",
    "print(metrics.f1_score(y_test, y_pred, average = None)) # F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive Bayes with 11 parameters\n",
    "model = GaussianNB()\n",
    "x = x_train[[\"TotalPop\", \"White\", \"Black\",\"Median Household Income\",\"IncomePerCap\",\"Poverty\",\"ChildPoverty\", \n",
    "             \"County Unemployment Rate for 2013\", 'Percent Population with age between 75 and over', 'Production','Mean Commute Time']]\n",
    "y = y_train\n",
    "model.fit(x,y)\n",
    "\n",
    "# Predict class labels using Naive Bayes classifier\n",
    "x_test = x_val[[\"TotalPop\", \"White\", \"Black\",\"Median Household Income\",\"IncomePerCap\",\"Poverty\",\"ChildPoverty\", \n",
    "                \"County Unemployment Rate for 2013\", 'Percent Population with age between 75 and over', 'Production','Mean Commute Time']]\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "# Compute confusion matrix\n",
    "y_test = y_val\n",
    "conf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(conf_matrix)\n",
    "\n",
    "# Plot confusion matrix\n",
    "sns.heatmap(conf_matrix, annot = True, fmt = \".3f\", square = True, cmap = plt.cm.Blues)\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.title('Confusion matrix')\n",
    "plt.tight_layout()\n",
    "\n",
    "# TASK 4\n",
    "# Compute evaluation metrics\n",
    "print(metrics.accuracy_score(y_test, y_pred)) # accuracy\n",
    "print(1 - metrics.accuracy_score(y_test, y_pred)) # error\n",
    "print(metrics.precision_score(y_test, y_pred, average = None)) # precision\n",
    "print(metrics.recall_score(y_test, y_pred, average = None)) # recall\n",
    "print(metrics.f1_score(y_test, y_pred, average = None)) # F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive Bayes with 11 parameters\n",
    "model = GaussianNB()\n",
    "x = x_train[[\"TotalPop\", \"White\", \"Black\",\"Median Household Income\",\"IncomePerCap\",\"Poverty\",\"ChildPoverty\", \n",
    "             \"County Unemployment Rate for 2013\", 'Percent Population with age between 75 and over', 'Production',\n",
    "             'State Unemployment rate for 2013']]\n",
    "y = y_train\n",
    "model.fit(x,y)\n",
    "\n",
    "# Predict class labels using Naive Bayes classifier\n",
    "x_test = x_val[[\"TotalPop\", \"White\", \"Black\",\"Median Household Income\",\"IncomePerCap\",\"Poverty\",\"ChildPoverty\", \n",
    "                \"County Unemployment Rate for 2013\", 'Percent Population with age between 75 and over', 'Production',\n",
    "                'State Unemployment rate for 2013']]\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "# Compute confusion matrix\n",
    "y_test = y_val\n",
    "conf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(conf_matrix)\n",
    "\n",
    "# Plot confusion matrix\n",
    "sns.heatmap(conf_matrix, annot = True, fmt = \".3f\", square = True, cmap = plt.cm.Blues)\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.title('Confusion matrix')\n",
    "plt.tight_layout()\n",
    "\n",
    "# TASK 4\n",
    "# Compute evaluation metrics\n",
    "print(metrics.accuracy_score(y_test, y_pred)) # accuracy\n",
    "print(1 - metrics.accuracy_score(y_test, y_pred)) # error\n",
    "print(metrics.precision_score(y_test, y_pred, average = None)) # precision\n",
    "print(metrics.recall_score(y_test, y_pred, average = None)) # recall\n",
    "print(metrics.f1_score(y_test, y_pred, average = None)) # F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive Bayes with 11 parameters\n",
    "model = GaussianNB()\n",
    "x = x_train[[\"County Unemployment Rate for 2013\"]]\n",
    "y = y_train\n",
    "Classifier = model.fit(x,y)\n",
    "\n",
    "# Predict class labels using Naive Bayes classifier\n",
    "x_test = x_val[[\"County Unemployment Rate for 2013\"]]\n",
    "y_pred = Classifier.predict(x_test)\n",
    "\n",
    "# Compute confusion matrix\n",
    "y_test = y_val\n",
    "conf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(conf_matrix)\n",
    "\n",
    "# Plot confusion matrix\n",
    "sns.heatmap(conf_matrix, annot = True, fmt = \".3f\", square = True, cmap = plt.cm.Blues)\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.title('Confusion matrix')\n",
    "plt.tight_layout()\n",
    "\n",
    "# TASK 4\n",
    "# Compute evaluation metrics\n",
    "print(metrics.accuracy_score(y_test, y_pred)) # accuracy\n",
    "print(1 - metrics.accuracy_score(y_test, y_pred)) # error\n",
    "print(metrics.precision_score(y_test, y_pred, average = None)) # precision\n",
    "print(metrics.recall_score(y_test, y_pred, average = None)) # recall\n",
    "print(metrics.f1_score(y_test, y_pred, average = None)) # F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#In case of Naive Bayes, the classifier with parameter:\n",
    "# \"County Unemployment Rate for 2013\"\n",
    "# is the best one with F1 Scores:\n",
    "# [0.7625     0.86728395 0.74166667]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K nearest neighbour with k = 3 and 1 parameter\n",
    "model = KNeighborsClassifier(n_neighbors = 3)\n",
    "x = x_train[[\"TotalPop\"]]\n",
    "y = y_train\n",
    "model.fit(x, y)\n",
    "\n",
    "# Predict class labels using KNearest Neighbour\n",
    "x_test = x_val[[\"TotalPop\"]]\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "\n",
    "# Compute confusion matrix\n",
    "y_test = y_val\n",
    "conf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(conf_matrix)\n",
    "\n",
    "# Plot confusion matrix\n",
    "sns.heatmap(conf_matrix, annot = True, fmt = \".3f\", square = True, cmap = plt.cm.Blues)\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.title('Confusion matrix')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Compute evaluation metrics\n",
    "print(metrics.accuracy_score(y_test, y_pred)) # accuracy\n",
    "print(1 - metrics.accuracy_score(y_test, y_pred)) # error\n",
    "print(metrics.precision_score(y_test, y_pred, average = None)) # precision\n",
    "print(metrics.recall_score(y_test, y_pred, average = None)) # recall\n",
    "print(metrics.f1_score(y_test, y_pred, average = None)) # F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K nearest neighbour with k = 3 and 2 parameters\n",
    "model = KNeighborsClassifier(n_neighbors = 3)\n",
    "x = x_train[[\"TotalPop\", \"Men\"]]\n",
    "y = y_train\n",
    "model.fit(x, y)\n",
    "\n",
    "# Predict class labels using KNearest Neighbour\n",
    "x_test = x_val[[\"TotalPop\", \"Men\"]]\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "\n",
    "# Compute confusion matrix\n",
    "y_test = y_val\n",
    "conf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(conf_matrix)\n",
    "\n",
    "# Plot confusion matrix\n",
    "sns.heatmap(conf_matrix, annot = True, fmt = \".3f\", square = True, cmap = plt.cm.Blues)\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.title('Confusion matrix')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Compute evaluation metrics\n",
    "print(metrics.accuracy_score(y_test, y_pred)) # accuracy\n",
    "print(1 - metrics.accuracy_score(y_test, y_pred)) # error\n",
    "print(metrics.precision_score(y_test, y_pred, average = None)) # precision\n",
    "print(metrics.recall_score(y_test, y_pred, average = None)) # recall\n",
    "print(\"F1 Score is: \")\n",
    "print(metrics.f1_score(y_test, y_pred, average = None)) # F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K nearest neighbour with k = 3 and 3 parameters\n",
    "model = KNeighborsClassifier(n_neighbors = 3)\n",
    "x = x_train[[\"TotalPop\", \"Men\", \"White\"]]\n",
    "y = y_train\n",
    "model.fit(x, y)\n",
    "\n",
    "# Predict class labels using KNearest Neighbour\n",
    "x_test = x_val[[\"TotalPop\", \"Men\", \"White\"]]\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "\n",
    "# Compute confusion matrix\n",
    "y_test = y_val\n",
    "conf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(conf_matrix)\n",
    "\n",
    "# Plot confusion matrix\n",
    "sns.heatmap(conf_matrix, annot = True, fmt = \".3f\", square = True, cmap = plt.cm.Blues)\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.title('Confusion matrix')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Compute evaluation metrics\n",
    "print(metrics.accuracy_score(y_test, y_pred)) # accuracy\n",
    "print(1 - metrics.accuracy_score(y_test, y_pred)) # error\n",
    "print(metrics.precision_score(y_test, y_pred, average = None)) # precision\n",
    "print(metrics.recall_score(y_test, y_pred, average = None)) # recall\n",
    "print(\"F1 Score is: \")\n",
    "print(metrics.f1_score(y_test, y_pred, average = None)) # F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K nearest neighbour with k = 3 and 4 parameters\n",
    "model = KNeighborsClassifier(n_neighbors = 3)\n",
    "x = x_train[[\"TotalPop\", \"Men\", \"White\", \"Black\"]]\n",
    "y = y_train\n",
    "model.fit(x, y)\n",
    "\n",
    "# Predict class labels using KNearest Neighbour\n",
    "x_test = x_val[[\"TotalPop\", \"Men\", \"White\", \"Black\"]]\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "\n",
    "# Compute confusion matrix\n",
    "y_test = y_val\n",
    "conf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(conf_matrix)\n",
    "\n",
    "# Plot confusion matrix\n",
    "sns.heatmap(conf_matrix, annot = True, fmt = \".3f\", square = True, cmap = plt.cm.Blues)\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.title('Confusion matrix')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Compute evaluation metrics\n",
    "print(metrics.accuracy_score(y_test, y_pred)) # accuracy\n",
    "print(1 - metrics.accuracy_score(y_test, y_pred)) # error\n",
    "print(metrics.precision_score(y_test, y_pred, average = None)) # precision\n",
    "print(metrics.recall_score(y_test, y_pred, average = None)) # recall\n",
    "print(\"F1 Score is: \")\n",
    "print(metrics.f1_score(y_test, y_pred, average = None)) # F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K nearest neighbour with k = 3 and 4 parameters\n",
    "model = KNeighborsClassifier(n_neighbors = 3)\n",
    "x = x_train[[\"TotalPop\", \"Men\", \"White\", \"Citizen Voting Age Pop\"]]\n",
    "y = y_train\n",
    "model.fit(x, y)\n",
    "\n",
    "# Predict class labels using KNearest Neighbour\n",
    "x_test = x_val[[\"TotalPop\", \"Men\", \"White\", 'Citizen Voting Age Pop']]\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "\n",
    "# Compute confusion matrix\n",
    "y_test = y_val\n",
    "conf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(conf_matrix)\n",
    "\n",
    "# Plot confusion matrix\n",
    "sns.heatmap(conf_matrix, annot = True, fmt = \".3f\", square = True, cmap = plt.cm.Blues)\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.title('Confusion matrix')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Compute evaluation metrics\n",
    "print(metrics.accuracy_score(y_test, y_pred)) # accuracy\n",
    "print(1 - metrics.accuracy_score(y_test, y_pred)) # error\n",
    "print(metrics.precision_score(y_test, y_pred, average = None)) # precision\n",
    "print(metrics.recall_score(y_test, y_pred, average = None)) # recall\n",
    "print(\"F1 Score is: \")\n",
    "print(metrics.f1_score(y_test, y_pred, average = None)) # F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K nearest neighbour with k = 3 and 5 parameters\n",
    "model = KNeighborsClassifier(n_neighbors = 3)\n",
    "x = x_train[[\"TotalPop\", \"Men\", \"White\", \"Median Household Income\",'Citizen Voting Age Pop']]\n",
    "y = y_train\n",
    "model.fit(x, y)\n",
    "\n",
    "# Predict class labels using KNearest Neighbour\n",
    "x_test = x_val[[\"TotalPop\", \"Men\", \"White\", 'Median Household Income', 'Citizen Voting Age Pop']]\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "\n",
    "# Compute confusion matrix\n",
    "y_test = y_val\n",
    "conf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(conf_matrix)\n",
    "\n",
    "# Plot confusion matrix\n",
    "sns.heatmap(conf_matrix, annot = True, fmt = \".3f\", square = True, cmap = plt.cm.Blues)\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.title('Confusion matrix')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Compute evaluation metrics\n",
    "print(metrics.accuracy_score(y_test, y_pred)) # accuracy\n",
    "print(1 - metrics.accuracy_score(y_test, y_pred)) # error\n",
    "print(metrics.precision_score(y_test, y_pred, average = None)) # precision\n",
    "print(metrics.recall_score(y_test, y_pred, average = None)) # recall\n",
    "print(\"F1 Score is: \")\n",
    "print(metrics.f1_score(y_test, y_pred, average = None)) # F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K nearest neighbour with k = 3 and 6 parameters\n",
    "model = KNeighborsClassifier(n_neighbors = 3)\n",
    "x = x_train[[\"TotalPop\", \"Men\", \"White\", \"Median Household Income\",'Citizen Voting Age Pop', \"IncomePerCap\"]]\n",
    "y = y_train\n",
    "model.fit(x, y)\n",
    "\n",
    "# Predict class labels using KNearest Neighbour\n",
    "x_test = x_val[[\"TotalPop\", \"Men\", \"White\", \"Median Household Income\",'Citizen Voting Age Pop', \"IncomePerCap\"]]\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "\n",
    "# Compute confusion matrix\n",
    "y_test = y_val\n",
    "conf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(conf_matrix)\n",
    "\n",
    "# Plot confusion matrix\n",
    "sns.heatmap(conf_matrix, annot = True, fmt = \".3f\", square = True, cmap = plt.cm.Blues)\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.title('Confusion matrix')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Compute evaluation metrics\n",
    "print(metrics.accuracy_score(y_test, y_pred)) # accuracy\n",
    "print(1 - metrics.accuracy_score(y_test, y_pred)) # error\n",
    "print(metrics.precision_score(y_test, y_pred, average = None)) # precision\n",
    "print(metrics.recall_score(y_test, y_pred, average = None)) # recall\n",
    "print(\"F1 Score is: \")\n",
    "print(metrics.f1_score(y_test, y_pred, average = None)) # F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K nearest neighbour with k = 3 and 6 parameters\n",
    "model = KNeighborsClassifier(n_neighbors = 3)\n",
    "x = x_train[[\"TotalPop\", \"Men\", \"White\", \"Median Household Income\",'Citizen Voting Age Pop', \"Poverty\"]]\n",
    "y = y_train\n",
    "model.fit(x, y)\n",
    "\n",
    "# Predict class labels using KNearest Neighbour\n",
    "x_test = x_val[[\"TotalPop\", \"Men\", \"White\", \"Median Household Income\",'Citizen Voting Age Pop', \"Poverty\"]]\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "\n",
    "# Compute confusion matrix\n",
    "y_test = y_val\n",
    "conf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(conf_matrix)\n",
    "\n",
    "# Plot confusion matrix\n",
    "sns.heatmap(conf_matrix, annot = True, fmt = \".3f\", square = True, cmap = plt.cm.Blues)\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.title('Confusion matrix')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Compute evaluation metrics\n",
    "print(metrics.accuracy_score(y_test, y_pred)) # accuracy\n",
    "print(1 - metrics.accuracy_score(y_test, y_pred)) # error\n",
    "print(metrics.precision_score(y_test, y_pred, average = None)) # precision\n",
    "print(metrics.recall_score(y_test, y_pred, average = None)) # recall\n",
    "print(\"F1 Score is: \")\n",
    "print(metrics.f1_score(y_test, y_pred, average = None)) # F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K nearest neighbour with k = 3 and 6 parameters\n",
    "model = KNeighborsClassifier(n_neighbors = 3)\n",
    "x = x_train[[\"TotalPop\", \"Men\", \"White\", \"Median Household Income\",'Citizen Voting Age Pop', \"ChildPoverty\"]]\n",
    "y = y_train\n",
    "model.fit(x, y)\n",
    "\n",
    "# Predict class labels using KNearest Neighbour\n",
    "x_test = x_val[[\"TotalPop\", \"Men\", \"White\", \"Median Household Income\",'Citizen Voting Age Pop', \"ChildPoverty\"]]\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "\n",
    "# Compute confusion matrix\n",
    "y_test = y_val\n",
    "conf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(conf_matrix)\n",
    "\n",
    "# Plot confusion matrix\n",
    "sns.heatmap(conf_matrix, annot = True, fmt = \".3f\", square = True, cmap = plt.cm.Blues)\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.title('Confusion matrix')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Compute evaluation metrics\n",
    "print(metrics.accuracy_score(y_test, y_pred)) # accuracy\n",
    "print(1 - metrics.accuracy_score(y_test, y_pred)) # error\n",
    "print(metrics.precision_score(y_test, y_pred, average = None)) # precision\n",
    "print(metrics.recall_score(y_test, y_pred, average = None)) # recall\n",
    "print(\"F1 Score is: \")\n",
    "print(metrics.f1_score(y_test, y_pred, average = None)) # F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K nearest neighbour with k = 3 and 6 parameters\n",
    "model = KNeighborsClassifier(n_neighbors = 3)\n",
    "x = x_train[[\"TotalPop\", \"Men\", \"White\", \"Median Household Income\",'Citizen Voting Age Pop', 'County Unemployment Rate for 2013']]\n",
    "y = y_train\n",
    "model.fit(x, y)\n",
    "\n",
    "# Predict class labels using KNearest Neighbour\n",
    "x_test = x_val[[\"TotalPop\", \"Men\", \"White\", \"Median Household Income\",'Citizen Voting Age Pop', 'County Unemployment Rate for 2013']]\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "\n",
    "# Compute confusion matrix\n",
    "y_test = y_val\n",
    "conf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(conf_matrix)\n",
    "\n",
    "# Plot confusion matrix\n",
    "sns.heatmap(conf_matrix, annot = True, fmt = \".3f\", square = True, cmap = plt.cm.Blues)\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.title('Confusion matrix')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Compute evaluation metrics\n",
    "print(metrics.accuracy_score(y_test, y_pred)) # accuracy\n",
    "print(1 - metrics.accuracy_score(y_test, y_pred)) # error\n",
    "print(metrics.precision_score(y_test, y_pred, average = None)) # precision\n",
    "print(metrics.recall_score(y_test, y_pred, average = None)) # recall\n",
    "print(\"F1 Score is: \")\n",
    "print(metrics.f1_score(y_test, y_pred, average = None)) # F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K nearest neighbour with k = 3 and 7 parameters\n",
    "model = KNeighborsClassifier(n_neighbors = 3)\n",
    "x = x_train[[\"TotalPop\", \"Men\", \"White\", \"Median Household Income\",'Citizen Voting Age Pop', \n",
    "             'County Unemployment Rate for 2013', 'Percent Population with age between 16 and 44']]\n",
    "y = y_train\n",
    "model.fit(x, y)\n",
    "\n",
    "# Predict class labels using KNearest Neighbour\n",
    "x_test = x_val[[\"TotalPop\", \"Men\", \"White\", \"Median Household Income\",'Citizen Voting Age Pop', \n",
    "                'County Unemployment Rate for 2013', 'Percent Population with age between 16 and 44']]\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "\n",
    "# Compute confusion matrix\n",
    "y_test = y_val\n",
    "conf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(conf_matrix)\n",
    "\n",
    "# Plot confusion matrix\n",
    "sns.heatmap(conf_matrix, annot = True, fmt = \".3f\", square = True, cmap = plt.cm.Blues)\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.title('Confusion matrix')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Compute evaluation metrics\n",
    "print(metrics.accuracy_score(y_test, y_pred)) # accuracy\n",
    "print(1 - metrics.accuracy_score(y_test, y_pred)) # error\n",
    "print(metrics.precision_score(y_test, y_pred, average = None)) # precision\n",
    "print(metrics.recall_score(y_test, y_pred, average = None)) # recall\n",
    "print(\"F1 Score is: \")\n",
    "print(metrics.f1_score(y_test, y_pred, average = None)) # F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K nearest neighbour with k = 3 and 7 parameters\n",
    "model = KNeighborsClassifier(n_neighbors = 3)\n",
    "x = x_train[[\"TotalPop\", \"Men\", \"White\", \"Median Household Income\",'Citizen Voting Age Pop', \n",
    "             'County Unemployment Rate for 2013','Percent Population with age between 45 and 74']]\n",
    "y = y_train\n",
    "model.fit(x, y)\n",
    "\n",
    "# Predict class labels using KNearest Neighbour\n",
    "x_test = x_val[[\"TotalPop\", \"Men\", \"White\", \"Median Household Income\",'Citizen Voting Age Pop', \n",
    "             'County Unemployment Rate for 2013', 'Percent Population with age between 45 and 74']]\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "\n",
    "# Compute confusion matrix\n",
    "y_test = y_val\n",
    "conf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(conf_matrix)\n",
    "\n",
    "# Plot confusion matrix\n",
    "sns.heatmap(conf_matrix, annot = True, fmt = \".3f\", square = True, cmap = plt.cm.Blues)\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.title('Confusion matrix')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Compute evaluation metrics\n",
    "print(metrics.accuracy_score(y_test, y_pred)) # accuracy\n",
    "print(1 - metrics.accuracy_score(y_test, y_pred)) # error\n",
    "print(metrics.precision_score(y_test, y_pred, average = None)) # precision\n",
    "print(metrics.recall_score(y_test, y_pred, average = None)) # recall\n",
    "print(\"F1 Score is: \")\n",
    "print(metrics.f1_score(y_test, y_pred, average = None)) # F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K nearest neighbour with k = 3 and 7 parameters\n",
    "model = KNeighborsClassifier(n_neighbors = 3)\n",
    "x = x_train[[\"TotalPop\", \"Men\", \"White\", \"Median Household Income\",'Citizen Voting Age Pop', \n",
    "             'County Unemployment Rate for 2013','Percent Population with age between 75 and over']]\n",
    "y = y_train\n",
    "model.fit(x, y)\n",
    "\n",
    "# Predict class labels using KNearest Neighbour\n",
    "x_test = x_val[[\"TotalPop\", \"Men\", \"White\", \"Median Household Income\",'Citizen Voting Age Pop', \n",
    "             'County Unemployment Rate for 2013', 'Percent Population with age between 75 and over']]\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "\n",
    "# Compute confusion matrix\n",
    "y_test = y_val\n",
    "conf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(conf_matrix)\n",
    "\n",
    "# Plot confusion matrix\n",
    "sns.heatmap(conf_matrix, annot = True, fmt = \".3f\", square = True, cmap = plt.cm.Blues)\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.title('Confusion matrix')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Compute evaluation metrics\n",
    "print(metrics.accuracy_score(y_test, y_pred)) # accuracy\n",
    "print(1 - metrics.accuracy_score(y_test, y_pred)) # error\n",
    "print(metrics.precision_score(y_test, y_pred, average = None)) # precision\n",
    "print(metrics.recall_score(y_test, y_pred, average = None)) # recall\n",
    "print(\"F1 Score is: \")\n",
    "print(metrics.f1_score(y_test, y_pred, average = None)) # F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K nearest neighbour with k = 3 and 7 parameters\n",
    "model = KNeighborsClassifier(n_neighbors = 3)\n",
    "x = x_train[[\"TotalPop\", \"Men\", \"White\", \"Median Household Income\",'Citizen Voting Age Pop', \n",
    "             'County Unemployment Rate for 2013', 'Hispanic']]\n",
    "y = y_train\n",
    "model.fit(x, y)\n",
    "\n",
    "# Predict class labels using KNearest Neighbour\n",
    "x_test = x_val[[\"TotalPop\", \"Men\", \"White\", \"Median Household Income\",'Citizen Voting Age Pop', \n",
    "             'County Unemployment Rate for 2013', 'Hispanic']]\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "\n",
    "# Compute confusion matrix\n",
    "y_test = y_val\n",
    "conf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(conf_matrix)\n",
    "\n",
    "# Plot confusion matrix\n",
    "sns.heatmap(conf_matrix, annot = True, fmt = \".3f\", square = True, cmap = plt.cm.Blues)\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.title('Confusion matrix')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Compute evaluation metrics\n",
    "print(metrics.accuracy_score(y_test, y_pred)) # accuracy\n",
    "print(1 - metrics.accuracy_score(y_test, y_pred)) # error\n",
    "print(metrics.precision_score(y_test, y_pred, average = None)) # precision\n",
    "print(metrics.recall_score(y_test, y_pred, average = None)) # recall\n",
    "print(\"F1 Score is: \")\n",
    "print(metrics.f1_score(y_test, y_pred, average = None)) # F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K nearest neighbour with k = 3 and 7 parameters\n",
    "model = KNeighborsClassifier(n_neighbors = 3)\n",
    "x = x_train[[\"TotalPop\", \"Men\", \"White\", \"Median Household Income\",'Citizen Voting Age Pop', \n",
    "             'County Unemployment Rate for 2013', 'Native']]\n",
    "y = y_train\n",
    "model.fit(x, y)\n",
    "\n",
    "# Predict class labels using KNearest Neighbour\n",
    "x_test = x_val[[\"TotalPop\", \"Men\", \"White\", \"Median Household Income\",'Citizen Voting Age Pop', \n",
    "             'County Unemployment Rate for 2013', 'Native']]\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "\n",
    "# Compute confusion matrix\n",
    "y_test = y_val\n",
    "conf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(conf_matrix)\n",
    "\n",
    "# Plot confusion matrix\n",
    "sns.heatmap(conf_matrix, annot = True, fmt = \".3f\", square = True, cmap = plt.cm.Blues)\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.title('Confusion matrix')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Compute evaluation metrics\n",
    "print(metrics.accuracy_score(y_test, y_pred)) # accuracy\n",
    "print(1 - metrics.accuracy_score(y_test, y_pred)) # error\n",
    "print(metrics.precision_score(y_test, y_pred, average = None)) # precision\n",
    "print(metrics.recall_score(y_test, y_pred, average = None)) # recall\n",
    "print(\"F1 Score is: \")\n",
    "print(metrics.f1_score(y_test, y_pred, average = None)) # F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K nearest neighbour with k = 3 and 7 parameters\n",
    "model = KNeighborsClassifier(n_neighbors = 3)\n",
    "x = x_train[[\"TotalPop\", \"Men\", \"White\", \"Median Household Income\",'Citizen Voting Age Pop', \n",
    "             'County Unemployment Rate for 2013', 'Asian']]\n",
    "y = y_train\n",
    "model.fit(x, y)\n",
    "\n",
    "# Predict class labels using KNearest Neighbour\n",
    "x_test = x_val[[\"TotalPop\", \"Men\", \"White\", \"Median Household Income\",'Citizen Voting Age Pop', \n",
    "             'County Unemployment Rate for 2013', 'Asian']]\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "\n",
    "# Compute confusion matrix\n",
    "y_test = y_val\n",
    "conf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(conf_matrix)\n",
    "\n",
    "# Plot confusion matrix\n",
    "sns.heatmap(conf_matrix, annot = True, fmt = \".3f\", square = True, cmap = plt.cm.Blues)\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.title('Confusion matrix')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Compute evaluation metrics\n",
    "print(metrics.accuracy_score(y_test, y_pred)) # accuracy\n",
    "print(1 - metrics.accuracy_score(y_test, y_pred)) # error\n",
    "print(metrics.precision_score(y_test, y_pred, average = None)) # precision\n",
    "print(metrics.recall_score(y_test, y_pred, average = None)) # recall\n",
    "print(\"F1 Score is: \")\n",
    "print(metrics.f1_score(y_test, y_pred, average = None)) # F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K nearest neighbour with k = 3 and 7 parameters\n",
    "model = KNeighborsClassifier(n_neighbors = 3)\n",
    "x = x_train[[\"TotalPop\", \"Men\", \"White\", \"Median Household Income\",'Citizen Voting Age Pop', \n",
    "             'County Unemployment Rate for 2013', 'Pacific']]\n",
    "y = y_train\n",
    "model.fit(x, y)\n",
    "\n",
    "# Predict class labels using KNearest Neighbour\n",
    "x_test = x_val[[\"TotalPop\", \"Men\", \"White\", \"Median Household Income\",'Citizen Voting Age Pop', \n",
    "             'County Unemployment Rate for 2013', 'Pacific']]\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "\n",
    "# Compute confusion matrix\n",
    "y_test = y_val\n",
    "conf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(conf_matrix)\n",
    "\n",
    "# Plot confusion matrix\n",
    "sns.heatmap(conf_matrix, annot = True, fmt = \".3f\", square = True, cmap = plt.cm.Blues)\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.title('Confusion matrix')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Compute evaluation metrics\n",
    "print(metrics.accuracy_score(y_test, y_pred)) # accuracy\n",
    "print(1 - metrics.accuracy_score(y_test, y_pred)) # error\n",
    "print(metrics.precision_score(y_test, y_pred, average = None)) # precision\n",
    "print(metrics.recall_score(y_test, y_pred, average = None)) # recall\n",
    "print(\"F1 Score is: \")\n",
    "print(metrics.f1_score(y_test, y_pred, average = None)) # F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K nearest neighbour with k = 3 and 7 parameters\n",
    "model = KNeighborsClassifier(n_neighbors = 3)\n",
    "x = x_train[[\"TotalPop\", \"Men\", \"White\", \"Median Household Income\",'Citizen Voting Age Pop', \n",
    "             'County Unemployment Rate for 2013', 'Professional']]\n",
    "y = y_train\n",
    "model.fit(x, y)\n",
    "\n",
    "# Predict class labels using KNearest Neighbour\n",
    "x_test = x_val[[\"TotalPop\", \"Men\", \"White\", \"Median Household Income\",'Citizen Voting Age Pop', \n",
    "             'County Unemployment Rate for 2013', 'Professional']]\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "\n",
    "# Compute confusion matrix\n",
    "y_test = y_val\n",
    "conf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(conf_matrix)\n",
    "\n",
    "# Plot confusion matrix\n",
    "sns.heatmap(conf_matrix, annot = True, fmt = \".3f\", square = True, cmap = plt.cm.Blues)\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.title('Confusion matrix')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Compute evaluation metrics\n",
    "print(metrics.accuracy_score(y_test, y_pred)) # accuracy\n",
    "print(1 - metrics.accuracy_score(y_test, y_pred)) # error\n",
    "print(metrics.precision_score(y_test, y_pred, average = None)) # precision\n",
    "print(metrics.recall_score(y_test, y_pred, average = None)) # recall\n",
    "print(\"F1 Score is: \")\n",
    "print(metrics.f1_score(y_test, y_pred, average = None)) # F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K nearest neighbour with k = 3 and 7 parameters\n",
    "model = KNeighborsClassifier(n_neighbors = 3)\n",
    "x = x_train[[\"TotalPop\", \"Men\", \"White\", \"Median Household Income\",'Citizen Voting Age Pop', \n",
    "             'County Unemployment Rate for 2013', 'Service']]\n",
    "y = y_train\n",
    "model.fit(x, y)\n",
    "\n",
    "# Predict class labels using KNearest Neighbour\n",
    "x_test = x_val[[\"TotalPop\", \"Men\", \"White\", \"Median Household Income\",'Citizen Voting Age Pop', \n",
    "             'County Unemployment Rate for 2013', 'Service']]\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "\n",
    "# Compute confusion matrix\n",
    "y_test = y_val\n",
    "conf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(conf_matrix)\n",
    "\n",
    "# Plot confusion matrix\n",
    "sns.heatmap(conf_matrix, annot = True, fmt = \".3f\", square = True, cmap = plt.cm.Blues)\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.title('Confusion matrix')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Compute evaluation metrics\n",
    "print(metrics.accuracy_score(y_test, y_pred)) # accuracy\n",
    "print(1 - metrics.accuracy_score(y_test, y_pred)) # error\n",
    "print(metrics.precision_score(y_test, y_pred, average = None)) # precision\n",
    "print(metrics.recall_score(y_test, y_pred, average = None)) # recall\n",
    "print(\"F1 Score is: \")\n",
    "print(metrics.f1_score(y_test, y_pred, average = None)) # F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K nearest neighbour with k = 3 and 7 parameters\n",
    "model = KNeighborsClassifier(n_neighbors = 3)\n",
    "x = x_train[[\"TotalPop\", \"Men\", \"White\", \"Median Household Income\",'Citizen Voting Age Pop', \n",
    "             'County Unemployment Rate for 2013', 'Office']]\n",
    "y = y_train\n",
    "model.fit(x, y)\n",
    "\n",
    "# Predict class labels using KNearest Neighbour\n",
    "x_test = x_val[[\"TotalPop\", \"Men\", \"White\", \"Median Household Income\",'Citizen Voting Age Pop', \n",
    "             'County Unemployment Rate for 2013', 'Office']]\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "\n",
    "# Compute confusion matrix\n",
    "y_test = y_val\n",
    "conf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(conf_matrix)\n",
    "\n",
    "# Plot confusion matrix\n",
    "sns.heatmap(conf_matrix, annot = True, fmt = \".3f\", square = True, cmap = plt.cm.Blues)\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.title('Confusion matrix')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Compute evaluation metrics\n",
    "print(metrics.accuracy_score(y_test, y_pred)) # accuracy\n",
    "print(1 - metrics.accuracy_score(y_test, y_pred)) # error\n",
    "print(metrics.precision_score(y_test, y_pred, average = None)) # precision\n",
    "print(metrics.recall_score(y_test, y_pred, average = None)) # recall\n",
    "print(\"F1 Score is: \")\n",
    "print(metrics.f1_score(y_test, y_pred, average = None)) # F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K nearest neighbour with k = 3 and 7 parameters\n",
    "model = KNeighborsClassifier(n_neighbors = 3)\n",
    "x = x_train[[\"TotalPop\", \"Men\", \"White\", \"Median Household Income\",'Citizen Voting Age Pop', \n",
    "             'County Unemployment Rate for 2013', 'Construction']]\n",
    "y = y_train\n",
    "model.fit(x, y)\n",
    "\n",
    "# Predict class labels using KNearest Neighbour\n",
    "x_test = x_val[[\"TotalPop\", \"Men\", \"White\", \"Median Household Income\",'Citizen Voting Age Pop', \n",
    "             'County Unemployment Rate for 2013', 'Construction']]\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "\n",
    "# Compute confusion matrix\n",
    "y_test = y_val\n",
    "conf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(conf_matrix)\n",
    "\n",
    "# Plot confusion matrix\n",
    "sns.heatmap(conf_matrix, annot = True, fmt = \".3f\", square = True, cmap = plt.cm.Blues)\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.title('Confusion matrix')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Compute evaluation metrics\n",
    "print(metrics.accuracy_score(y_test, y_pred)) # accuracy\n",
    "print(1 - metrics.accuracy_score(y_test, y_pred)) # error\n",
    "print(metrics.precision_score(y_test, y_pred, average = None)) # precision\n",
    "print(metrics.recall_score(y_test, y_pred, average = None)) # recall\n",
    "print(\"F1 Score is: \")\n",
    "print(metrics.f1_score(y_test, y_pred, average = None)) # F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K nearest neighbour with k = 3 and 7 parameters\n",
    "model = KNeighborsClassifier(n_neighbors = 3)\n",
    "x = x_train[[\"TotalPop\", \"Men\", \"White\", \"Median Household Income\",'Citizen Voting Age Pop', \n",
    "             'County Unemployment Rate for 2013', 'Production']]\n",
    "y = y_train\n",
    "model.fit(x, y)\n",
    "\n",
    "# Predict class labels using KNearest Neighbour\n",
    "x_test = x_val[[\"TotalPop\", \"Men\", \"White\", \"Median Household Income\",'Citizen Voting Age Pop', \n",
    "             'County Unemployment Rate for 2013', 'Production']]\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "\n",
    "# Compute confusion matrix\n",
    "y_test = y_val\n",
    "conf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(conf_matrix)\n",
    "\n",
    "# Plot confusion matrix\n",
    "sns.heatmap(conf_matrix, annot = True, fmt = \".3f\", square = True, cmap = plt.cm.Blues)\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.title('Confusion matrix')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Compute evaluation metrics\n",
    "print(metrics.accuracy_score(y_test, y_pred)) # accuracy\n",
    "print(1 - metrics.accuracy_score(y_test, y_pred)) # error\n",
    "print(metrics.precision_score(y_test, y_pred, average = None)) # precision\n",
    "print(metrics.recall_score(y_test, y_pred, average = None)) # recall\n",
    "print(\"F1 Score is: \")\n",
    "print(metrics.f1_score(y_test, y_pred, average = None)) # F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K nearest neighbour with k = 3 and 7 parameters\n",
    "model = KNeighborsClassifier(n_neighbors = 3)\n",
    "x = x_train[[\"TotalPop\", \"Men\", \"White\", \"Median Household Income\",'Citizen Voting Age Pop', \n",
    "             'County Unemployment Rate for 2013', 'Drive']]\n",
    "y = y_train\n",
    "model.fit(x, y)\n",
    "\n",
    "# Predict class labels using KNearest Neighbour\n",
    "x_test = x_val[[\"TotalPop\", \"Men\", \"White\", \"Median Household Income\",'Citizen Voting Age Pop', \n",
    "             'County Unemployment Rate for 2013', 'Drive']]\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "\n",
    "# Compute confusion matrix\n",
    "y_test = y_val\n",
    "conf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(conf_matrix)\n",
    "\n",
    "# Plot confusion matrix\n",
    "sns.heatmap(conf_matrix, annot = True, fmt = \".3f\", square = True, cmap = plt.cm.Blues)\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.title('Confusion matrix')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Compute evaluation metrics\n",
    "print(metrics.accuracy_score(y_test, y_pred)) # accuracy\n",
    "print(1 - metrics.accuracy_score(y_test, y_pred)) # error\n",
    "print(metrics.precision_score(y_test, y_pred, average = None)) # precision\n",
    "print(metrics.recall_score(y_test, y_pred, average = None)) # recall\n",
    "print(\"F1 Score is: \")\n",
    "print(metrics.f1_score(y_test, y_pred, average = None)) # F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K nearest neighbour with k = 3 and 7 parameters\n",
    "model = KNeighborsClassifier(n_neighbors = 3)\n",
    "x = x_train[[\"TotalPop\", \"Men\", \"White\", \"Median Household Income\",'Citizen Voting Age Pop', \n",
    "             'County Unemployment Rate for 2013', 'Carpool']]\n",
    "y = y_train\n",
    "model.fit(x, y)\n",
    "\n",
    "# Predict class labels using KNearest Neighbour\n",
    "x_test = x_val[[\"TotalPop\", \"Men\", \"White\", \"Median Household Income\",'Citizen Voting Age Pop', \n",
    "             'County Unemployment Rate for 2013', 'Carpool']]\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "\n",
    "# Compute confusion matrix\n",
    "y_test = y_val\n",
    "conf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(conf_matrix)\n",
    "\n",
    "# Plot confusion matrix\n",
    "sns.heatmap(conf_matrix, annot = True, fmt = \".3f\", square = True, cmap = plt.cm.Blues)\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.title('Confusion matrix')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Compute evaluation metrics\n",
    "print(metrics.accuracy_score(y_test, y_pred)) # accuracy\n",
    "print(1 - metrics.accuracy_score(y_test, y_pred)) # error\n",
    "print(metrics.precision_score(y_test, y_pred, average = None)) # precision\n",
    "print(metrics.recall_score(y_test, y_pred, average = None)) # recall\n",
    "print(\"F1 Score is: \")\n",
    "print(metrics.f1_score(y_test, y_pred, average = None)) # F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K nearest neighbour with k = 3 and 7 parameters\n",
    "model = KNeighborsClassifier(n_neighbors = 3)\n",
    "x = x_train[[\"TotalPop\", \"Men\", \"White\", \"Median Household Income\",'Citizen Voting Age Pop', \n",
    "             'County Unemployment Rate for 2013', 'Transit']]\n",
    "y = y_train\n",
    "model.fit(x, y)\n",
    "\n",
    "# Predict class labels using KNearest Neighbour\n",
    "x_test = x_val[[\"TotalPop\", \"Men\", \"White\", \"Median Household Income\",'Citizen Voting Age Pop', \n",
    "             'County Unemployment Rate for 2013', 'Transit']]\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "\n",
    "# Compute confusion matrix\n",
    "y_test = y_val\n",
    "conf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(conf_matrix)\n",
    "\n",
    "# Plot confusion matrix\n",
    "sns.heatmap(conf_matrix, annot = True, fmt = \".3f\", square = True, cmap = plt.cm.Blues)\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.title('Confusion matrix')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Compute evaluation metrics\n",
    "print(metrics.accuracy_score(y_test, y_pred)) # accuracy\n",
    "print(1 - metrics.accuracy_score(y_test, y_pred)) # error\n",
    "print(metrics.precision_score(y_test, y_pred, average = None)) # precision\n",
    "print(metrics.recall_score(y_test, y_pred, average = None)) # recall\n",
    "print(\"F1 Score is: \")\n",
    "print(metrics.f1_score(y_test, y_pred, average = None)) # F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K nearest neighbour with k = 3 and 7 parameters\n",
    "model = KNeighborsClassifier(n_neighbors = 3)\n",
    "x = x_train[[\"TotalPop\", \"Men\", \"White\", \"Median Household Income\",'Citizen Voting Age Pop', \n",
    "             'County Unemployment Rate for 2013', 'Walk']]\n",
    "y = y_train\n",
    "model.fit(x, y)\n",
    "\n",
    "# Predict class labels using KNearest Neighbour\n",
    "x_test = x_val[[\"TotalPop\", \"Men\", \"White\", \"Median Household Income\",'Citizen Voting Age Pop', \n",
    "             'County Unemployment Rate for 2013', 'Walk']]\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "\n",
    "# Compute confusion matrix\n",
    "y_test = y_val\n",
    "conf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(conf_matrix)\n",
    "\n",
    "# Plot confusion matrix\n",
    "sns.heatmap(conf_matrix, annot = True, fmt = \".3f\", square = True, cmap = plt.cm.Blues)\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.title('Confusion matrix')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Compute evaluation metrics\n",
    "print(metrics.accuracy_score(y_test, y_pred)) # accuracy\n",
    "print(1 - metrics.accuracy_score(y_test, y_pred)) # error\n",
    "print(metrics.precision_score(y_test, y_pred, average = None)) # precision\n",
    "print(metrics.recall_score(y_test, y_pred, average = None)) # recall\n",
    "print(\"F1 Score is: \")\n",
    "print(metrics.f1_score(y_test, y_pred, average = None)) # F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K nearest neighbour with k = 3 and 7 parameters\n",
    "model = KNeighborsClassifier(n_neighbors = 3)\n",
    "x = x_train[[\"TotalPop\", \"Men\", \"White\", \"Median Household Income\",'Citizen Voting Age Pop', \n",
    "             'County Unemployment Rate for 2013', 'WorkAtHome']]\n",
    "y = y_train\n",
    "model.fit(x, y)\n",
    "\n",
    "# Predict class labels using KNearest Neighbour\n",
    "x_test = x_val[[\"TotalPop\", \"Men\", \"White\", \"Median Household Income\",'Citizen Voting Age Pop', \n",
    "             'County Unemployment Rate for 2013', 'WorkAtHome']]\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "\n",
    "# Compute confusion matrix\n",
    "y_test = y_val\n",
    "conf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(conf_matrix)\n",
    "\n",
    "# Plot confusion matrix\n",
    "sns.heatmap(conf_matrix, annot = True, fmt = \".3f\", square = True, cmap = plt.cm.Blues)\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.title('Confusion matrix')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Compute evaluation metrics\n",
    "print(metrics.accuracy_score(y_test, y_pred)) # accuracy\n",
    "print(1 - metrics.accuracy_score(y_test, y_pred)) # error\n",
    "print(metrics.precision_score(y_test, y_pred, average = None)) # precision\n",
    "print(metrics.recall_score(y_test, y_pred, average = None)) # recall\n",
    "print(\"F1 Score is: \")\n",
    "print(metrics.f1_score(y_test, y_pred, average = None)) # F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K nearest neighbour with k = 3 and 7 parameters\n",
    "model = KNeighborsClassifier(n_neighbors = 3)\n",
    "x = x_train[[\"TotalPop\", \"Men\", \"White\", \"Median Household Income\",'Citizen Voting Age Pop', \n",
    "             'County Unemployment Rate for 2013', 'Mean Commute Time']]\n",
    "y = y_train\n",
    "model.fit(x, y)\n",
    "\n",
    "# Predict class labels using KNearest Neighbour\n",
    "x_test = x_val[[\"TotalPop\", \"Men\", \"White\", \"Median Household Income\",'Citizen Voting Age Pop', \n",
    "             'County Unemployment Rate for 2013', 'Mean Commute Time']]\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "\n",
    "# Compute confusion matrix\n",
    "y_test = y_val\n",
    "conf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(conf_matrix)\n",
    "\n",
    "# Plot confusion matrix\n",
    "sns.heatmap(conf_matrix, annot = True, fmt = \".3f\", square = True, cmap = plt.cm.Blues)\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.title('Confusion matrix')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Compute evaluation metrics\n",
    "print(metrics.accuracy_score(y_test, y_pred)) # accuracy\n",
    "print(1 - metrics.accuracy_score(y_test, y_pred)) # error\n",
    "print(metrics.precision_score(y_test, y_pred, average = None)) # precision\n",
    "print(metrics.recall_score(y_test, y_pred, average = None)) # recall\n",
    "print(\"F1 Score is: \")\n",
    "print(metrics.f1_score(y_test, y_pred, average = None)) # F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K nearest neighbour with k = 3 and 7 parameters\n",
    "model = KNeighborsClassifier(n_neighbors = 3)\n",
    "x = x_train[[\"TotalPop\", \"Men\", \"White\", \"Median Household Income\",'Citizen Voting Age Pop', \n",
    "             'County Unemployment Rate for 2013', 'State Unemployment rate for 2013']]\n",
    "y = y_train\n",
    "model.fit(x, y)\n",
    "\n",
    "# Predict class labels using KNearest Neighbour\n",
    "x_test = x_val[[\"TotalPop\", \"Men\", \"White\", \"Median Household Income\",'Citizen Voting Age Pop', \n",
    "             'County Unemployment Rate for 2013', 'State Unemployment rate for 2013']]\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "\n",
    "# Compute confusion matrix\n",
    "y_test = y_val\n",
    "conf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(conf_matrix)\n",
    "\n",
    "# Plot confusion matrix\n",
    "sns.heatmap(conf_matrix, annot = True, fmt = \".3f\", square = True, cmap = plt.cm.Blues)\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.title('Confusion matrix')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Compute evaluation metrics\n",
    "print(metrics.accuracy_score(y_test, y_pred)) # accuracy\n",
    "print(1 - metrics.accuracy_score(y_test, y_pred)) # error\n",
    "print(metrics.precision_score(y_test, y_pred, average = None)) # precision\n",
    "print(metrics.recall_score(y_test, y_pred, average = None)) # recall\n",
    "print(\"F1 Score is: \")\n",
    "print(metrics.f1_score(y_test, y_pred, average = None)) # F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K nearest neighbour with k = 3 and 'County Unemployment Rate for 2013'\n",
    "model = KNeighborsClassifier(n_neighbors = 3)\n",
    "x = x_train[['County Unemployment Rate for 2013']]\n",
    "y = y_train\n",
    "model.fit(x, y)\n",
    "\n",
    "# Predict class labels using KNearest Neighbour\n",
    "x_test = x_val[['County Unemployment Rate for 2013']]\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "\n",
    "# Compute confusion matrix\n",
    "y_test = y_val\n",
    "conf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(conf_matrix)\n",
    "\n",
    "# Plot confusion matrix\n",
    "sns.heatmap(conf_matrix, annot = True, fmt = \".3f\", square = True, cmap = plt.cm.Blues)\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.title('Confusion matrix')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Compute evaluation metrics\n",
    "print(metrics.accuracy_score(y_test, y_pred)) # accuracy\n",
    "print(1 - metrics.accuracy_score(y_test, y_pred)) # error\n",
    "print(metrics.precision_score(y_test, y_pred, average = None)) # precision\n",
    "print(metrics.recall_score(y_test, y_pred, average = None)) # recall\n",
    "print(\"F1 Score is: \")\n",
    "print(metrics.f1_score(y_test, y_pred, average = None)) # F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K nearest neighbour with k = 3 and all parameters\n",
    "model = KNeighborsClassifier(n_neighbors = 3)\n",
    "x = x_train\n",
    "y = y_train\n",
    "model.fit(x, y)\n",
    "\n",
    "# Predict class labels using KNearest Neighbour\n",
    "x_test = x_val\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "\n",
    "# Compute confusion matrix\n",
    "y_test = y_val\n",
    "conf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(conf_matrix)\n",
    "\n",
    "# Plot confusion matrix\n",
    "sns.heatmap(conf_matrix, annot = True, fmt = \".3f\", square = True, cmap = plt.cm.Blues)\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.title('Confusion matrix')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Compute evaluation metrics\n",
    "print(metrics.accuracy_score(y_test, y_pred)) # accuracy\n",
    "print(1 - metrics.accuracy_score(y_test, y_pred)) # error\n",
    "print(metrics.precision_score(y_test, y_pred, average = None)) # precision\n",
    "print(metrics.recall_score(y_test, y_pred, average = None)) # recall\n",
    "print(\"F1 Score is: \")\n",
    "print(metrics.f1_score(y_test, y_pred, average = None)) # F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K nearest neighbour with k = 3 and 'County Unemployment Rate for 2013'\n",
    "model = KNeighborsClassifier(n_neighbors = 3)\n",
    "x = x_train[['County Unemployment Rate for 2013']]\n",
    "y = y_train\n",
    "model.fit(x, y)\n",
    "\n",
    "# Predict class labels using KNearest Neighbour\n",
    "x_test = x_val[['County Unemployment Rate for 2013']]\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "\n",
    "# Compute confusion matrix\n",
    "y_test = y_val\n",
    "conf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(conf_matrix)\n",
    "\n",
    "# Plot confusion matrix\n",
    "sns.heatmap(conf_matrix, annot = True, fmt = \".3f\", square = True, cmap = plt.cm.Blues)\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.title('Confusion matrix')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Compute evaluation metrics\n",
    "print(metrics.accuracy_score(y_test, y_pred)) # accuracy\n",
    "print(1 - metrics.accuracy_score(y_test, y_pred)) # error\n",
    "print(metrics.precision_score(y_test, y_pred, average = None)) # precision\n",
    "print(metrics.recall_score(y_test, y_pred, average = None)) # recall\n",
    "print(\"F1 Score is: \")\n",
    "print(metrics.f1_score(y_test, y_pred, average = None)) # F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In case of K_Nearest Neighbour with k=3, the classifier with \n",
    "# \"TotalPop\", \"Men\", \"White\", \"Median Household Income\",'Citizen Voting Age Pop', \n",
    "#  'County Unemployment Rate for 2013' is the best one with F1 Scores\n",
    "# [0.75294118 0.85714286 0.70403587]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K nearest neighbour K = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K = 5 \n",
    "#\"TotalPop\",\"Poverty\", \"Men\", 'Black', 'Citizen Voting Age Pop'\n",
    "# 0.73170732 0.51141553 0.50980392\n",
    "\n",
    "#\"County Unemployment Rate for 2013\"\n",
    "#0.83563748 0.65502183 0.69273743"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K nearest neighbour with k = 4 and 1 parameter\n",
    "model = KNeighborsClassifier(n_neighbors = 4)\n",
    "x = x_train[[\"TotalPop\"]]\n",
    "y = y_train\n",
    "model.fit(x, y)\n",
    "\n",
    "# Predict class labels using KNearest Neighbour\n",
    "x_test = x_val[[\"TotalPop\"]]\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "\n",
    "# Compute confusion matrix\n",
    "y_test = y_val\n",
    "conf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(conf_matrix)\n",
    "\n",
    "# Plot confusion matrix\n",
    "sns.heatmap(conf_matrix, annot = True, fmt = \".3f\", square = True, cmap = plt.cm.Blues)\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.title('Confusion matrix')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Compute evaluation metrics\n",
    "print(metrics.accuracy_score(y_test, y_pred)) # accuracy\n",
    "print(1 - metrics.accuracy_score(y_test, y_pred)) # error\n",
    "print(metrics.precision_score(y_test, y_pred, average = None)) # precision\n",
    "print(metrics.recall_score(y_test, y_pred, average = None)) # recall\n",
    "print(metrics.f1_score(y_test, y_pred, average = None)) # F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.63196126 0.26775956 0.0625    TotalPop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K nearest neighbour with k = 4 and 2 parameter\n",
    "model = KNeighborsClassifier(n_neighbors = 4)\n",
    "x = x_train[[\"TotalPop\",\"Men\"]]\n",
    "y = y_train\n",
    "model.fit(x, y)\n",
    "\n",
    "# Predict class labels using KNearest Neighbour\n",
    "x_test = x_val[[\"TotalPop\",\"Men\"]]\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "\n",
    "# Compute confusion matrix\n",
    "y_test = y_val\n",
    "conf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(conf_matrix)\n",
    "\n",
    "# Plot confusion matrix\n",
    "sns.heatmap(conf_matrix, annot = True, fmt = \".3f\", square = True, cmap = plt.cm.Blues)\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.title('Confusion matrix')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Compute evaluation metrics\n",
    "print(metrics.accuracy_score(y_test, y_pred)) # accuracy\n",
    "print(1 - metrics.accuracy_score(y_test, y_pred)) # error\n",
    "print(metrics.precision_score(y_test, y_pred, average = None)) # precision\n",
    "print(metrics.recall_score(y_test, y_pred, average = None)) # recall\n",
    "print(metrics.f1_score(y_test, y_pred, average = None)) # F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K nearest neighbour with k = 4 and 2 parameter\n",
    "model = KNeighborsClassifier(n_neighbors = 4)\n",
    "x = x_train[[\"TotalPop\",\"White\"]]\n",
    "y = y_train\n",
    "model.fit(x, y)\n",
    "\n",
    "# Predict class labels using KNearest Neighbour\n",
    "x_test = x_val[[\"TotalPop\",\"White\"]]\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "\n",
    "# Compute confusion matrix\n",
    "y_test = y_val\n",
    "conf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(conf_matrix)\n",
    "\n",
    "# Plot confusion matrix\n",
    "sns.heatmap(conf_matrix, annot = True, fmt = \".3f\", square = True, cmap = plt.cm.Blues)\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.title('Confusion matrix')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Compute evaluation metrics\n",
    "print(metrics.accuracy_score(y_test, y_pred)) # accuracy\n",
    "print(1 - metrics.accuracy_score(y_test, y_pred)) # error\n",
    "print(metrics.precision_score(y_test, y_pred, average = None)) # precision\n",
    "print(metrics.recall_score(y_test, y_pred, average = None)) # recall\n",
    "print(metrics.f1_score(y_test, y_pred, average = None)) # F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K nearest neighbour with k = 4 and 2 parameter\n",
    "model = KNeighborsClassifier(n_neighbors = 4)\n",
    "x = x_train[[\"TotalPop\",\"Black\"]]\n",
    "y = y_train\n",
    "model.fit(x, y)\n",
    "\n",
    "# Predict class labels using KNearest Neighbour\n",
    "x_test = x_val[[\"TotalPop\",\"Black\"]]\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "\n",
    "# Compute confusion matrix\n",
    "y_test = y_val\n",
    "conf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(conf_matrix)\n",
    "\n",
    "# Plot confusion matrix\n",
    "sns.heatmap(conf_matrix, annot = True, fmt = \".3f\", square = True, cmap = plt.cm.Blues)\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.title('Confusion matrix')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Compute evaluation metrics\n",
    "print(metrics.accuracy_score(y_test, y_pred)) # accuracy\n",
    "print(1 - metrics.accuracy_score(y_test, y_pred)) # error\n",
    "print(metrics.precision_score(y_test, y_pred, average = None)) # precision\n",
    "print(metrics.recall_score(y_test, y_pred, average = None)) # recall\n",
    "print(metrics.f1_score(y_test, y_pred, average = None)) # F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K nearest neighbour with k = 4 and 2 parameter\n",
    "model = KNeighborsClassifier(n_neighbors = 4)\n",
    "x = x_train[[\"TotalPop\",\"Citizen Voting Age Pop\"]]\n",
    "y = y_train\n",
    "model.fit(x, y)\n",
    "\n",
    "# Predict class labels using KNearest Neighbour\n",
    "x_test = x_val[[\"TotalPop\",\"Citizen Voting Age Pop\"]]\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "\n",
    "# Compute confusion matrix\n",
    "y_test = y_val\n",
    "conf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(conf_matrix)\n",
    "\n",
    "# Plot confusion matrix\n",
    "sns.heatmap(conf_matrix, annot = True, fmt = \".3f\", square = True, cmap = plt.cm.Blues)\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.title('Confusion matrix')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Compute evaluation metrics\n",
    "print(metrics.accuracy_score(y_test, y_pred)) # accuracy\n",
    "print(1 - metrics.accuracy_score(y_test, y_pred)) # error\n",
    "print(metrics.precision_score(y_test, y_pred, average = None)) # precision\n",
    "print(metrics.recall_score(y_test, y_pred, average = None)) # recall\n",
    "print(metrics.f1_score(y_test, y_pred, average = None)) # F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K nearest neighbour with k = 4 and 2 parameter\n",
    "model = KNeighborsClassifier(n_neighbors = 4)\n",
    "x = x_train[[\"TotalPop\",\"Median Household Income\"]]\n",
    "y = y_train\n",
    "model.fit(x, y)\n",
    "\n",
    "# Predict class labels using KNearest Neighbour\n",
    "x_test = x_val[[\"TotalPop\",\"Median Household Income\"]]\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "\n",
    "# Compute confusion matrix\n",
    "y_test = y_val\n",
    "conf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(conf_matrix)\n",
    "\n",
    "# Plot confusion matrix\n",
    "sns.heatmap(conf_matrix, annot = True, fmt = \".3f\", square = True, cmap = plt.cm.Blues)\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.title('Confusion matrix')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Compute evaluation metrics\n",
    "print(metrics.accuracy_score(y_test, y_pred)) # accuracy\n",
    "print(1 - metrics.accuracy_score(y_test, y_pred)) # error\n",
    "print(metrics.precision_score(y_test, y_pred, average = None)) # precision\n",
    "print(metrics.recall_score(y_test, y_pred, average = None)) # recall\n",
    "print(metrics.f1_score(y_test, y_pred, average = None)) # F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K nearest neighbour with k = 4 and 2 parameter\n",
    "model = KNeighborsClassifier(n_neighbors = 4)\n",
    "x = x_train[[\"TotalPop\",\"IncomePerCap\"]]\n",
    "y = y_train\n",
    "model.fit(x, y)\n",
    "\n",
    "# Predict class labels using KNearest Neighbour\n",
    "x_test = x_val[[\"TotalPop\",\"IncomePerCap\"]]\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "\n",
    "# Compute confusion matrix\n",
    "y_test = y_val\n",
    "conf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(conf_matrix)\n",
    "\n",
    "# Plot confusion matrix\n",
    "sns.heatmap(conf_matrix, annot = True, fmt = \".3f\", square = True, cmap = plt.cm.Blues)\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.title('Confusion matrix')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Compute evaluation metrics\n",
    "print(metrics.accuracy_score(y_test, y_pred)) # accuracy\n",
    "print(1 - metrics.accuracy_score(y_test, y_pred)) # error\n",
    "print(metrics.precision_score(y_test, y_pred, average = None)) # precision\n",
    "print(metrics.recall_score(y_test, y_pred, average = None)) # recall\n",
    "print(metrics.f1_score(y_test, y_pred, average = None)) # F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K nearest neighbour with k = 4 and 2 parameter\n",
    "model = KNeighborsClassifier(n_neighbors = 4)\n",
    "x = x_train[[\"TotalPop\",\"Poverty\"]]\n",
    "y = y_train\n",
    "model.fit(x, y)\n",
    "\n",
    "# Predict class labels using KNearest Neighbour\n",
    "x_test = x_val[[\"TotalPop\",\"Poverty\"]]\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "\n",
    "# Compute confusion matrix\n",
    "y_test = y_val\n",
    "conf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(conf_matrix)\n",
    "\n",
    "# Plot confusion matrix\n",
    "sns.heatmap(conf_matrix, annot = True, fmt = \".3f\", square = True, cmap = plt.cm.Blues)\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.title('Confusion matrix')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Compute evaluation metrics\n",
    "print(metrics.accuracy_score(y_test, y_pred)) # accuracy\n",
    "print(1 - metrics.accuracy_score(y_test, y_pred)) # error\n",
    "print(metrics.precision_score(y_test, y_pred, average = None)) # precision\n",
    "print(metrics.recall_score(y_test, y_pred, average = None)) # recall\n",
    "print(metrics.f1_score(y_test, y_pred, average = None)) # F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K nearest neighbour with k = 4 and 2 parameter\n",
    "model = KNeighborsClassifier(n_neighbors = 4)\n",
    "x = x_train[[\"TotalPop\",\"ChildPoverty\"]]\n",
    "y = y_train\n",
    "model.fit(x, y)\n",
    "\n",
    "# Predict class labels using KNearest Neighbour\n",
    "x_test = x_val[[\"TotalPop\",\"ChildPoverty\"]]\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "\n",
    "# Compute confusion matrix\n",
    "y_test = y_val\n",
    "conf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(conf_matrix)\n",
    "\n",
    "# Plot confusion matrix\n",
    "sns.heatmap(conf_matrix, annot = True, fmt = \".3f\", square = True, cmap = plt.cm.Blues)\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.title('Confusion matrix')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Compute evaluation metrics\n",
    "print(metrics.accuracy_score(y_test, y_pred)) # accuracy\n",
    "print(1 - metrics.accuracy_score(y_test, y_pred)) # error\n",
    "print(metrics.precision_score(y_test, y_pred, average = None)) # precision\n",
    "print(metrics.recall_score(y_test, y_pred, average = None)) # recall\n",
    "print(metrics.f1_score(y_test, y_pred, average = None)) # F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k = 4, 2 parameter\n",
    "# 0.65566038 0.2716763  0.04255319\n",
    "# 0.69356873 0.35040431 0.38709677\n",
    "# 0.69849246 0.32844575 0.35761589\n",
    "# 0.65051903 0.21587302 0.01886792\n",
    "# 0.74669868 0.39655172 0.31775701\n",
    "# 0.7357631  0.26666667 0.4\n",
    "# 0.72275862 0.4725537  0.48611111\t\"TotalPop\",\"Poverty\"\n",
    "# 0.7057101  0.45475638 0.42528736"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K nearest neighbour with k = 4 and 3 parameter\n",
    "model = KNeighborsClassifier(n_neighbors = 4)\n",
    "x = x_train[[\"TotalPop\",\"Poverty\",\"Men\"]]\n",
    "y = y_train\n",
    "model.fit(x, y)\n",
    "\n",
    "# Predict class labels using KNearest Neighbour\n",
    "x_test = x_val[[\"TotalPop\",\"Poverty\",\"Men\"]]\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "\n",
    "# Compute confusion matrix\n",
    "y_test = y_val\n",
    "conf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(conf_matrix)\n",
    "\n",
    "# Plot confusion matrix\n",
    "sns.heatmap(conf_matrix, annot = True, fmt = \".3f\", square = True, cmap = plt.cm.Blues)\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.title('Confusion matrix')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Compute evaluation metrics\n",
    "print(metrics.accuracy_score(y_test, y_pred)) # accuracy\n",
    "print(1 - metrics.accuracy_score(y_test, y_pred)) # error\n",
    "print(metrics.precision_score(y_test, y_pred, average = None)) # precision\n",
    "print(metrics.recall_score(y_test, y_pred, average = None)) # recall\n",
    "print(metrics.f1_score(y_test, y_pred, average = None)) # F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K nearest neighbour with k = 4 and 3 parameter\n",
    "model = KNeighborsClassifier(n_neighbors = 4)\n",
    "x = x_train[[\"TotalPop\",\"Poverty\",\"White\"]]\n",
    "y = y_train\n",
    "model.fit(x, y)\n",
    "\n",
    "# Predict class labels using KNearest Neighbour\n",
    "x_test = x_val[[\"TotalPop\",\"Poverty\",\"White\"]]\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "\n",
    "# Compute confusion matrix\n",
    "y_test = y_val\n",
    "conf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(conf_matrix)\n",
    "\n",
    "# Plot confusion matrix\n",
    "sns.heatmap(conf_matrix, annot = True, fmt = \".3f\", square = True, cmap = plt.cm.Blues)\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.title('Confusion matrix')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Compute evaluation metrics\n",
    "print(metrics.accuracy_score(y_test, y_pred)) # accuracy\n",
    "print(1 - metrics.accuracy_score(y_test, y_pred)) # error\n",
    "print(metrics.precision_score(y_test, y_pred, average = None)) # precision\n",
    "print(metrics.recall_score(y_test, y_pred, average = None)) # recall\n",
    "print(metrics.f1_score(y_test, y_pred, average = None)) # F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K nearest neighbour with k = 4 and 3 parameter\n",
    "model = KNeighborsClassifier(n_neighbors = 4)\n",
    "x = x_train[[\"TotalPop\",\"Poverty\",\"Black\"]]\n",
    "y = y_train\n",
    "model.fit(x, y)\n",
    "\n",
    "# Predict class labels using KNearest Neighbour\n",
    "x_test = x_val[[\"TotalPop\",\"Poverty\",\"Black\"]]\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "\n",
    "# Compute confusion matrix\n",
    "y_test = y_val\n",
    "conf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(conf_matrix)\n",
    "\n",
    "# Plot confusion matrix\n",
    "sns.heatmap(conf_matrix, annot = True, fmt = \".3f\", square = True, cmap = plt.cm.Blues)\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.title('Confusion matrix')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Compute evaluation metrics\n",
    "print(metrics.accuracy_score(y_test, y_pred)) # accuracy\n",
    "print(1 - metrics.accuracy_score(y_test, y_pred)) # error\n",
    "print(metrics.precision_score(y_test, y_pred, average = None)) # precision\n",
    "print(metrics.recall_score(y_test, y_pred, average = None)) # recall\n",
    "print(metrics.f1_score(y_test, y_pred, average = None)) # F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K nearest neighbour with k = 4 and 3 parameter\n",
    "model = KNeighborsClassifier(n_neighbors = 4)\n",
    "x = x_train[[\"TotalPop\",\"Poverty\",\"Citizen Voting Age Pop\"]]\n",
    "y = y_train\n",
    "model.fit(x, y)\n",
    "\n",
    "# Predict class labels using KNearest Neighbour\n",
    "x_test = x_val[[\"TotalPop\",\"Poverty\",\"Citizen Voting Age Pop\"]]\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "\n",
    "# Compute confusion matrix\n",
    "y_test = y_val\n",
    "conf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(conf_matrix)\n",
    "\n",
    "# Plot confusion matrix\n",
    "sns.heatmap(conf_matrix, annot = True, fmt = \".3f\", square = True, cmap = plt.cm.Blues)\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.title('Confusion matrix')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Compute evaluation metrics\n",
    "print(metrics.accuracy_score(y_test, y_pred)) # accuracy\n",
    "print(1 - metrics.accuracy_score(y_test, y_pred)) # error\n",
    "print(metrics.precision_score(y_test, y_pred, average = None)) # precision\n",
    "print(metrics.recall_score(y_test, y_pred, average = None)) # recall\n",
    "print(metrics.f1_score(y_test, y_pred, average = None)) # F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K nearest neighbour with k = 4 and 3 parameter\n",
    "model = KNeighborsClassifier(n_neighbors = 4)\n",
    "x = x_train[[\"TotalPop\",\"Poverty\",\"Median Household Income\"]]\n",
    "y = y_train\n",
    "model.fit(x, y)\n",
    "\n",
    "# Predict class labels using KNearest Neighbour\n",
    "x_test = x_val[[\"TotalPop\",\"Poverty\",\"Median Household Income\"]]\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "\n",
    "# Compute confusion matrix\n",
    "y_test = y_val\n",
    "conf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(conf_matrix)\n",
    "\n",
    "# Plot confusion matrix\n",
    "sns.heatmap(conf_matrix, annot = True, fmt = \".3f\", square = True, cmap = plt.cm.Blues)\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.title('Confusion matrix')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Compute evaluation metrics\n",
    "print(metrics.accuracy_score(y_test, y_pred)) # accuracy\n",
    "print(1 - metrics.accuracy_score(y_test, y_pred)) # error\n",
    "print(metrics.precision_score(y_test, y_pred, average = None)) # precision\n",
    "print(metrics.recall_score(y_test, y_pred, average = None)) # recall\n",
    "print(metrics.f1_score(y_test, y_pred, average = None)) # F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K nearest neighbour with k = 4 and 3 parameter\n",
    "model = KNeighborsClassifier(n_neighbors = 4)\n",
    "x = x_train[[\"TotalPop\",\"Poverty\",\"IncomePerCap\"]]\n",
    "y = y_train\n",
    "model.fit(x, y)\n",
    "\n",
    "# Predict class labels using KNearest Neighbour\n",
    "x_test = x_val[[\"TotalPop\",\"Poverty\",\"IncomePerCap\"]]\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "\n",
    "# Compute confusion matrix\n",
    "y_test = y_val\n",
    "conf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(conf_matrix)\n",
    "\n",
    "# Plot confusion matrix\n",
    "sns.heatmap(conf_matrix, annot = True, fmt = \".3f\", square = True, cmap = plt.cm.Blues)\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.title('Confusion matrix')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Compute evaluation metrics\n",
    "print(metrics.accuracy_score(y_test, y_pred)) # accuracy\n",
    "print(1 - metrics.accuracy_score(y_test, y_pred)) # error\n",
    "print(metrics.precision_score(y_test, y_pred, average = None)) # precision\n",
    "print(metrics.recall_score(y_test, y_pred, average = None)) # recall\n",
    "print(metrics.f1_score(y_test, y_pred, average = None)) # F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K nearest neighbour with k = 4 and 3 parameter\n",
    "model = KNeighborsClassifier(n_neighbors = 4)\n",
    "x = x_train[[\"TotalPop\",\"Poverty\",\"ChildPoverty\"]]\n",
    "y = y_train\n",
    "model.fit(x, y)\n",
    "\n",
    "# Predict class labels using KNearest Neighbour\n",
    "x_test = x_val[[\"TotalPop\",\"Poverty\",\"ChildPoverty\"]]\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "\n",
    "# Compute confusion matrix\n",
    "y_test = y_val\n",
    "conf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(conf_matrix)\n",
    "\n",
    "# Plot confusion matrix\n",
    "sns.heatmap(conf_matrix, annot = True, fmt = \".3f\", square = True, cmap = plt.cm.Blues)\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.title('Confusion matrix')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Compute evaluation metrics\n",
    "print(metrics.accuracy_score(y_test, y_pred)) # accuracy\n",
    "print(1 - metrics.accuracy_score(y_test, y_pred)) # error\n",
    "print(metrics.precision_score(y_test, y_pred, average = None)) # precision\n",
    "print(metrics.recall_score(y_test, y_pred, average = None)) # recall\n",
    "print(metrics.f1_score(y_test, y_pred, average = None)) # F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k = 4, 3 parameter\n",
    "# 0.72099448 0.47281324 0.4822695\t\t\"TotalPop\",\"Poverty\",\"Men\"\n",
    "# 0.71900826 0.47596154 0.50684932\n",
    "# 0.72931276 0.47867299 0.44444444\n",
    "# 0.72650771 0.48598131 0.46258503\n",
    "# 0.72405063 0.39130435 0.35384615\n",
    "# 0.71931956 0.30177515 0.44094488\n",
    "# 0.73713491 0.46808511 0.39726027\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K nearest neighbour with k = 4 and 4 parameter\n",
    "model = KNeighborsClassifier(n_neighbors = 4)\n",
    "x = x_train[[\"TotalPop\",\"Poverty\",\"Men\", \"White\"]]\n",
    "y = y_train\n",
    "model.fit(x, y)\n",
    "\n",
    "# Predict class labels using KNearest Neighbour\n",
    "x_test = x_val[[\"TotalPop\",\"Poverty\",\"Men\",\"White\"]]\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "\n",
    "# Compute confusion matrix\n",
    "y_test = y_val\n",
    "conf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(conf_matrix)\n",
    "\n",
    "# Plot confusion matrix\n",
    "sns.heatmap(conf_matrix, annot = True, fmt = \".3f\", square = True, cmap = plt.cm.Blues)\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.title('Confusion matrix')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Compute evaluation metrics\n",
    "print(metrics.accuracy_score(y_test, y_pred)) # accuracy\n",
    "print(1 - metrics.accuracy_score(y_test, y_pred)) # error\n",
    "print(metrics.precision_score(y_test, y_pred, average = None)) # precision\n",
    "print(metrics.recall_score(y_test, y_pred, average = None)) # recall\n",
    "print(metrics.f1_score(y_test, y_pred, average = None)) # F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K nearest neighbour with k = 4 and 4 parameter\n",
    "model = KNeighborsClassifier(n_neighbors = 4)\n",
    "x = x_train[[\"TotalPop\",\"Poverty\",\"Men\", \"Black\"]]\n",
    "y = y_train\n",
    "model.fit(x, y)\n",
    "\n",
    "# Predict class labels using KNearest Neighbour\n",
    "x_test = x_val[[\"TotalPop\",\"Poverty\",\"Men\",\"Black\"]]\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "\n",
    "# Compute confusion matrix\n",
    "y_test = y_val\n",
    "conf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(conf_matrix)\n",
    "\n",
    "# Plot confusion matrix\n",
    "sns.heatmap(conf_matrix, annot = True, fmt = \".3f\", square = True, cmap = plt.cm.Blues)\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.title('Confusion matrix')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Compute evaluation metrics\n",
    "print(metrics.accuracy_score(y_test, y_pred)) # accuracy\n",
    "print(1 - metrics.accuracy_score(y_test, y_pred)) # error\n",
    "print(metrics.precision_score(y_test, y_pred, average = None)) # precision\n",
    "print(metrics.recall_score(y_test, y_pred, average = None)) # recall\n",
    "print(metrics.f1_score(y_test, y_pred, average = None)) # F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K nearest neighbour with k = 4 and 4 parameter\n",
    "model = KNeighborsClassifier(n_neighbors = 4)\n",
    "x = x_train[[\"TotalPop\",\"Poverty\",\"Men\", \"Citizen Voting Age Pop\"]]\n",
    "y = y_train\n",
    "model.fit(x, y)\n",
    "\n",
    "# Predict class labels using KNearest Neighbour\n",
    "x_test = x_val[[\"TotalPop\",\"Poverty\",\"Men\",\"Citizen Voting Age Pop\"]]\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "\n",
    "# Compute confusion matrix\n",
    "y_test = y_val\n",
    "conf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(conf_matrix)\n",
    "\n",
    "# Plot confusion matrix\n",
    "sns.heatmap(conf_matrix, annot = True, fmt = \".3f\", square = True, cmap = plt.cm.Blues)\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.title('Confusion matrix')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Compute evaluation metrics\n",
    "print(metrics.accuracy_score(y_test, y_pred)) # accuracy\n",
    "print(1 - metrics.accuracy_score(y_test, y_pred)) # error\n",
    "print(metrics.precision_score(y_test, y_pred, average = None)) # precision\n",
    "print(metrics.recall_score(y_test, y_pred, average = None)) # recall\n",
    "print(metrics.f1_score(y_test, y_pred, average = None)) # F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K nearest neighbour with k = 4 and 4 parameter\n",
    "model = KNeighborsClassifier(n_neighbors = 4)\n",
    "x = x_train[[\"TotalPop\",\"Poverty\",\"Men\", \"Median Household Income\"]]\n",
    "y = y_train\n",
    "model.fit(x, y)\n",
    "\n",
    "# Predict class labels using KNearest Neighbour\n",
    "x_test = x_val[[\"TotalPop\",\"Poverty\",\"Men\",\"Median Household Income\"]]\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "\n",
    "# Compute confusion matrix\n",
    "y_test = y_val\n",
    "conf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(conf_matrix)\n",
    "\n",
    "# Plot confusion matrix\n",
    "sns.heatmap(conf_matrix, annot = True, fmt = \".3f\", square = True, cmap = plt.cm.Blues)\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.title('Confusion matrix')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Compute evaluation metrics\n",
    "print(metrics.accuracy_score(y_test, y_pred)) # accuracy\n",
    "print(1 - metrics.accuracy_score(y_test, y_pred)) # error\n",
    "print(metrics.precision_score(y_test, y_pred, average = None)) # precision\n",
    "print(metrics.recall_score(y_test, y_pred, average = None)) # recall\n",
    "print(metrics.f1_score(y_test, y_pred, average = None)) # F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K nearest neighbour with k = 4 and 4 parameter\n",
    "model = KNeighborsClassifier(n_neighbors = 4)\n",
    "x = x_train[[\"TotalPop\",\"Poverty\",\"Men\", \"IncomePerCap\"]]\n",
    "y = y_train\n",
    "model.fit(x, y)\n",
    "\n",
    "# Predict class labels using KNearest Neighbour\n",
    "x_test = x_val[[\"TotalPop\",\"Poverty\",\"Men\",\"IncomePerCap\"]]\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "\n",
    "# Compute confusion matrix\n",
    "y_test = y_val\n",
    "conf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(conf_matrix)\n",
    "\n",
    "# Plot confusion matrix\n",
    "sns.heatmap(conf_matrix, annot = True, fmt = \".3f\", square = True, cmap = plt.cm.Blues)\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.title('Confusion matrix')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Compute evaluation metrics\n",
    "print(metrics.accuracy_score(y_test, y_pred)) # accuracy\n",
    "print(1 - metrics.accuracy_score(y_test, y_pred)) # error\n",
    "print(metrics.precision_score(y_test, y_pred, average = None)) # precision\n",
    "print(metrics.recall_score(y_test, y_pred, average = None)) # recall\n",
    "print(metrics.f1_score(y_test, y_pred, average = None)) # F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K nearest neighbour with k = 4 and 4 parameter\n",
    "model = KNeighborsClassifier(n_neighbors = 4)\n",
    "x = x_train[[\"TotalPop\",\"Poverty\",\"Men\", \"ChildPoverty\"]]\n",
    "y = y_train\n",
    "model.fit(x, y)\n",
    "\n",
    "# Predict class labels using KNearest Neighbour\n",
    "x_test = x_val[[\"TotalPop\",\"Poverty\",\"Men\",\"ChildPoverty\"]]\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "\n",
    "# Compute confusion matrix\n",
    "y_test = y_val\n",
    "conf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(conf_matrix)\n",
    "\n",
    "# Plot confusion matrix\n",
    "sns.heatmap(conf_matrix, annot = True, fmt = \".3f\", square = True, cmap = plt.cm.Blues)\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.title('Confusion matrix')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Compute evaluation metrics\n",
    "print(metrics.accuracy_score(y_test, y_pred)) # accuracy\n",
    "print(1 - metrics.accuracy_score(y_test, y_pred)) # error\n",
    "print(metrics.precision_score(y_test, y_pred, average = None)) # precision\n",
    "print(metrics.recall_score(y_test, y_pred, average = None)) # recall\n",
    "print(metrics.f1_score(y_test, y_pred, average = None)) # F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K nearest neighbour with k = 4 and 5 parameter\n",
    "model = KNeighborsClassifier(n_neighbors = 4)\n",
    "x = x_train[[\"TotalPop\",\"Poverty\", \"Men\", \"Black\" ,\"White\"]]\n",
    "y = y_train\n",
    "model.fit(x, y)\n",
    "\n",
    "# Predict class labels using KNearest Neighbour\n",
    "x_test = x_val[[\"TotalPop\",\"Poverty\", \"Men\", \"Black\" ,\"White\"]]\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "\n",
    "# Compute confusion matrix\n",
    "y_test = y_val\n",
    "conf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(conf_matrix)\n",
    "\n",
    "# Plot confusion matrix\n",
    "sns.heatmap(conf_matrix, annot = True, fmt = \".3f\", square = True, cmap = plt.cm.Blues)\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.title('Confusion matrix')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Compute evaluation metrics\n",
    "print(metrics.accuracy_score(y_test, y_pred)) # accuracy\n",
    "print(1 - metrics.accuracy_score(y_test, y_pred)) # error\n",
    "print(metrics.precision_score(y_test, y_pred, average = None)) # precision\n",
    "print(metrics.recall_score(y_test, y_pred, average = None)) # recall\n",
    "print(metrics.f1_score(y_test, y_pred, average = None)) # F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K nearest neighbour with k = 4 and 5 parameter\n",
    "model = KNeighborsClassifier(n_neighbors = 4)\n",
    "x = x_train[[\"TotalPop\",\"Poverty\", \"Men\", \"Black\" ,\"Citizen Voting Age Pop\"]]\n",
    "y = y_train\n",
    "model.fit(x, y)\n",
    "\n",
    "# Predict class labels using KNearest Neighbour\n",
    "x_test = x_val[[\"TotalPop\",\"Poverty\", \"Men\", \"Black\" ,\"Citizen Voting Age Pop\"]]\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "\n",
    "# Compute confusion matrix\n",
    "y_test = y_val\n",
    "conf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(conf_matrix)\n",
    "\n",
    "# Plot confusion matrix\n",
    "sns.heatmap(conf_matrix, annot = True, fmt = \".3f\", square = True, cmap = plt.cm.Blues)\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.title('Confusion matrix')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Compute evaluation metrics\n",
    "print(metrics.accuracy_score(y_test, y_pred)) # accuracy\n",
    "print(1 - metrics.accuracy_score(y_test, y_pred)) # error\n",
    "print(metrics.precision_score(y_test, y_pred, average = None)) # precision\n",
    "print(metrics.recall_score(y_test, y_pred, average = None)) # recall\n",
    "print(metrics.f1_score(y_test, y_pred, average = None)) # F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K nearest neighbour with k = 4 and 5 parameter\n",
    "model = KNeighborsClassifier(n_neighbors = 4)\n",
    "x = x_train[[\"TotalPop\",\"Poverty\", \"Men\", \"Black\" ,\"Median Household Income\"]]\n",
    "y = y_train\n",
    "model.fit(x, y)\n",
    "\n",
    "# Predict class labels using KNearest Neighbour\n",
    "x_test = x_val[[\"TotalPop\",\"Poverty\", \"Men\", \"Black\" ,\"Median Household Income\"]]\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "\n",
    "# Compute confusion matrix\n",
    "y_test = y_val\n",
    "conf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(conf_matrix)\n",
    "\n",
    "# Plot confusion matrix\n",
    "sns.heatmap(conf_matrix, annot = True, fmt = \".3f\", square = True, cmap = plt.cm.Blues)\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.title('Confusion matrix')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Compute evaluation metrics\n",
    "print(metrics.accuracy_score(y_test, y_pred)) # accuracy\n",
    "print(1 - metrics.accuracy_score(y_test, y_pred)) # error\n",
    "print(metrics.precision_score(y_test, y_pred, average = None)) # precision\n",
    "print(metrics.recall_score(y_test, y_pred, average = None)) # recall\n",
    "print(metrics.f1_score(y_test, y_pred, average = None)) # F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K nearest neighbour with k = 4 and 6 parameter\n",
    "model = KNeighborsClassifier(n_neighbors = 4)\n",
    "x = x_train[[\"TotalPop\",\"Poverty\", \"Men\", \"Black\" ,\"IncomePerCap\"]]\n",
    "y = y_train\n",
    "model.fit(x, y)\n",
    "\n",
    "# Predict class labels using KNearest Neighbour\n",
    "x_test = x_val[[\"TotalPop\",\"Poverty\", \"Men\", \"Black\" ,\"IncomePerCap\"]]\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "\n",
    "# Compute confusion matrix\n",
    "y_test = y_val\n",
    "conf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(conf_matrix)\n",
    "\n",
    "# Plot confusion matrix\n",
    "sns.heatmap(conf_matrix, annot = True, fmt = \".3f\", square = True, cmap = plt.cm.Blues)\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.title('Confusion matrix')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Compute evaluation metrics\n",
    "print(metrics.accuracy_score(y_test, y_pred)) # accuracy\n",
    "print(1 - metrics.accuracy_score(y_test, y_pred)) # error\n",
    "print(metrics.precision_score(y_test, y_pred, average = None)) # precision\n",
    "print(metrics.recall_score(y_test, y_pred, average = None)) # recall\n",
    "print(metrics.f1_score(y_test, y_pred, average = None)) # F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k = 4, 5 parameter\n",
    "# 0.73469388 0.48241206 0.47741935\n",
    "# 0.73170732 0.51141553 0.50980392\t\t\"TotalPop\",\"Poverty\", \"Men\", 'Black', 'Citizen Voting Age Pop'\n",
    "# 0.7483531  0.45144357 0.43243243\n",
    "# 0.73134328 0.36931818 0.48484848\n",
    "# 0.74135546 0.48076923 0.46979866"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K nearest neighbour with k = 4 and 6 parameter\n",
    "model = KNeighborsClassifier(n_neighbors = 4)\n",
    "x = x_train[[\"TotalPop\",\"Poverty\", \"Men\", \"Black\", \"Citizen Voting Age Pop\",\"White\"]]\n",
    "y = y_train\n",
    "model.fit(x, y)\n",
    "\n",
    "# Predict class labels using KNearest Neighbour\n",
    "x_test = x_val[[\"TotalPop\",\"Poverty\", \"Men\", \"Black\", \"Citizen Voting Age Pop\",\"White\"]]\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "\n",
    "# Compute confusion matrix\n",
    "y_test = y_val\n",
    "conf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(conf_matrix)\n",
    "\n",
    "# Plot confusion matrix\n",
    "sns.heatmap(conf_matrix, annot = True, fmt = \".3f\", square = True, cmap = plt.cm.Blues)\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.title('Confusion matrix')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Compute evaluation metrics\n",
    "print(metrics.accuracy_score(y_test, y_pred)) # accuracy\n",
    "print(1 - metrics.accuracy_score(y_test, y_pred)) # error\n",
    "print(metrics.precision_score(y_test, y_pred, average = None)) # precision\n",
    "print(metrics.recall_score(y_test, y_pred, average = None)) # recall\n",
    "print(metrics.f1_score(y_test, y_pred, average = None)) # F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K nearest neighbour with k = 4 and 6 parameter\n",
    "model = KNeighborsClassifier(n_neighbors = 4)\n",
    "x = x_train[[\"TotalPop\",\"Poverty\", \"Men\", \"Black\", \"Citizen Voting Age Pop\",\"Median Household Income\"]]\n",
    "y = y_train\n",
    "model.fit(x, y)\n",
    "\n",
    "# Predict class labels using KNearest Neighbour\n",
    "x_test = x_val[[\"TotalPop\",\"Poverty\", \"Men\", \"Black\", \"Citizen Voting Age Pop\",\"Median Household Income\"]]\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "\n",
    "# Compute confusion matrix\n",
    "y_test = y_val\n",
    "conf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(conf_matrix)\n",
    "\n",
    "# Plot confusion matrix\n",
    "sns.heatmap(conf_matrix, annot = True, fmt = \".3f\", square = True, cmap = plt.cm.Blues)\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.title('Confusion matrix')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Compute evaluation metrics\n",
    "print(metrics.accuracy_score(y_test, y_pred)) # accuracy\n",
    "print(1 - metrics.accuracy_score(y_test, y_pred)) # error\n",
    "print(metrics.precision_score(y_test, y_pred, average = None)) # precision\n",
    "print(metrics.recall_score(y_test, y_pred, average = None)) # recall\n",
    "print(metrics.f1_score(y_test, y_pred, average = None)) # F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K nearest neighbour with k = 4 and 6 parameter\n",
    "model = KNeighborsClassifier(n_neighbors = 4)\n",
    "x = x_train[[\"TotalPop\",\"Poverty\", \"Men\", \"Black\", \"Citizen Voting Age Pop\",\"IncomePerCap\"]]\n",
    "y = y_train\n",
    "model.fit(x, y)\n",
    "\n",
    "# Predict class labels using KNearest Neighbour\n",
    "x_test = x_val[[\"TotalPop\",\"Poverty\", \"Men\", \"Black\", \"Citizen Voting Age Pop\",\"IncomePerCap\"]]\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "\n",
    "# Compute confusion matrix\n",
    "y_test = y_val\n",
    "conf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(conf_matrix)\n",
    "\n",
    "# Plot confusion matrix\n",
    "sns.heatmap(conf_matrix, annot = True, fmt = \".3f\", square = True, cmap = plt.cm.Blues)\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.title('Confusion matrix')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Compute evaluation metrics\n",
    "print(metrics.accuracy_score(y_test, y_pred)) # accuracy\n",
    "print(1 - metrics.accuracy_score(y_test, y_pred)) # error\n",
    "print(metrics.precision_score(y_test, y_pred, average = None)) # precision\n",
    "print(metrics.recall_score(y_test, y_pred, average = None)) # recall\n",
    "print(metrics.f1_score(y_test, y_pred, average = None)) # F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K nearest neighbour with k = 4 and 6 parameter\n",
    "model = KNeighborsClassifier(n_neighbors = 4)\n",
    "x = x_train[[\"TotalPop\",\"Poverty\", \"Men\", \"Black\", \"Citizen Voting Age Pop\",\"ChildPoverty\"]]\n",
    "y = y_train\n",
    "model.fit(x, y)\n",
    "\n",
    "# Predict class labels using KNearest Neighbour\n",
    "x_test = x_val[[\"TotalPop\",\"Poverty\", \"Men\", \"Black\", \"Citizen Voting Age Pop\",\"ChildPoverty\"]]\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "\n",
    "# Compute confusion matrix\n",
    "y_test = y_val\n",
    "conf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(conf_matrix)\n",
    "\n",
    "# Plot confusion matrix\n",
    "sns.heatmap(conf_matrix, annot = True, fmt = \".3f\", square = True, cmap = plt.cm.Blues)\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.title('Confusion matrix')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Compute evaluation metrics\n",
    "print(metrics.accuracy_score(y_test, y_pred)) # accuracy\n",
    "print(1 - metrics.accuracy_score(y_test, y_pred)) # error\n",
    "print(metrics.precision_score(y_test, y_pred, average = None)) # precision\n",
    "print(metrics.recall_score(y_test, y_pred, average = None)) # recall\n",
    "print(metrics.f1_score(y_test, y_pred, average = None)) # F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k = 4, 6 parameter\n",
    "# 0.72305593 0.47761194 0.47058824\n",
    "# 0.74934726 0.44385027 0.45945946\n",
    "# 0.74406991 0.38068182 0.45925926\n",
    "# 0.75720165 0.5        0.47619048\n",
    "\n",
    "# 0.73170732 0.51141553 0.50980392\t\t\"TotalPop\",\"Poverty\", \"Men\", 'Black', 'Citizen Voting Age Pop'\n",
    "# All Values beginn to decreace.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K nearest neighbour with k = 4 and 6 parameter\n",
    "model = KNeighborsClassifier(n_neighbors = 4)\n",
    "x = x_train[[\"TotalPop\",\"Poverty\", \"Men\", \"Black\" ,\"Citizen Voting Age Pop\", \"County Unemployment Rate for 2013\"]]\n",
    "y = y_train\n",
    "model.fit(x, y)\n",
    "\n",
    "# Predict class labels using KNearest Neighbour\n",
    "x_test = x_val[[\"TotalPop\",\"Poverty\", \"Men\", \"Black\" ,\"Citizen Voting Age Pop\", \"County Unemployment Rate for 2013\"]]\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "\n",
    "# Compute confusion matrix\n",
    "y_test = y_val\n",
    "conf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(conf_matrix)\n",
    "\n",
    "# Plot confusion matrix\n",
    "sns.heatmap(conf_matrix, annot = True, fmt = \".3f\", square = True, cmap = plt.cm.Blues)\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.title('Confusion matrix')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Compute evaluation metrics\n",
    "print(metrics.accuracy_score(y_test, y_pred)) # accuracy\n",
    "print(1 - metrics.accuracy_score(y_test, y_pred)) # error\n",
    "print(metrics.precision_score(y_test, y_pred, average = None)) # precision\n",
    "print(metrics.recall_score(y_test, y_pred, average = None)) # recall\n",
    "print(metrics.f1_score(y_test, y_pred, average = None)) # F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K nearest neighbour with k = 4 and 7 parameter\n",
    "model = KNeighborsClassifier(n_neighbors = 4)\n",
    "x = x_train[[\"TotalPop\",\"Poverty\", \"Men\", \"Black\" ,\"Citizen Voting Age Pop\", \"County Unemployment Rate for 2013\",\n",
    "             'Percent Population with age between 16 and 44']]\n",
    "y = y_train\n",
    "model.fit(x, y)\n",
    "\n",
    "# Predict class labels using KNearest Neighbour\n",
    "x_test = x_val[[\"TotalPop\",\"Poverty\", \"Men\", \"Black\" ,\"Citizen Voting Age Pop\", \"County Unemployment Rate for 2013\",\n",
    "                'Percent Population with age between 16 and 44']]\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "\n",
    "# Compute confusion matrix\n",
    "y_test = y_val\n",
    "conf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(conf_matrix)\n",
    "\n",
    "# Plot confusion matrix\n",
    "sns.heatmap(conf_matrix, annot = True, fmt = \".3f\", square = True, cmap = plt.cm.Blues)\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.title('Confusion matrix')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Compute evaluation metrics\n",
    "print(metrics.accuracy_score(y_test, y_pred)) # accuracy\n",
    "print(1 - metrics.accuracy_score(y_test, y_pred)) # error\n",
    "print(metrics.precision_score(y_test, y_pred, average = None)) # precision\n",
    "print(metrics.recall_score(y_test, y_pred, average = None)) # recall\n",
    "print(metrics.f1_score(y_test, y_pred, average = None)) # F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K nearest neighbour with k = 4 and 8 parameter\n",
    "model = KNeighborsClassifier(n_neighbors = 4)\n",
    "x = x_train[[\"TotalPop\",\"Poverty\", \"Men\", \"Black\" ,\"Citizen Voting Age Pop\", \"County Unemployment Rate for 2013\",\n",
    "               'Percent Population with age between 16 and 44', \n",
    "             'Percent Population with age between 45 and 74']]\n",
    "y = y_train\n",
    "model.fit(x, y)\n",
    "\n",
    "# Predict class labels using KNearest Neighbour\n",
    "x_test = x_val[[\"TotalPop\",\"Poverty\", \"Men\", \"Black\" ,\"Citizen Voting Age Pop\", \"County Unemployment Rate for 2013\",\n",
    "                  'Percent Population with age between 16 and 44', \n",
    "                'Percent Population with age between 45 and 74']]\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "\n",
    "# Compute confusion matrix\n",
    "y_test = y_val\n",
    "conf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(conf_matrix)\n",
    "\n",
    "# Plot confusion matrix\n",
    "sns.heatmap(conf_matrix, annot = True, fmt = \".3f\", square = True, cmap = plt.cm.Blues)\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.title('Confusion matrix')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Compute evaluation metrics\n",
    "print(metrics.accuracy_score(y_test, y_pred)) # accuracy\n",
    "print(1 - metrics.accuracy_score(y_test, y_pred)) # error\n",
    "print(metrics.precision_score(y_test, y_pred, average = None)) # precision\n",
    "print(metrics.recall_score(y_test, y_pred, average = None)) # recall\n",
    "print(metrics.f1_score(y_test, y_pred, average = None)) # F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K nearest neighbour with k = 4 and 8 parameter\n",
    "model = KNeighborsClassifier(n_neighbors = 4)\n",
    "x = x_train[[\"TotalPop\",\"Poverty\", \"Men\", \"Black\" ,\"Citizen Voting Age Pop\", \"County Unemployment Rate for 2013\",\n",
    "               'Percent Population with age between 16 and 44', \n",
    "             'Percent Population with age between 75 and over']]\n",
    "y = y_train\n",
    "model.fit(x, y)\n",
    "\n",
    "# Predict class labels using KNearest Neighbour\n",
    "x_test = x_val[[\"TotalPop\",\"Poverty\", \"Men\", \"Black\" ,\"Citizen Voting Age Pop\", \"County Unemployment Rate for 2013\",\n",
    "               'Percent Population with age between 16 and 44', \n",
    "                'Percent Population with age between 75 and over']]\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "\n",
    "# Compute confusion matrix\n",
    "y_test = y_val\n",
    "conf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(conf_matrix)\n",
    "\n",
    "# Plot confusion matrix\n",
    "sns.heatmap(conf_matrix, annot = True, fmt = \".3f\", square = True, cmap = plt.cm.Blues)\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.title('Confusion matrix')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Compute evaluation metrics\n",
    "print(metrics.accuracy_score(y_test, y_pred)) # accuracy\n",
    "print(1 - metrics.accuracy_score(y_test, y_pred)) # error\n",
    "print(metrics.precision_score(y_test, y_pred, average = None)) # precision\n",
    "print(metrics.recall_score(y_test, y_pred, average = None)) # recall\n",
    "print(metrics.f1_score(y_test, y_pred, average = None)) # F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K nearest neighbour with k = 4 and 8 parameter\n",
    "model = KNeighborsClassifier(n_neighbors = 4)\n",
    "x = x_train[[\"TotalPop\",\"Poverty\", \"Men\", \"Black\" ,\"Citizen Voting Age Pop\", \"County Unemployment Rate for 2013\",\n",
    "               'Percent Population with age between 16 and 44', 'Hispanic']]\n",
    "y = y_train\n",
    "model.fit(x, y)\n",
    "\n",
    "# Predict class labels using KNearest Neighbour\n",
    "x_test = x_val[[\"TotalPop\",\"Poverty\", \"Men\", \"Black\" ,\"Citizen Voting Age Pop\", \"County Unemployment Rate for 2013\",\n",
    "               'Percent Population with age between 16 and 44', 'Hispanic']]\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "\n",
    "# Compute confusion matrix\n",
    "y_test = y_val\n",
    "conf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(conf_matrix)\n",
    "\n",
    "# Plot confusion matrix\n",
    "sns.heatmap(conf_matrix, annot = True, fmt = \".3f\", square = True, cmap = plt.cm.Blues)\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.title('Confusion matrix')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Compute evaluation metrics\n",
    "print(metrics.accuracy_score(y_test, y_pred)) # accuracy\n",
    "print(1 - metrics.accuracy_score(y_test, y_pred)) # error\n",
    "print(metrics.precision_score(y_test, y_pred, average = None)) # precision\n",
    "print(metrics.recall_score(y_test, y_pred, average = None)) # recall\n",
    "print(metrics.f1_score(y_test, y_pred, average = None)) # F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K nearest neighbour with k = 4 and 9 parameter\n",
    "model = KNeighborsClassifier(n_neighbors = 4)\n",
    "x = x_train[[\"TotalPop\",\"Poverty\", \"Men\", \"Black\" ,\"Citizen Voting Age Pop\", \"County Unemployment Rate for 2013\",\n",
    "               'Percent Population with age between 16 and 44', 'Hispanic', 'Native']]\n",
    "y = y_train\n",
    "model.fit(x, y)\n",
    "\n",
    "# Predict class labels using KNearest Neighbour\n",
    "x_test = x_val[[\"TotalPop\",\"Poverty\", \"Men\", \"Black\" ,\"Citizen Voting Age Pop\", \"County Unemployment Rate for 2013\",\n",
    "               'Percent Population with age between 16 and 44', 'Hispanic', 'Native']]\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "\n",
    "# Compute confusion matrix\n",
    "y_test = y_val\n",
    "conf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(conf_matrix)\n",
    "\n",
    "# Plot confusion matrix\n",
    "sns.heatmap(conf_matrix, annot = True, fmt = \".3f\", square = True, cmap = plt.cm.Blues)\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.title('Confusion matrix')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Compute evaluation metrics\n",
    "print(metrics.accuracy_score(y_test, y_pred)) # accuracy\n",
    "print(1 - metrics.accuracy_score(y_test, y_pred)) # error\n",
    "print(metrics.precision_score(y_test, y_pred, average = None)) # precision\n",
    "print(metrics.recall_score(y_test, y_pred, average = None)) # recall\n",
    "print(metrics.f1_score(y_test, y_pred, average = None)) # F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K nearest neighbour with k = 4 and 10 parameter\n",
    "model = KNeighborsClassifier(n_neighbors = 4)\n",
    "x = x_train[[\"TotalPop\",\"Poverty\", \"Men\", \"Black\" ,\"Citizen Voting Age Pop\", \"County Unemployment Rate for 2013\",\n",
    "               'Percent Population with age between 16 and 44', 'Hispanic', 'Native', 'Asian']]\n",
    "y = y_train\n",
    "model.fit(x, y)\n",
    "\n",
    "# Predict class labels using KNearest Neighbour\n",
    "x_test = x_val[[\"TotalPop\",\"Poverty\", \"Men\", \"Black\" ,\"Citizen Voting Age Pop\", \"County Unemployment Rate for 2013\",\n",
    "               'Percent Population with age between 16 and 44', 'Hispanic', 'Native', 'Asian']]\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "\n",
    "# Compute confusion matrix\n",
    "y_test = y_val\n",
    "conf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(conf_matrix)\n",
    "\n",
    "# Plot confusion matrix\n",
    "sns.heatmap(conf_matrix, annot = True, fmt = \".3f\", square = True, cmap = plt.cm.Blues)\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.title('Confusion matrix')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Compute evaluation metrics\n",
    "print(metrics.accuracy_score(y_test, y_pred)) # accuracy\n",
    "print(1 - metrics.accuracy_score(y_test, y_pred)) # error\n",
    "print(metrics.precision_score(y_test, y_pred, average = None)) # precision\n",
    "print(metrics.recall_score(y_test, y_pred, average = None)) # recall\n",
    "print(metrics.f1_score(y_test, y_pred, average = None)) # F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K nearest neighbour with k = 4 and 10 parameter\n",
    "model = KNeighborsClassifier(n_neighbors = 4)\n",
    "x = x_train[[\"TotalPop\",\"Poverty\", \"Men\", \"Black\" ,\"Citizen Voting Age Pop\", \"County Unemployment Rate for 2013\",\n",
    "               'Percent Population with age between 16 and 44', 'Hispanic', 'Native', 'Pacific']]\n",
    "y = y_train\n",
    "model.fit(x, y)\n",
    "\n",
    "# Predict class labels using KNearest Neighbour\n",
    "x_test = x_val[[\"TotalPop\",\"Poverty\", \"Men\", \"Black\" ,\"Citizen Voting Age Pop\", \"County Unemployment Rate for 2013\",\n",
    "               'Percent Population with age between 16 and 44', 'Hispanic', 'Native', 'Pacific']]\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "\n",
    "# Compute confusion matrix\n",
    "y_test = y_val\n",
    "conf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(conf_matrix)\n",
    "\n",
    "# Plot confusion matrix\n",
    "sns.heatmap(conf_matrix, annot = True, fmt = \".3f\", square = True, cmap = plt.cm.Blues)\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.title('Confusion matrix')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Compute evaluation metrics\n",
    "print(metrics.accuracy_score(y_test, y_pred)) # accuracy\n",
    "print(1 - metrics.accuracy_score(y_test, y_pred)) # error\n",
    "print(metrics.precision_score(y_test, y_pred, average = None)) # precision\n",
    "print(metrics.recall_score(y_test, y_pred, average = None)) # recall\n",
    "print(metrics.f1_score(y_test, y_pred, average = None)) # F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K nearest neighbour with k = 4 and 10 parameter\n",
    "model = KNeighborsClassifier(n_neighbors = 4)\n",
    "x = x_train[[\"TotalPop\",\"Poverty\", \"Men\", \"Black\" ,\"Citizen Voting Age Pop\", \"County Unemployment Rate for 2013\",\n",
    "               'Percent Population with age between 16 and 44', 'Hispanic', 'Native', 'Professional']]\n",
    "y = y_train\n",
    "model.fit(x, y)\n",
    "\n",
    "# Predict class labels using KNearest Neighbour\n",
    "x_test = x_val[[\"TotalPop\",\"Poverty\", \"Men\", \"Black\" ,\"Citizen Voting Age Pop\", \"County Unemployment Rate for 2013\",\n",
    "               'Percent Population with age between 16 and 44', 'Hispanic', 'Native', 'Professional']]\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "\n",
    "# Compute confusion matrix\n",
    "y_test = y_val\n",
    "conf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(conf_matrix)\n",
    "\n",
    "# Plot confusion matrix\n",
    "sns.heatmap(conf_matrix, annot = True, fmt = \".3f\", square = True, cmap = plt.cm.Blues)\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.title('Confusion matrix')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Compute evaluation metrics\n",
    "print(metrics.accuracy_score(y_test, y_pred)) # accuracy\n",
    "print(1 - metrics.accuracy_score(y_test, y_pred)) # error\n",
    "print(metrics.precision_score(y_test, y_pred, average = None)) # precision\n",
    "print(metrics.recall_score(y_test, y_pred, average = None)) # recall\n",
    "print(metrics.f1_score(y_test, y_pred, average = None)) # F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K nearest neighbour with k = 4 and 10 parameter\n",
    "model = KNeighborsClassifier(n_neighbors = 4)\n",
    "x = x_train[[\"TotalPop\",\"Poverty\", \"Men\", \"Black\" ,\"Citizen Voting Age Pop\", \"County Unemployment Rate for 2013\",\n",
    "               'Percent Population with age between 16 and 44', 'Hispanic', 'Native', 'Service']]\n",
    "y = y_train\n",
    "model.fit(x, y)\n",
    "\n",
    "# Predict class labels using KNearest Neighbour\n",
    "x_test = x_val[[\"TotalPop\",\"Poverty\", \"Men\", \"Black\" ,\"Citizen Voting Age Pop\", \"County Unemployment Rate for 2013\",\n",
    "               'Percent Population with age between 16 and 44', 'Hispanic', 'Native', 'Service']]\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "\n",
    "# Compute confusion matrix\n",
    "y_test = y_val\n",
    "conf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(conf_matrix)\n",
    "\n",
    "# Plot confusion matrix\n",
    "sns.heatmap(conf_matrix, annot = True, fmt = \".3f\", square = True, cmap = plt.cm.Blues)\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.title('Confusion matrix')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Compute evaluation metrics\n",
    "print(metrics.accuracy_score(y_test, y_pred)) # accuracy\n",
    "print(1 - metrics.accuracy_score(y_test, y_pred)) # error\n",
    "print(metrics.precision_score(y_test, y_pred, average = None)) # precision\n",
    "print(metrics.recall_score(y_test, y_pred, average = None)) # recall\n",
    "print(metrics.f1_score(y_test, y_pred, average = None)) # F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K nearest neighbour with k = 4 and 10 parameter\n",
    "model = KNeighborsClassifier(n_neighbors = 4)\n",
    "x = x_train[[\"TotalPop\",\"Poverty\", \"Men\", \"Black\" ,\"Citizen Voting Age Pop\", \"County Unemployment Rate for 2013\",\n",
    "               'Percent Population with age between 16 and 44', 'Hispanic', 'Native', 'Office']]\n",
    "y = y_train\n",
    "model.fit(x, y)\n",
    "\n",
    "# Predict class labels using KNearest Neighbour\n",
    "x_test = x_val[[\"TotalPop\",\"Poverty\", \"Men\", \"Black\" ,\"Citizen Voting Age Pop\", \"County Unemployment Rate for 2013\",\n",
    "               'Percent Population with age between 16 and 44', 'Hispanic', 'Native', 'Office']]\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "\n",
    "# Compute confusion matrix\n",
    "y_test = y_val\n",
    "conf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(conf_matrix)\n",
    "\n",
    "# Plot confusion matrix\n",
    "sns.heatmap(conf_matrix, annot = True, fmt = \".3f\", square = True, cmap = plt.cm.Blues)\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.title('Confusion matrix')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Compute evaluation metrics\n",
    "print(metrics.accuracy_score(y_test, y_pred)) # accuracy\n",
    "print(1 - metrics.accuracy_score(y_test, y_pred)) # error\n",
    "print(metrics.precision_score(y_test, y_pred, average = None)) # precision\n",
    "print(metrics.recall_score(y_test, y_pred, average = None)) # recall\n",
    "print(metrics.f1_score(y_test, y_pred, average = None)) # F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K nearest neighbour with k = 4 and 10 parameter\n",
    "model = KNeighborsClassifier(n_neighbors = 4)\n",
    "x = x_train[[\"TotalPop\",\"Poverty\", \"Men\", \"Black\" ,\"Citizen Voting Age Pop\", \"County Unemployment Rate for 2013\",\n",
    "               'Percent Population with age between 16 and 44', 'Hispanic', 'Native', 'Construction']]\n",
    "y = y_train\n",
    "model.fit(x, y)\n",
    "\n",
    "# Predict class labels using KNearest Neighbour\n",
    "x_test = x_val[[\"TotalPop\",\"Poverty\", \"Men\", \"Black\" ,\"Citizen Voting Age Pop\", \"County Unemployment Rate for 2013\",\n",
    "               'Percent Population with age between 16 and 44', 'Hispanic', 'Native', 'Construction']]\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "\n",
    "# Compute confusion matrix\n",
    "y_test = y_val\n",
    "conf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(conf_matrix)\n",
    "\n",
    "# Plot confusion matrix\n",
    "sns.heatmap(conf_matrix, annot = True, fmt = \".3f\", square = True, cmap = plt.cm.Blues)\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.title('Confusion matrix')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Compute evaluation metrics\n",
    "print(metrics.accuracy_score(y_test, y_pred)) # accuracy\n",
    "print(1 - metrics.accuracy_score(y_test, y_pred)) # error\n",
    "print(metrics.precision_score(y_test, y_pred, average = None)) # precision\n",
    "print(metrics.recall_score(y_test, y_pred, average = None)) # recall\n",
    "print(metrics.f1_score(y_test, y_pred, average = None)) # F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K nearest neighbour with k = 4 and 10 parameter\n",
    "model = KNeighborsClassifier(n_neighbors = 4)\n",
    "x = x_train[[\"TotalPop\",\"Poverty\", \"Men\", \"Black\" ,\"Citizen Voting Age Pop\", \"County Unemployment Rate for 2013\",\n",
    "               'Percent Population with age between 16 and 44', 'Hispanic', 'Native', 'Production']]\n",
    "y = y_train\n",
    "model.fit(x, y)\n",
    "\n",
    "# Predict class labels using KNearest Neighbour\n",
    "x_test = x_val[[\"TotalPop\",\"Poverty\", \"Men\", \"Black\" ,\"Citizen Voting Age Pop\", \"County Unemployment Rate for 2013\",\n",
    "               'Percent Population with age between 16 and 44', 'Hispanic', 'Native', 'Production']]\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "\n",
    "# Compute confusion matrix\n",
    "y_test = y_val\n",
    "conf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(conf_matrix)\n",
    "\n",
    "# Plot confusion matrix\n",
    "sns.heatmap(conf_matrix, annot = True, fmt = \".3f\", square = True, cmap = plt.cm.Blues)\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.title('Confusion matrix')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Compute evaluation metrics\n",
    "print(metrics.accuracy_score(y_test, y_pred)) # accuracy\n",
    "print(1 - metrics.accuracy_score(y_test, y_pred)) # error\n",
    "print(metrics.precision_score(y_test, y_pred, average = None)) # precision\n",
    "print(metrics.recall_score(y_test, y_pred, average = None)) # recall\n",
    "print(metrics.f1_score(y_test, y_pred, average = None)) # F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K nearest neighbour with k = 4 and 10 parameter\n",
    "model = KNeighborsClassifier(n_neighbors = 4)\n",
    "x = x_train[[\"TotalPop\",\"Poverty\", \"Men\", \"Black\" ,\"Citizen Voting Age Pop\", \"County Unemployment Rate for 2013\",\n",
    "               'Percent Population with age between 16 and 44', 'Hispanic', 'Native', 'Drive']]\n",
    "y = y_train\n",
    "model.fit(x, y)\n",
    "\n",
    "# Predict class labels using KNearest Neighbour\n",
    "x_test = x_val[[\"TotalPop\",\"Poverty\", \"Men\", \"Black\" ,\"Citizen Voting Age Pop\", \"County Unemployment Rate for 2013\",\n",
    "               'Percent Population with age between 16 and 44', 'Hispanic', 'Native', 'Drive']]\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "\n",
    "# Compute confusion matrix\n",
    "y_test = y_val\n",
    "conf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(conf_matrix)\n",
    "\n",
    "# Plot confusion matrix\n",
    "sns.heatmap(conf_matrix, annot = True, fmt = \".3f\", square = True, cmap = plt.cm.Blues)\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.title('Confusion matrix')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Compute evaluation metrics\n",
    "print(metrics.accuracy_score(y_test, y_pred)) # accuracy\n",
    "print(1 - metrics.accuracy_score(y_test, y_pred)) # error\n",
    "print(metrics.precision_score(y_test, y_pred, average = None)) # precision\n",
    "print(metrics.recall_score(y_test, y_pred, average = None)) # recall\n",
    "print(metrics.f1_score(y_test, y_pred, average = None)) # F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K nearest neighbour with k = 4 and 10 parameter\n",
    "model = KNeighborsClassifier(n_neighbors = 4)\n",
    "x = x_train[[\"TotalPop\",\"Poverty\", \"Men\", \"Black\" ,\"Citizen Voting Age Pop\", \"County Unemployment Rate for 2013\",\n",
    "               'Percent Population with age between 16 and 44', 'Hispanic', 'Native', 'Carpool']]\n",
    "y = y_train\n",
    "model.fit(x, y)\n",
    "\n",
    "# Predict class labels using KNearest Neighbour\n",
    "x_test = x_val[[\"TotalPop\",\"Poverty\", \"Men\", \"Black\" ,\"Citizen Voting Age Pop\", \"County Unemployment Rate for 2013\",\n",
    "               'Percent Population with age between 16 and 44', 'Hispanic', 'Native', 'Carpool']]\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "\n",
    "# Compute confusion matrix\n",
    "y_test = y_val\n",
    "conf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(conf_matrix)\n",
    "\n",
    "# Plot confusion matrix\n",
    "sns.heatmap(conf_matrix, annot = True, fmt = \".3f\", square = True, cmap = plt.cm.Blues)\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.title('Confusion matrix')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Compute evaluation metrics\n",
    "print(metrics.accuracy_score(y_test, y_pred)) # accuracy\n",
    "print(1 - metrics.accuracy_score(y_test, y_pred)) # error\n",
    "print(metrics.precision_score(y_test, y_pred, average = None)) # precision\n",
    "print(metrics.recall_score(y_test, y_pred, average = None)) # recall\n",
    "print(metrics.f1_score(y_test, y_pred, average = None)) # F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K nearest neighbour with k = 4 and 10 parameter\n",
    "model = KNeighborsClassifier(n_neighbors = 4)\n",
    "x = x_train[[\"TotalPop\",\"Poverty\", \"Men\", \"Black\" ,\"Citizen Voting Age Pop\", \"County Unemployment Rate for 2013\",\n",
    "               'Percent Population with age between 16 and 44', 'Hispanic', 'Native', 'Transit']]\n",
    "y = y_train\n",
    "model.fit(x, y)\n",
    "\n",
    "# Predict class labels using KNearest Neighbour\n",
    "x_test = x_val[[\"TotalPop\",\"Poverty\", \"Men\", \"Black\" ,\"Citizen Voting Age Pop\", \"County Unemployment Rate for 2013\",\n",
    "               'Percent Population with age between 16 and 44', 'Hispanic', 'Native', 'Transit']]\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "\n",
    "# Compute confusion matrix\n",
    "y_test = y_val\n",
    "conf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(conf_matrix)\n",
    "\n",
    "# Plot confusion matrix\n",
    "sns.heatmap(conf_matrix, annot = True, fmt = \".3f\", square = True, cmap = plt.cm.Blues)\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.title('Confusion matrix')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Compute evaluation metrics\n",
    "print(metrics.accuracy_score(y_test, y_pred)) # accuracy\n",
    "print(1 - metrics.accuracy_score(y_test, y_pred)) # error\n",
    "print(metrics.precision_score(y_test, y_pred, average = None)) # precision\n",
    "print(metrics.recall_score(y_test, y_pred, average = None)) # recall\n",
    "print(metrics.f1_score(y_test, y_pred, average = None)) # F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K nearest neighbour with k = 4 and 10 parameter\n",
    "model = KNeighborsClassifier(n_neighbors = 4)\n",
    "x = x_train[[\"TotalPop\",\"Poverty\", \"Men\", \"Black\" ,\"Citizen Voting Age Pop\", \"County Unemployment Rate for 2013\",\n",
    "               'Percent Population with age between 16 and 44', 'Hispanic', 'Native', 'Walk']]\n",
    "y = y_train\n",
    "model.fit(x, y)\n",
    "\n",
    "# Predict class labels using KNearest Neighbour\n",
    "x_test = x_val[[\"TotalPop\",\"Poverty\", \"Men\", \"Black\" ,\"Citizen Voting Age Pop\", \"County Unemployment Rate for 2013\",\n",
    "               'Percent Population with age between 16 and 44', 'Hispanic', 'Native', 'Walk']]\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "\n",
    "# Compute confusion matrix\n",
    "y_test = y_val\n",
    "conf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(conf_matrix)\n",
    "\n",
    "# Plot confusion matrix\n",
    "sns.heatmap(conf_matrix, annot = True, fmt = \".3f\", square = True, cmap = plt.cm.Blues)\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.title('Confusion matrix')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Compute evaluation metrics\n",
    "print(metrics.accuracy_score(y_test, y_pred)) # accuracy\n",
    "print(1 - metrics.accuracy_score(y_test, y_pred)) # error\n",
    "print(metrics.precision_score(y_test, y_pred, average = None)) # precision\n",
    "print(metrics.recall_score(y_test, y_pred, average = None)) # recall\n",
    "print(metrics.f1_score(y_test, y_pred, average = None)) # F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K nearest neighbour with k = 4 and 10 parameter\n",
    "model = KNeighborsClassifier(n_neighbors = 4)\n",
    "x = x_train[[\"TotalPop\",\"Poverty\", \"Men\", \"Black\" ,\"Citizen Voting Age Pop\", \"County Unemployment Rate for 2013\",\n",
    "               'Percent Population with age between 16 and 44', 'Hispanic', 'Native', 'WorkAtHome']]\n",
    "y = y_train\n",
    "model.fit(x, y)\n",
    "\n",
    "# Predict class labels using KNearest Neighbour\n",
    "x_test = x_val[[\"TotalPop\",\"Poverty\", \"Men\", \"Black\" ,\"Citizen Voting Age Pop\", \"County Unemployment Rate for 2013\",\n",
    "               'Percent Population with age between 16 and 44', 'Hispanic', 'Native', 'WorkAtHome']]\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "\n",
    "# Compute confusion matrix\n",
    "y_test = y_val\n",
    "conf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(conf_matrix)\n",
    "\n",
    "# Plot confusion matrix\n",
    "sns.heatmap(conf_matrix, annot = True, fmt = \".3f\", square = True, cmap = plt.cm.Blues)\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.title('Confusion matrix')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Compute evaluation metrics\n",
    "print(metrics.accuracy_score(y_test, y_pred)) # accuracy\n",
    "print(1 - metrics.accuracy_score(y_test, y_pred)) # error\n",
    "print(metrics.precision_score(y_test, y_pred, average = None)) # precision\n",
    "print(metrics.recall_score(y_test, y_pred, average = None)) # recall\n",
    "print(metrics.f1_score(y_test, y_pred, average = None)) # F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K nearest neighbour with k = 4 and 10 parameter\n",
    "model = KNeighborsClassifier(n_neighbors = 4)\n",
    "x = x_train[[\"TotalPop\",\"Poverty\", \"Men\", \"Black\" ,\"Citizen Voting Age Pop\", \"County Unemployment Rate for 2013\",\n",
    "               'Percent Population with age between 16 and 44', 'Hispanic', 'Native', 'Mean Commute Time']]\n",
    "y = y_train\n",
    "model.fit(x, y)\n",
    "\n",
    "# Predict class labels using KNearest Neighbour\n",
    "x_test = x_val[[\"TotalPop\",\"Poverty\", \"Men\", \"Black\" ,\"Citizen Voting Age Pop\", \"County Unemployment Rate for 2013\",\n",
    "               'Percent Population with age between 16 and 44', 'Hispanic', 'Native', 'Mean Commute Time']]\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "\n",
    "# Compute confusion matrix\n",
    "y_test = y_val\n",
    "conf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(conf_matrix)\n",
    "\n",
    "# Plot confusion matrix\n",
    "sns.heatmap(conf_matrix, annot = True, fmt = \".3f\", square = True, cmap = plt.cm.Blues)\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.title('Confusion matrix')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Compute evaluation metrics\n",
    "print(metrics.accuracy_score(y_test, y_pred)) # accuracy\n",
    "print(1 - metrics.accuracy_score(y_test, y_pred)) # error\n",
    "print(metrics.precision_score(y_test, y_pred, average = None)) # precision\n",
    "print(metrics.recall_score(y_test, y_pred, average = None)) # recall\n",
    "print(metrics.f1_score(y_test, y_pred, average = None)) # F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K nearest neighbour with k = 4 and 10 parameter\n",
    "model = KNeighborsClassifier(n_neighbors = 4)\n",
    "x = x_train[[\"TotalPop\",\"Poverty\", \"Men\", \"Black\" ,\"Citizen Voting Age Pop\", \"County Unemployment Rate for 2013\",\n",
    "               'Percent Population with age between 16 and 44', 'Hispanic', 'Native', 'State Unemployment rate for 2013']]\n",
    "y = y_train\n",
    "model.fit(x, y)\n",
    "\n",
    "# Predict class labels using KNearest Neighbour\n",
    "x_test = x_val[[\"TotalPop\",\"Poverty\", \"Men\", \"Black\" ,\"Citizen Voting Age Pop\", \"County Unemployment Rate for 2013\",\n",
    "               'Percent Population with age between 16 and 44', 'Hispanic', 'Native', 'State Unemployment rate for 2013']]\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "\n",
    "# Compute confusion matrix\n",
    "y_test = y_val\n",
    "conf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(conf_matrix)\n",
    "\n",
    "# Plot confusion matrix\n",
    "sns.heatmap(conf_matrix, annot = True, fmt = \".3f\", square = True, cmap = plt.cm.Blues)\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.title('Confusion matrix')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Compute evaluation metrics\n",
    "print(metrics.accuracy_score(y_test, y_pred)) # accuracy\n",
    "print(1 - metrics.accuracy_score(y_test, y_pred)) # error\n",
    "print(metrics.precision_score(y_test, y_pred, average = None)) # precision\n",
    "print(metrics.recall_score(y_test, y_pred, average = None)) # recall\n",
    "print(metrics.f1_score(y_test, y_pred, average = None)) # F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K nearest neighbour with k = 4 and \"County Unemployment Rate for 2013\"\n",
    "model = KNeighborsClassifier(n_neighbors = 4)\n",
    "x = x_train[[\"County Unemployment Rate for 2013\"]]\n",
    "y = y_train\n",
    "model.fit(x, y)\n",
    "\n",
    "# Predict class labels using KNearest Neighbour\n",
    "x_test = x_val[[\"County Unemployment Rate for 2013\"]]\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "\n",
    "# Compute confusion matrix\n",
    "y_test = y_val\n",
    "conf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(conf_matrix)\n",
    "\n",
    "# Plot confusion matrix\n",
    "sns.heatmap(conf_matrix, annot = True, fmt = \".3f\", square = True, cmap = plt.cm.Blues)\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.title('Confusion matrix')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Compute evaluation metrics\n",
    "print(metrics.accuracy_score(y_test, y_pred)) # accuracy\n",
    "print(1 - metrics.accuracy_score(y_test, y_pred)) # error\n",
    "print(metrics.precision_score(y_test, y_pred, average = None)) # precision\n",
    "print(metrics.recall_score(y_test, y_pred, average = None)) # recall\n",
    "print(metrics.f1_score(y_test, y_pred, average = None)) # F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In case of K_Nearest Neighbour with k=4, the classifier with \n",
    "# \"TotalPop\",\"Poverty\", \"Men\", \"Black\" ,\"Citizen Voting Age Pop\", \"County Unemployment Rate for 2013\",\n",
    "# 'Percent Population with age between 16 and 44', 'Hispanic', 'Native' is the best one with F1 Scores\n",
    "# [0.72820513 0.8729927  0.68137255]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The best classifier is \n",
    "# Naive Bayes, the classifier with parameter:\n",
    "# \"County Unemployment Rate for 2013\"\n",
    "# is the best one with F1 Scores:\n",
    "# [0.7625     0.86728395 0.74166667]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper Paramter TUning\n",
    "x_train.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tree.DecisionTreeClassifier()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x_train[['TotalPop', 'Men', 'White', 'Black','Citizen Voting Age Pop', 'Median Household Income', \n",
    "             'IncomePerCap', 'Poverty', 'ChildPoverty', 'County Unemployment Rate for 2013']]\n",
    "y = y_train\n",
    "x2 = x_val[['TotalPop', 'Men', 'White', 'Black','Citizen Voting Age Pop', 'Median Household Income', \n",
    "            'IncomePerCap', 'Poverty', 'ChildPoverty', 'County Unemployment Rate for 2013']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'criterion': [\"gini\", \"entropy\"], 'max_features': [1,10], 'min_samples_leaf' : randint(1,32),\n",
    "          'min_samples_split': randint(2,32)}\n",
    "scorer = make_scorer(f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = RandomizedSearchCV(model, param_distributions = params, n_jobs=-1, n_iter = 61, scoring = 'f1_macro')\n",
    "h.fit(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestP = h.best_params_\n",
    "bestDT = h.best_estimator_\n",
    "bestP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score (bestDT, x, y, cv = 5, scoring = 'f1_macro')\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = bestDT.predict(x2)\n",
    "\n",
    "# Compute confusion matrix\n",
    "y_test = y_val\n",
    "conf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(conf_matrix)\n",
    "\n",
    "# Plot confusion matrix\n",
    "sns.heatmap(conf_matrix, annot = True, fmt = \".3f\", square = True, cmap = plt.cm.Blues)\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.title('Confusion matrix')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Compute evaluation metrics\n",
    "print(metrics.accuracy_score(y_test, y_pred)) # accuracy\n",
    "print(1 - metrics.accuracy_score(y_test, y_pred)) # error\n",
    "print(metrics.precision_score(y_test, y_pred, average = None)) # precision\n",
    "print(metrics.recall_score(y_test, y_pred, average = None)) # recall\n",
    "print(metrics.f1_score(y_test, y_pred, average = None)) # F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelKNN = KNeighborsClassifier()\n",
    "modelKNN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x_train[['TotalPop', 'Men', 'White', 'Black','Citizen Voting Age Pop', 'Median Household Income', \n",
    "             'IncomePerCap', 'Poverty', 'ChildPoverty', 'County Unemployment Rate for 2013']]\n",
    "y = y_train\n",
    "x2 = x_val[['TotalPop', 'Men', 'White', 'Black','Citizen Voting Age Pop', 'Median Household Income', \n",
    "            'IncomePerCap', 'Poverty', 'ChildPoverty', 'County Unemployment Rate for 2013']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paramsKNN = {'n_neighbors' : randint(1,20), 'metric':[\"euclidean\",\"manhattan\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H_KNN = RandomizedSearchCV(modelKNN, param_distributions = paramsKNN, n_jobs=-1, n_iter = 61, scoring = 'f1_macro')\n",
    "H_KNN.fit(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestPKNN = H_KNN.best_params_\n",
    "bestDTKNN = H_KNN.best_estimator_\n",
    "bestPKNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score (bestDTKNN, x, y, cv = 5, scoring = 'f1_macro')\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = bestDTKNN.predict(x_val[['TotalPop', 'Men', 'White', 'Black','Citizen Voting Age Pop', 'Median Household Income', \n",
    "               'IncomePerCap', 'Poverty', 'ChildPoverty', 'County Unemployment Rate for 2013']])\n",
    "\n",
    "# Compute confusion matrix\n",
    "y_test = y_val\n",
    "conf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(conf_matrix)\n",
    "\n",
    "# Plot confusion matrix\n",
    "sns.heatmap(conf_matrix, annot = True, fmt = \".3f\", square = True, cmap = plt.cm.Blues)\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.title('Confusion matrix')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Compute evaluation metrics\n",
    "print(metrics.accuracy_score(y_test, y_pred)) # accuracy\n",
    "print(1 - metrics.accuracy_score(y_test, y_pred)) # error\n",
    "print(metrics.precision_score(y_test, y_pred, average = None)) # precision\n",
    "print(metrics.recall_score(y_test, y_pred, average = None)) # recall\n",
    "print(metrics.f1_score(y_test, y_pred, average = None)) # F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x_train[['TotalPop', 'Men', 'White', 'Black','Citizen Voting Age Pop', 'Median Household Income', \n",
    "              'IncomePerCap', 'Poverty', 'ChildPoverty', 'County Unemployment Rate for 2013']]\n",
    "y = y_train\n",
    "x.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_func(args):\n",
    "    min_samples_split = args['min_samples_split']\n",
    "    criterion = args['criterion']\n",
    "    max_features = args['max_features']\n",
    "    min_samples_leaf = args['min_samples_leaf']\n",
    "    clf = tree.DecisionTreeClassifier(criterion=criterion, \n",
    "                       max_features=max_features,min_samples_leaf=min_samples_leaf, min_samples_split=min_samples_split)\n",
    " \n",
    "    clf.fit(x,y)    \n",
    "    y_pred = clf.predict(x2)\n",
    "    f1 = -(f1_score(y_pred,y_val,  average='macro'))\n",
    "    return f1\n",
    "space = {'criterion': hp.choice('criterion',['gini', 'entropy']),'max_features': hp.choice('max_features', range(1,11)),\n",
    "        'min_samples_split': hp.choice('min_samples_split', range(2,32)),\n",
    "         'min_samples_leaf' : hp.choice('min_samples_leaf',range(1,32))}\n",
    "                                \n",
    "                                \n",
    "                                \n",
    "best_classifier = fmin(objective_func, space, algo=tpe.suggest, max_evals=61)\n",
    "print(best_classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bhdt = tree.DecisionTreeClassifier(criterion='gini', \n",
    "                       max_features=7,min_samples_leaf=28, min_samples_split=7)\n",
    "\n",
    "bhdt.fit(x,y)\n",
    "y_pred = bhdt.predict(x_val[['TotalPop', 'Men', 'White', 'Black','Citizen Voting Age Pop', 'Median Household Income', \n",
    "               'IncomePerCap', 'Poverty', 'ChildPoverty', 'County Unemployment Rate for 2013']])\n",
    "\n",
    "# Compute confusion matrix\n",
    "y_test = y_val\n",
    "conf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(conf_matrix)\n",
    "\n",
    "# Plot confusion matrix\n",
    "sns.heatmap(conf_matrix, annot = True, fmt = \".3f\", square = True, cmap = plt.cm.Blues)\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.title('Confusion matrix')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Compute evaluation metrics\n",
    "print(metrics.accuracy_score(y_test, y_pred)) # accuracy\n",
    "print(1 - metrics.accuracy_score(y_test, y_pred)) # error\n",
    "print(metrics.precision_score(y_test, y_pred, average = None)) # precision\n",
    "print(metrics.recall_score(y_test, y_pred, average = None)) # recall\n",
    "print(metrics.f1_score(y_test, y_pred, average = None)) # F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_func(args):\n",
    "    n_neighbors = args['n_neighbors']\n",
    "    metric = args['metric']\n",
    "    clf = KNeighborsClassifier(n_neighbors=n_neighbors, metric=metric)\n",
    " \n",
    "    clf.fit(x,y)    \n",
    "    y_pred = clf.predict(x2)\n",
    "    f1 = -(f1_score(y_pred,y_val,  average='macro'))\n",
    "    return f1\n",
    "space = {'n_neighbors': hp.choice('n_neighbors',range(1,20)),\n",
    "        'metric':hp.choice('metric', [\"euclidean\",\"manhattan\"])}\n",
    "\n",
    "best_classifier = fmin(objective_func, space, algo=tpe.suggest, max_evals=61)\n",
    "print(best_classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bh = KNeighborsClassifier(metric = 'euclidean', n_neighbors= 8)\n",
    "bh.fit(x,y)\n",
    "y_pred = bh.predict(x_val[['TotalPop', 'Men', 'White', 'Black','Citizen Voting Age Pop', 'Median Household Income', \n",
    "               'IncomePerCap', 'Poverty', 'ChildPoverty', 'County Unemployment Rate for 2013']])\n",
    "\n",
    "# Compute confusion matrix\n",
    "y_test = y_val\n",
    "conf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(conf_matrix)\n",
    "\n",
    "# Plot confusion matrix\n",
    "sns.heatmap(conf_matrix, annot = True, fmt = \".3f\", square = True, cmap = plt.cm.Blues)\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.title('Confusion matrix')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Compute evaluation metrics\n",
    "print(metrics.accuracy_score(y_test, y_pred)) # accuracy\n",
    "print(1 - metrics.accuracy_score(y_test, y_pred)) # error\n",
    "print(metrics.precision_score(y_test, y_pred, average = None)) # precision\n",
    "print(metrics.recall_score(y_test, y_pred, average = None)) # recall\n",
    "print(metrics.f1_score(y_test, y_pred, average = None)) # F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estim = HyperoptEstimator(classifier=knn('my_knn', n_neighbors= hp.choice('n_neighbors',range(1,20)),\n",
    "        metric=hp.choice('metric', [\"euclidean\",\"manhattan\"])),\n",
    "                          preprocessing=[],\n",
    "                          algo=tpe.suggest,\n",
    "                          max_evals=61,\n",
    "                          trial_timeout=300)\n",
    "estim.fit(x.reset_index(),y.reset_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly as py\n",
    "import plotly.graph_objs as go\n",
    "import plotly.figure_factory as ff\n",
    "\n",
    "fips =data_new['CensusId'].astype(str).tolist()\n",
    "values = data_new['Class'].tolist()\n",
    "#colorscale = ['rgb(0,0,255)', 'rgb(255,0,0)', 'rgb(0,255,0)']\n",
    "fig = ff.create_choropleth(fips=fips, values=values)\n",
    "fig.layout.template = None\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the classes of observations of 2015 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "DataC[['TotalPop',\n",
    "       'Percent Population with age between 16 and 44',\n",
    "       'Percent Population with age between 45 and 74',\n",
    "       'Percent Population with age between 75 and over', 'Men', 'Women',\n",
    "       'Hispanic', 'White', 'Black', 'Native', 'Asian', 'Pacific',\n",
    "       'Citizen Voting Age Pop', 'Median Household Income', 'IncomePerCap',\n",
    "       'Poverty', 'ChildPoverty', 'Professional', 'Service', 'Office',\n",
    "       'Construction', 'Production', 'Drive', 'Carpool', 'Transit', 'Walk',\n",
    "       'OtherTransp', 'WorkAtHome', 'Mean Commute Time',\n",
    "       'State Unemployment rate for 2013', 'County Unemployment Rate for 2013']] = scaler.fit_transform(DataC[['TotalPop',\n",
    "       'Percent Population with age between 16 and 44',\n",
    "       'Percent Population with age between 45 and 74',\n",
    "       'Percent Population with age between 75 and over', 'Men', 'Women',\n",
    "       'Hispanic', 'White', 'Black', 'Native', 'Asian', 'Pacific',\n",
    "       'Citizen Voting Age Pop', 'Median Household Income', 'IncomePerCap',\n",
    "       'Poverty', 'ChildPoverty', 'Professional', 'Service', 'Office',\n",
    "       'Construction', 'Production', 'Drive', 'Carpool', 'Transit', 'Walk',\n",
    "       'OtherTransp', 'WorkAtHome', 'Mean Commute Time',\n",
    "       'State Unemployment rate for 2013', 'County Unemployment Rate for 2013']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DataC.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the classes of observations of 2015 data\n",
    "\n",
    "\n",
    "# Predict class labels using Naive Bayes\n",
    "x_test = DataC[[\"County Unemployment Rate for 2013\"]]\n",
    "y_pred = Classifier.predict(x_test)\n",
    "\n",
    "\n",
    "# Compute confusion matrix\n",
    "y_test = DataC[[\"Class\"]]\n",
    "conf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(conf_matrix)\n",
    "\n",
    "# Plot confusion matrix\n",
    "sns.heatmap(conf_matrix, annot = True, fmt = \".3f\", square = True, cmap = plt.cm.Blues)\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.title('Confusion matrix')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Compute evaluation metrics\n",
    "print(metrics.accuracy_score(y_test, y_pred)) # accuracy\n",
    "print(1 - metrics.accuracy_score(y_test, y_pred)) # error\n",
    "print(metrics.precision_score(y_test, y_pred, average = None)) # precision\n",
    "print(metrics.recall_score(y_test, y_pred, average = None)) # recall\n",
    "print(metrics.f1_score(y_test, y_pred, average = None)) # F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fips =DataC['CensusId'].astype(str).tolist()\n",
    "values = y_pred.tolist()\n",
    "#colorscale = ['rgb(0,0,255)', 'rgb(255,0,0)', 'rgb(0,255,0)']\n",
    "fig = ff.create_choropleth(fips=fips, values=values)\n",
    "fig.layout.template = None\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataN2017.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_indexes=dataN2017[dataN2017['Unemployment'] >= 12].index\n",
    "dataN2017.loc[row_indexes,'Class']=\"3\"\n",
    "\n",
    "row_indexes1=dataN2017[(dataN2017['Unemployment'] >= 8) & (dataN2017['Unemployment'] < 12)].index\n",
    "dataN2017.loc[row_indexes1,'Class']=\"2\"\n",
    "\n",
    "row_indexes2=dataN2017[dataN2017['Unemployment'] < 8].index\n",
    "dataN2017.loc[row_indexes2,'Class']=\"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataN2017['Class'][dataN2017['Class'] == \"1\"] = \"Lowest\"\n",
    "dataN2017['Class'][dataN2017['Class'] == \"2\"] = \"Moderate\"\n",
    "dataN2017['Class'][dataN2017['Class'] == \"3\"] = \"Highest\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataN2017.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the classes of observations of 2017 dataset\n",
    "\n",
    "\n",
    "# Predict class labels using Naive Bayes\n",
    "x_test = dataN2017[[\"County Unemployment Rate for 2015\"]]\n",
    "y_pred2 = Classifier.predict(x_test)\n",
    "\n",
    "# Compute confusion matrix\n",
    "y_test = dataN2017[[\"Class\"]]\n",
    "conf_matrix = metrics.confusion_matrix(y_test, y_pred2)\n",
    "print(conf_matrix)\n",
    "\n",
    "# Plot confusion matrix\n",
    "sns.heatmap(conf_matrix, annot = True, fmt = \".3f\", square = True, cmap = plt.cm.Blues)\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.title('Confusion matrix')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Compute evaluation metrics\n",
    "print(metrics.accuracy_score(y_test, y_pred)) # accuracy\n",
    "print(1 - metrics.accuracy_score(y_test, y_pred)) # error\n",
    "print(metrics.precision_score(y_test, y_pred, average = None)) # precision\n",
    "print(metrics.recall_score(y_test, y_pred, average = None)) # recall\n",
    "print(metrics.f1_score(y_test, y_pred, average = None)) # F1 score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fips = dataN2017['CountyId'].astype(str).tolist()\n",
    "values = dataN2017[\"Class\"].tolist()\n",
    "#colorscale = ['rgb(0,0,255)', 'rgb(255,0,0)', 'rgb(0,255,0)']\n",
    "fig = ff.create_choropleth(fips=fips, values=values)\n",
    "fig.layout.template = None\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fips = dataN2017['CountyId'].astype(str).tolist()\n",
    "values = y_pred2.tolist()\n",
    "#colorscale = ['rgb(0,0,255)', 'rgb(255,0,0)', 'rgb(0,255,0)']\n",
    "fig = ff.create_choropleth(fips=fips, values=values)\n",
    "fig.layout.template = None\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_pred2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = pd.DataFrame(data = {\"Class\":y_pred2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.to_csv(\"Predicted Classes of counties 2017.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
